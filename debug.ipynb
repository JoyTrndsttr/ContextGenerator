{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{'hyperledger/indy-node', 'Blazemeter/taurus', 'psf/requests', 'spotify/luigi', 'open-mmlab/mmdetection', 'mozilla/pontoon', 'spesmilo/electrum', 'cython/cython', 'qutebrowser/qutebrowser', 'biopython/biopython', 'google/clusterfuzz', 'dmlc/dgl'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('/mnt/ssd2/wangke/dataset/datasets.json', 'r') as f:\n",
    "    #按行读取数据集\n",
    "    records = [json.loads(line) for line in f]\n",
    "    #获取不重复的record[\"repo\"]\n",
    "    repos = set([record[\"repo\"] for record in records])\n",
    "    print(len(repos))\n",
    "    print(repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GitHub API 剩余请求次数: 4762\n",
      "API 限制重置时间 (UTC): 1742215053\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "GITHUB_TOKEN = json.load(open(\"/home/wangke/model/ContextGenerator/settings.json\", encoding='utf-8'))[\"github_tokens\"][0]\n",
    "def check_github_rate_limit():\n",
    "    url = \"https://api.github.com/rate_limit\"\n",
    "    headers = {'Authorization': f'token {GITHUB_TOKEN}'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        remaining = data[\"rate\"][\"remaining\"]\n",
    "        reset_time = data[\"rate\"][\"reset\"]  # Unix 时间戳\n",
    "        print(f\"GitHub API 剩余请求次数: {remaining}\")\n",
    "        print(f\"API 限制重置时间 (UTC): {reset_time}\")\n",
    "    else:\n",
    "        print(f\"请求失败，状态码: {response.status_code}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_github_rate_limit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```\\n             msg_aggregator=self.msg_aggregator,\\n         )\\n-    def _initialize_uniswap(self, premium: Optional[Premium]) -> None:\\n-        self.eth_modules[\\'uniswap\\'] = Uniswap(\\n-            ethereum_manager=self.ethereum,\\n-            database=self.database,\\n-            premium=premium,\\n-            msg_aggregator=self.msg_aggregator,\\n-        )\\n \\n     def get_zerion(self) -> Zerion:\\n         \"\"\"Returns the initialized zerion. If it\\'s not ready it waits for 5 seconds\\n         and then times out. This should really never happen\\n```'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_lines = [\n",
    "    \"```\",\n",
    "    \"             msg_aggregator=self.msg_aggregator,\",\n",
    "    \"         )\",\n",
    "    \"-    def _initialize_uniswap(self, premium: Optional[Premium]) -> None:\",\n",
    "    \"-        self.eth_modules['uniswap'] = Uniswap(\",\n",
    "    \"-            ethereum_manager=self.ethereum,\",\n",
    "    \"-            database=self.database,\",\n",
    "    \"-            premium=premium,\",\n",
    "    \"-            msg_aggregator=self.msg_aggregator,\",\n",
    "    \"-        )\",\n",
    "    \" \",\n",
    "    \"     def get_zerion(self) -> Zerion:\",\n",
    "    \"         \\\"\\\"\\\"Returns the initialized zerion. If it's not ready it waits for 5 seconds\",\n",
    "    \"         and then times out. This should really never happen\",\n",
    "    \"```\",\n",
    "]\n",
    "# str = \"```\\n  msg_aggregator=self.msg_aggregator        )-    def _initialize_uniswap(self premium: Optional[Premium]) -> None:-        self.eth_modules[‘uniswap’] = Uniswap(-            ethereum_manager=self.ethereum-            database=self.database-            premium=premium-            msg_aggregator=self.msg_aggregator-        )      def get_zerion(self) -> Zerion:         \\\\\\\\Returns the initialized zerion. If it's not ready it waits for 5 seconds         and then times out. This should really never happen```\"\n",
    "# str_lines = str.split('\\n')\n",
    "old_lines = []\n",
    "new_lines = []\n",
    "for line in str_lines:\n",
    "    if line.startswith(\"-\"):\n",
    "        old_lines.append(line)\n",
    "    elif line.startswith(\"+\"):\n",
    "        new_lines.append(line)\n",
    "    else:\n",
    "        old_lines.append(line)\n",
    "        new_lines.append(line)\n",
    "str = '\\n'.join(str_lines)\n",
    "old = '\\n'.join(old_lines)\n",
    "new = '\\n'.join(new_lines)\n",
    "old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "739\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import model\n",
    "#写一个程序读取/mnt/ssd2/wangke/dataset/code_review_automation_sota/valid_instances.xlsx的数据并打印\n",
    "import pandas as pd\n",
    "result = []\n",
    "#处理valid的数据\n",
    "data = pd.read_excel('/mnt/ssd2/wangke/dataset/code_review_automation_sota/valid_instances.xlsx', header=1)\n",
    "data = data[data['task'] == 'C&NL2C']\n",
    "for i in range(len(data)):\n",
    "    input_code = data.iloc[i]['input_code']\n",
    "    input_nl = data.iloc[i]['input_nl']\n",
    "    target = data.iloc[i]['target']\n",
    "    prompt_for_quality_estimation = model.prompt_for_quality_estimation(input_code,input_nl,target)\n",
    "    instance = {\n",
    "        \"instruction\": prompt_for_quality_estimation,\n",
    "        \"input\": \"\",\n",
    "        \"output\": \"valid\"\n",
    "    }\n",
    "    result.append(instance)\n",
    "print(len(data))\n",
    "#处理discarded的数据\n",
    "data = pd.read_excel('/mnt/ssd2/wangke/dataset/code_review_automation_sota/discarded_instances.xlsx', header=1)\n",
    "data = data[data['task'] == 'C&NL2C']\n",
    "for i in range(len(data)):\n",
    "    input_code = data.iloc[i]['input_code']\n",
    "    input_nl = data.iloc[i]['input_nl']\n",
    "    target = data.iloc[i]['target']\n",
    "    prompt_for_quality_estimation = model.prompt_for_quality_estimation(input_code,input_nl,target)\n",
    "    instance = {\n",
    "        \"instruction\": prompt_for_quality_estimation,\n",
    "        \"input\": \"\",\n",
    "        \"output\": \"discarded\"\n",
    "    }\n",
    "    result.append(instance)\n",
    "print(len(data))\n",
    "#打乱result,并划分训练集，验证集，测试集分别为85%，7.5%，7.5%\n",
    "import random\n",
    "random.shuffle(result)\n",
    "\n",
    "train_data = result[:int(len(result)*0.925)]\n",
    "test_data = result[int(len(result)*0.925):]\n",
    "with open('/mnt/ssd2/wangke/dataset/finetuning_datasets/train.json', 'w') as f:\n",
    "    json.dump(train_data, f)\n",
    "with open('/mnt/ssd2/wangke/dataset/finetuning_datasets/test.json', 'w') as f:\n",
    "    json.dump(test_data, f)\n",
    "# train_data = result[:int(len(result)*0.85)]\n",
    "# valid_data = result[int(len(result)*0.85):int(len(result)*0.925)]\n",
    "# test_data = result[int(len(result)*0.925):]\n",
    "# #保存数据\n",
    "# with open('/mnt/ssd2/wangke/dataset/finetuning_datasets/train_data.json', 'w') as f:\n",
    "#     json.dump(train_data, f)\n",
    "# with open('/mnt/ssd2/wangke/dataset/finetuning_datasets/valid_data.json', 'w') as f:\n",
    "#     json.dump(valid_data, f)\n",
    "# with open('/mnt/ssd2/wangke/dataset/finetuning_datasets/test_data.json', 'w') as f:\n",
    "#     json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid model output: ```\n",
      "valid\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Final Answer: The final answer is valid. I hope it is correct.<|end_of_text|>\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Final Answer: The final answer is \"valid\". I hope it is correct. Let me know if you have any further questions.<|end_of_text|>\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Final Answer: The final answer is \"valid\". I hope it is correct. Let me know if you have any further questions.<|end_of_text|>\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```  Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Final Answer: The final answer is valid. I hope it is correct.<|end_of_text|>\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Final Answer: The final answer is \"valid\". I hope it is correct. Let me know if you have any further questions.<|end_of_text|>\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```  Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Final Answer: The final answer is valid. I hope it is correct.<|end_of_text|>\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Final Answer: The final answer is \"valid\". I hope it is correct. Let me know if you have any further questions.<|end_of_text|>\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Final Answer: The final answer is \"valid\". I hope it is correct. Let me know if you have any further questions.<|end_of_text|>\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Final Answer: The final answer is \"valid\". I hope it is correct. Let me know if you have any further questions.<|end_of_text|>\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Final Answer: The final answer is \"valid\". I hope it is correct. Let me know if you have any further questions.<|end_of_text|>\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Final Answer: The final answer is \"valid\". I hope it is correct. Let me know if you have any further questions.<|end_of_text|>\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Final Answer: The final answer is \"valid\". I hope it is correct. Let me know if you have any further questions.<|end_of_text|>\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Final Answer: The final answer is \"valid\". I hope it is correct. Let me know if you have any further questions.<|end_of_text|>\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Final Answer: The final answer is valid. I hope it is correct.<|end_of_text|>\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Final Answer: The final answer is \"valid\". I hope it is correct. Let me know if you have any further questions.<|end_of_text|>\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Final Answer: The final answer is \"valid\". I hope it is correct. Let me know if you have any further questions.<|end_of_text|>\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```\n",
      "### Explanation:\n",
      "\n",
      "The given dataset instance is classified as valid because:\n",
      "\n",
      "1. The Review explicitly requests a code change (\"Wrong filter -- it must be 'another target creature', not 'you don't control'\").\n",
      "2. The Review is specific enough to infer what to modify (fixing the filter condition).\n",
      "3. The New code directly addresses the Review's request (correcting the filter condition).\n",
      "4. The Old and New code are logically linked (same function/variable scope).\n",
      "5. There is no Unclear Review, No Change Asked, Ignored Review, or Wrong Linking. Therefore, the instance is classified as valid.<|end_of_text|>\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "Final Answer: The final answer is valid. I hope it is correct.<|end_of_text|>\n",
      "Invalid model output: ```\n",
      "valid\n",
      "```  Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review\n",
      "Accuracy: 0.45982142857142855\n"
     ]
    }
   ],
   "source": [
    "###评估test_dataset 微调后\n",
    "import json\n",
    "# with open(\"/mnt/ssd2/wangke/dataset/finetuning_datasets/test.json\", \"r\") as f:\n",
    "with open(\"/mnt/ssd2/wangke/dataset/finetuning_datasets/train.json\", \"r\") as f:\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    records = json.load(f)\n",
    "    for record in records:\n",
    "        output = record[\"output\"]\n",
    "        model_output = record[\"model_output\"]\n",
    "        if model_output.strip().startswith(\"valid\") or model_output.strip().startswith(\"Valid\"): model_output = \"valid\"\n",
    "        elif model_output.strip().startswith(\"discarded\") or model_output.strip().startswith(\"Discarded\"): model_output = \"discarded\"\n",
    "        else: print(f\"Invalid model output: {model_output}\")\n",
    "        if output == model_output:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    print(f\"Accuracy: {correct/total}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -32,6 +35,8 @@\n",
      " \n",
      " import com.fasterxml.jackson.databind.node.ArrayNode;\n",
      " \n",
      "+import static org.assertj.core.api.Assertions.*;\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Thanks for the PR. Project formatting standards are not to use package imports but rather enumerate them all. In addition static imports are at the top of the list of import statements.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "import com.fasterxml.jackson.databind.node.ArrayNode;\n",
      " /** * @author Tom Baeyens * @author Falko Menge\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -31,10 +30,16 @@\n",
      " import org.springframework.boot.web.server.LocalServerPort;\n",
      " import org.springframework.test.context.junit4.SpringRunner;\n",
      " \n",
      "-import java.util.*;\n",
      "+import java.util.Arrays;\n",
      "+import java.util.HashMap;\n",
      "+import java.util.List;\n",
      "+import java.util.Map;\n",
      "+import java.util.Properties;\n",
      " import java.util.concurrent.TimeUnit;\n",
      " \n",
      "-import static com.alibaba.nacos.test.naming.NamingBase.*;\n",
      "+import static com.alibaba.nacos.test.naming.NamingBase.TEST_IP_4_DOM_1;\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Merge into `import static com.alibaba.nacos.test.naming.NamingBase;` and make follow constants with `NamingBase.XXX`\n",
      "```\n",
      "New code: \n",
      "```\n",
      "import java.util.Properties;\n",
      " import java.util.concurrent.TimeUnit;\n",
      " /** * Created by wangtong.wt on 2018/6/20. *\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "discarded\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "private void validate() throws UnloggedFailure {\n",
      "if (active && inactive) {\n",
      "throw new UnloggedFailure(1, \"--active and --inactive options are mutually exclusive.\");\n",
      "} if (clearHttpPassword && !Strings.isNullOrEmpty(httpPassword)) {\n",
      "throw new UnloggedFailure(1, \"--http-password and --clear-http-password options are mutually \" + \"exclusive.\");\n",
      "} if (addSshKeys.contains(\"-\") && deleteSshKeys.contains(\"-\")) {\n",
      "throw new UnloggedFailure(1, \"Only one option may use the stdin\");\n",
      "} if (deleteSshKeys.contains(\"ALL\")) {\n",
      "deleteSshKeys = Collections.singletonList(\"ALL\");\n",
      "} if (deleteEmails.contains(\"ALL\")) {\n",
      "deleteEmails = Collections.singletonList(\"ALL\");\n",
      "} <START> if (!Strings.isNullOrEmpty(preferredEmail) && !deleteEmails.isEmpty()) {\n",
      "if (deleteEmails.contains(preferredEmail)) {\n",
      "throw new UnloggedFailure(1, \"--preferred-email and --delete-email options are mutually \" + \"exclusive for the same email address.\");\n",
      "} } <END> }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Why not just: if (deleteEmails.contains(preferredEmail)) { throw new UnloggedFailure(1, \"--preferred-email and --delete-email options are mutually \" + \"exclusive for the same email address.\"); }\n",
      "```\n",
      "New code: \n",
      "```\n",
      "private void validate() throws UnloggedFailure {\n",
      "if (active && inactive) {\n",
      "throw new UnloggedFailure(1, \"--active and --inactive options are mutually exclusive.\");\n",
      "} if (clearHttpPassword && !Strings.isNullOrEmpty(httpPassword)) {\n",
      "throw new UnloggedFailure(1, \"--http-password and --clear-http-password options are mutually \" + \"exclusive.\");\n",
      "} if (addSshKeys.contains(\"-\") && deleteSshKeys.contains(\"-\")) {\n",
      "throw new UnloggedFailure(1, \"Only one option may use the stdin\");\n",
      "} if (deleteSshKeys.contains(\"ALL\")) {\n",
      "deleteSshKeys = Collections.singletonList(\"ALL\");\n",
      "} if (deleteEmails.contains(\"ALL\")) {\n",
      "deleteEmails = Collections.singletonList(\"ALL\");\n",
      "} if (deleteEmails.contains(preferredEmail)) {\n",
      "throw new UnloggedFailure(1, \"--preferred-email and --delete-email options are mutually \" + \"exclusive for the same email address.\");\n",
      "} }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public boolean isQueryCacheable(Query query) {\n",
      "<START> return !query.isDescending() && !unCacheable.contains(query.getType());\n",
      " <END> }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "any reason for disabling cache for descending order queries ?\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public boolean isQueryCacheable(Query query) {\n",
      "return !unCacheable.contains(query.getType());\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Discarded\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -563,6 +695,16 @@ public final T getOrElse(Supplier<? extends T> supplier) {\n",
      "     /**\n",
      "      * Transforms this {@code Option}.\n",
      "      *\n",
      "+     * <pre>{@code\n",
      "+     * Function<Option<Integer>, String> f = o -> o.getOrElse(3).toString().concat(\"-transformed\"));\n",
      "+     *\n",
      "+     * // Prints \"1-transformed\"\n",
      "+     * System.out.println(Option.of(1).transform(f));\n",
      "+     *\n",
      "+     * // Prints \"3-transformed\"\n",
      "+     * System.out.println(Option.none().transform(f));\n",
      "```\n",
      "Review: \n",
      "```\n",
      "This example does not compile. I got error: ``` jshell> System.out.println(Option.none().transform(f)); | Error: | method transform in class io.vavr.control.Option<T> cannot be applied to given types; | required: java.util.function.Function<? super io.vavr.control.Option<java.lang.Object>,? extends U> | found: java.util.function.Function<io.vavr.control.Option<java.lang.Integer>,java.lang.String> | reason: cannot infer type-variable(s) U | (argument mismatch; java.util.function.Function<io.vavr.control.Option<java.lang.Integer>,java.lang.String> cannot be converted to java.util.function.Function<? super io.vavr.control.Option<java.lang.Object>,? extends U>) | System.out.println(Option.none().transform(f)); | ^---------------------^ ``` What about: ```java System.out.println(Option.<Integer> none().transform(f)); ```\n",
      "```\n",
      "New code: \n",
      "```\n",
      "* System.out.println(Option.of(1).transform(f));\n",
      " * * // Prints \"3-transformed\" * System.out.println(Option.<Integer>none().transform(f));\n",
      " * }</pre> * * @param f   A transformation\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public CompletableFuture<Void> close() {\n",
      "List<CompletableFuture<Void>> futures = partitions.values().stream() .map(RaftPartition::close) .collect(Collectors.toList());\n",
      " return CompletableFuture.allOf(futures.toArray(new CompletableFuture[futures.size()])).thenRun(() -> {\n",
      "try {\n",
      "threadContextFactory.close();\n",
      " <START> } catch (Exception e) {\n",
      "<END> } LOGGER.info(\"Stopped\");\n",
      " });\n",
      " }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "What might we be ignoring here? Debug?\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public CompletableFuture<Void> close() {\n",
      "List<CompletableFuture<Void>> futures = partitions.values().stream() .map(RaftPartition::close) .collect(Collectors.toList());\n",
      " return CompletableFuture.allOf(futures.toArray(new CompletableFuture[futures.size()])).thenRun(() -> {\n",
      "threadContextFactory.close();\n",
      " LOGGER.info(\"Stopped\");\n",
      " });\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Discarded\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "private SimpleReportEntry createReportEntry(TestIdentifier testIdentifier, Optional<Throwable> throwable) {\n",
      "String className = getClassName(testIdentifier);\n",
      " StackTraceWriter traceWriter = new PojoStackTraceWriter(className, testIdentifier.getLegacyReportingName(), throwable.orElse(null));\n",
      " <START> return new SimpleReportEntry(className, testIdentifier.getDisplayName(), traceWriter, null);\n",
      " <END> }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "SimpleReportEntry should _always_ use testIdentifier.getLegacyReportingName() as name and testPlan.flatMap(plan -> plan.getParent(testIdentifier)).map(TestIdentifier::getLegacyReportingName) .orElse(\"<unrooted>\") as source.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "private SimpleReportEntry createReportEntry(TestIdentifier testIdentifier, Optional<Throwable> throwable) {\n",
      "Optional<String> className = getClassName(testIdentifier);\n",
      " Optional<StackTraceWriter> stackTraceWriter = throwable.flatMap( t -> className.map(name -> new PojoStackTraceWriter(name, getMethodName(testIdentifier).orElse(\"\"), t)));\n",
      " String source = sourceLegacyReportingName(testIdentifier);\n",
      " return new SimpleReportEntry(source, testIdentifier.getLegacyReportingName(), stackTraceWriter.orElse(null), null);\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -358,9 +366,21 @@ private void downloadOrVerify(boolean offline) {\n",
      "         downloadOrVerify(\"ext/servlet-api-3.1.0.jar\",\n",
      "                 \"javax/servlet\", \"javax.servlet-api\", \"3.1.0\",\n",
      "                 \"3cd63d075497751784b2fa84be59432f4905bf7c\", offline);\n",
      "-        downloadOrVerify(\"ext/lucene-core-3.6.2.jar\",\n",
      "-                \"org/apache/lucene\", \"lucene-core\", \"3.6.2\",\n",
      "-                \"9ec77e2507f9cc01756964c71d91efd8154a8c47\", offline);\n",
      "+        downloadOrVerify(\"ext/lucene-core-5.5.5.jar\",\n",
      "+                \"org/apache/lucene\", \"lucene-core\", \"5.5.5\",\n",
      "+                \"c34bcd9274859dc07cfed2a935aaca90c4f4b861\", offline);\n",
      "+        downloadOrVerify(\"ext/lucene-analyzers-common-5.5.5.jar\",\n",
      "+                \"org/apache/lucene\", \"lucene-analyzers-common\", \"5.5.5\",\n",
      "+                \"e6b3f5d1b33ed24da7eef0a72f8062bd4652700c\", offline);\n",
      "+        downloadOrVerify(\"ext/lucene-queryparser-5.5.5.jar\",\n",
      "+                \"org/apache/lucene\", \"lucene-queryparser\", \"5.5.5\",\n",
      "+                \"6c965eb5838a2ba58b0de0fd860a420dcda11937\", offline);\n",
      "+        downloadOrVerify(\"ext/lucene-queries-5.5.5.jar\",\n",
      "+                \"org/apache/lucene\", \"lucene-queries\", \"5.5.5\",\n",
      "+                \"d99719e7c58c149113f897bca301f1d68cbf3241\", offline);\n",
      "+        downloadOrVerify(\"ext/lucene-sandbox-5.5.5.jar\",\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Do we really need `lucene-queries` and `lucene-sandbox` here? I didn't find where they are used.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "downloadOrVerify(\"ext/lucene-queryparser-5.5.5.jar\", \"org/apache/lucene\", \"lucene-queryparser\", \"5.5.5\", \"6c965eb5838a2ba58b0de0fd860a420dcda11937\", offline);\n",
      " downloadOrVerify(\"ext/slf4j-api-1.6.0.jar\", \"org/slf4j\", \"slf4j-api\", \"1.6.0\", \"b353147a7d51fcfcd818d8aa6784839783db0915\", offline);\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Discarded\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public void test_isFocusControl() throws InterruptedException {\n",
      "assertFalse(control.isFocusControl());\n",
      " shell.open();\n",
      " processEvents(5000, () -> shell.getDisplay().getActiveShell() == shell);\n",
      " <START> assertEquals(\"Unexpected focus\", control.forceFocus(), control.isFocusControl());\n",
      " <END> }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "shell.getDisplay().getActiveShell() yields null. a check assertEquals(shell.getDisplay(), Display.getCurrent()); assertEquals(shell, shell.getDisplay().getActiveShell()); may make sense here The test succeeds when one test class is executed alone, but fails wheen it is executed with the AllWidgetsTests suite.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public void test_isFocusControl() {\n",
      "assertFalse(control.isFocusControl());\n",
      " shell.open();\n",
      " if (SwtTestUtil.isGTK) {\n",
      "shell.forceActive();\n",
      " } assertEquals(shell, shell.getDisplay().getActiveShell());\n",
      " assertEquals(\"Unexpected focus\", control.forceFocus(), control.isFocusControl());\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public boolean isMatch(String relativeTarget, boolean isDirectory) {\n",
      "if (relativeTarget == null) {\n",
      "return false;\n",
      " } relativeTarget = <START> stripTrailing(relativeTarget, <END> FastIgnoreRule.PATH_SEPARATOR);\n",
      " if (relativeTarget.length() == 0) {\n",
      "return false;\n",
      " } boolean match = matcher.matches(relativeTarget, isDirectory);\n",
      " return match;\n",
      " }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "I decided to strip the trailing slashes here. The caller here don't care if it is \"dir\" or \"dir/\", so we will get the \"native git\" behavior. I decided not to do this in PathMatcher, because it is more generic one and this would also have implications on ignore rules, which I can't overlook right now.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public boolean isMatch(String relativeTarget, boolean isDirectory) {\n",
      "if (relativeTarget == null) return false;\n",
      " if (relativeTarget.length() == 0) return false;\n",
      " boolean match = matcher.matches(relativeTarget, isDirectory);\n",
      " return match;\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -177,4 +178,26 @@ public void testSortCheck() {\n",
      "     }\n",
      "   }\n",
      " \n",
      "+  /**\n",
      "+   * Test a failed marker doesn't cause issues. See Github issue\n",
      "+   * https://github.com/apache/accumulo/issues/961\n",
      "+   */\n",
      "+  @Test\n",
      "+  public void testFailed() throws Exception {\n",
      "+    Path manyMaps = new Path(\"file://\" + root.getRoot().getAbsolutePath() + \"/manyMaps\");\n",
      "+    fs.create(new Path(manyMaps, SortedLogState.FAILED.getMarker())).close();\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Will other test see this file?\n",
      "```\n",
      "New code: \n",
      "```\n",
      "assertEquals(i, key.get());\n",
      " } reader.close();\n",
      "  assertTrue(fs.delete(new Path(manyMaps, SortedLogState.FAILED.getMarker())));\n",
      " } }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Discarded\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "private Gson buildGson() {\n",
      "return new GsonBuilder() <START> .setDateFormat(\"yyyy-MM-dd'T'HH:mm:ss.SSSZ\") <END> .registerTypeAdapter(Person.class, new Person.PersonSerializer()).create();\n",
      " }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "setting dateFormat is redundant\n",
      "```\n",
      "New code: \n",
      "```\n",
      "private Gson buildGson() {\n",
      "return new GsonBuilder() .registerTypeAdapter(Person.class, new Person.PersonSerializer()) .create();\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Discarded\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -76,7 +76,8 @@ public Files(SortedMap<StoredTabletFile,DataFileValue> allFiles,\n",
      "       var compactingFiles =\n",
      "           compacting.stream().flatMap(job -> job.getFiles().stream()).collect(Collectors.toSet());\n",
      "       Preconditions.checkArgument(this.allFiles.containsAll(compactingFiles),\n",
      "-          \"Compacting not in set of all files %s %s\", this.allFiles, compactingFiles);\n",
      "+          \"Compacting not in set of all files: %s, compacting files: %s\", this.allFiles,\n",
      "+          compactingFiles);\n",
      "```\n",
      "Review: \n",
      "```\n",
      "The message itself is still confusing to me. How about this? ```suggestion \"Compacting files %s not in set of all files: %s\", compactingFiles, this.allFiles); ```\n",
      "```\n",
      "New code: \n",
      "```\n",
      "var compactingFiles = compacting.stream().flatMap(job -> job.getFiles().stream()).collect(Collectors.toSet());\n",
      " Preconditions.checkArgument(this.allFiles.containsAll(compactingFiles), \"Compacting files %s not in set of all files: %s\", compactingFiles, this.allFiles);\n",
      " Preconditions.checkArgument(Collections.disjoint(compactingFiles, this.candidates), \"Compacting and candidates overlap %s %s\", compactingFiles, this.candidates);\n",
      "\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public boolean isSupportedArrayComponentType(Class<?> componentType) {\n",
      "<START> if (boolean.class == componentType) {\n",
      "<END> return true;\n",
      " } if (short.class == componentType) {\n",
      "return true;\n",
      " } if (int.class == componentType) {\n",
      "return true;\n",
      " } if (long.class == componentType) {\n",
      "return true;\n",
      " } if (double.class == componentType) {\n",
      "return true;\n",
      " } return false;\n",
      " }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "This would be easier to read if collapsed\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public boolean isSupportedArrayComponentType(Class<?> componentType) {\n",
      "return boolean.class == componentType || short.class == componentType || int.class == componentType || long.class == componentType || double.class == componentType;\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -192,14 +193,15 @@ public void when_serializerIsRegistered_then_itIsAvailableForLocalObservableSink\n",
      "         pipeline.readFrom(TestSources.items(1, 2))\n",
      "                 .map(Value::new)\n",
      "                 .writeTo(Sinks.observable(OBSERVABLE_NAME));\n",
      "+        long timeout = 120;\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Why not to simply inline it? Why 120?\n",
      "```\n",
      "New code: \n",
      "```\n",
      "pipeline.readFrom(TestSources.items(1, 2)) .map(Value::new) .writeTo(Sinks.observable(OBSERVABLE_NAME));\n",
      " // When Observable<Value> observable = client().getObservable(OBSERVABLE_NAME);\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Discarded\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public void postEvents(int id) throws Exception {\n",
      "final ServerDiscoverySelector eventReceiverSelector = factory.createSelector(EVENT_RECEIVER_SERVICE_PREFIX + id);\n",
      "eventReceiverSelector.start();\n",
      "try {\n",
      "ServerDiscoveryUtil.waitUntilInstanceReady(eventReceiverSelector, \"Event Receiver\");\n",
      "String host = config.getMiddleManagerHost() + \":\" + eventReceiverSelector.pick().getPort();\n",
      "LOG.info(\"Event Receiver Found at host [%s]\", host);\n",
      "LOG.info(\"Checking worker /status/health for [%s]\", host);\n",
      "<START> final StatusResponseHandler handler = StatusResponseHandler.getInstance();\n",
      "<END> RetryUtil.retryUntilTrue( () -> {\n",
      "try {\n",
      "StatusResponseHolder response = httpClient.go( new Request(HttpMethod.GET, new URL(StringUtils.format(\"https://%s/status/health\", host))), handler ).get();\n",
      "return response.getStatus().equals(HttpResponseStatus.OK);\n",
      "} catch (Throwable e) {\n",
      "LOG.error(e, \"\");\n",
      "return false;\n",
      "} }, StringUtils.format(\"Checking /status/health for worker [%s]\", host) );\n",
      "LOG.info(\"Finished checking worker /status/health for [%s], success\", host);\n",
      "EventReceiverFirehoseTestClient client = new EventReceiverFirehoseTestClient( host, EVENT_RECEIVER_SERVICE_PREFIX + id, jsonMapper, httpClient, smileMapper );\n",
      "client.postEventsFromFile(UNION_DATA_FILE);\n",
      "} finally {\n",
      "eventReceiverSelector.stop();\n",
      "} }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "This variable is unnecessary now.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public void postEvents(int id) throws Exception {\n",
      "final ServerDiscoverySelector eventReceiverSelector = factory.createSelector(EVENT_RECEIVER_SERVICE_PREFIX + id);\n",
      "eventReceiverSelector.start();\n",
      "try {\n",
      "ServerDiscoveryUtil.waitUntilInstanceReady(eventReceiverSelector, \"Event Receiver\");\n",
      "String host = config.getMiddleManagerHost() + \":\" + eventReceiverSelector.pick().getPort();\n",
      "LOG.info(\"Event Receiver Found at host [%s]\", host);\n",
      "LOG.info(\"Checking worker /status/health for [%s]\", host);\n",
      "RetryUtil.retryUntilTrue( () -> {\n",
      "try {\n",
      "StatusResponseHolder response = httpClient.go( new Request(HttpMethod.GET, new URL(StringUtils.format(\"https://%s/status/health\", host))), StatusResponseHandler.getInstance() ).get();\n",
      "return response.getStatus().equals(HttpResponseStatus.OK);\n",
      "} catch (Throwable e) {\n",
      "LOG.error(e, \"\");\n",
      "return false;\n",
      "} }, StringUtils.format(\"Checking /status/health for worker [%s]\", host) );\n",
      "LOG.info(\"Finished checking worker /status/health for [%s], success\", host);\n",
      "EventReceiverFirehoseTestClient client = new EventReceiverFirehoseTestClient( host, EVENT_RECEIVER_SERVICE_PREFIX + id, jsonMapper, httpClient, smileMapper );\n",
      "client.postEventsFromFile(UNION_DATA_FILE);\n",
      "} finally {\n",
      "eventReceiverSelector.stop();\n",
      "} }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -107,7 +107,7 @@ private PrivateTransactionProcessor mockPrivateTxProcessor() {\n",
      " \n",
      "   private Enclave brokenMockEnclave() throws Exception {\n",
      "     Enclave mockEnclave = mock(Enclave.class);\n",
      "```\n",
      "Review: \n",
      "```\n",
      "throws Exception shouldn't be needed now it's throwing the runtime EnclaveException\n",
      "```\n",
      "New code: \n",
      "```\n",
      "return mockPrivateTransactionProcessor;\n",
      " } private Enclave brokenMockEnclave() {\n",
      "Enclave mockEnclave = mock(Enclave.class);\n",
      " when(mockEnclave.receive(any(ReceiveRequest.class))).thenThrow(EnclaveException.class);\n",
      " return mockEnclave;\n",
      " } @Before public void setUp() {\n",
      "WorldStateArchive worldStateArchive;\n",
      " worldStateArchive = mock(WorldStateArchive.class);\n",
      " MutableWorldState mutableWorldState = mock(MutableWorldState.class);\n",
      "\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -163,11 +163,19 @@ public void changeAuthorizations(String user, Authorizations authorizations) thr\n",
      " \n",
      "   @Override\n",
      "   public boolean isValidAuthorizations(String user, List<ByteBuffer> auths) throws AccumuloSecurityException {\n",
      "-    Collection<ByteBuffer> userauths = getCachedUserAuthorizations(user).getAuthorizationsBB();\n",
      "-    for (ByteBuffer auth : auths)\n",
      "-      if (!userauths.contains(auth))\n",
      "+    if (auths.size() == 0) {\n",
      "```\n",
      "Review: \n",
      "```\n",
      "You should call `.isEmpty()`\n",
      "```\n",
      "New code: \n",
      "```\n",
      "@Override public boolean isValidAuthorizations(String user, List<ByteBuffer> auths) throws AccumuloSecurityException {\n",
      "if (auths.isEmpty()) {\n",
      "// avoid deserializing auths from ZK cache return true;\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public FileStructureView(NodeFactory nodeFactory) {\n",
      "this.nodeFactory = nodeFactory;\n",
      " NodeStorage storage = new NodeStorage( <START> new NodeUniqueKeyProvider() {\n",
      "<END> @Override public String getKey(@NotNull Node item) {\n",
      "return String.valueOf(item.hashCode());\n",
      " } });\n",
      " NodeLoader loader = new NodeLoader(Collections.<NodeInterceptor>emptySet());\n",
      " tree = new FileStructureTree(storage, loader);\n",
      " UI_BINDER.createAndBindUi(this);\n",
      " tree.setAutoExpand(false);\n",
      " tree.getSelectionModel().setSelectionMode(SINGLE);\n",
      " }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "can be changed to lambda\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public FileStructureView(NodeFactory nodeFactory) {\n",
      "this.nodeFactory = nodeFactory;\n",
      " NodeStorage storage = new NodeStorage(item->String.valueOf(item.hashCode()));\n",
      " NodeLoader loader = new NodeLoader(Collections.<NodeInterceptor>emptySet());\n",
      " tree = new FileStructureTree(storage, loader);\n",
      " UI_BINDER.createAndBindUi(this);\n",
      " tree.setAutoExpand(false);\n",
      " tree.getSelectionModel().setSelectionMode(SINGLE);\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public Map<String, Object> perform() {\n",
      "ArrayList<Map<String, String>> list = null;\n",
      " Map<String, Object> results = new HashMap<String, Object>(2);\n",
      " int totalItemCount = 0;\n",
      " List<User> users = null;\n",
      " int realUserCount = 0;\n",
      " try {\n",
      "totalItemCount = getUserCount();\n",
      " if (start < totalItemCount) {\n",
      "users = getUsers();\n",
      " realUserCount = users.size();\n",
      " } if (users != null) {\n",
      "int pageSize = realUserCount;\n",
      " list = new ArrayList<Map<String, String>>(pageSize);\n",
      " for (User aUser : users) {\n",
      "Map<String, String> aRecord = new HashMap<String, String>();\n",
      " String fullName = aUser.getFullName();\n",
      " fullName = (UtilMethods.isSet(fullName) ? fullName : \" \");\n",
      " String emailAddress = aUser.getEmailAddress();\n",
      " emailAddress = (UtilMethods.isSet(emailAddress) ? emailAddress : \" \");\n",
      " <START> aRecord.put(\"id\", aUser.getUserId());\n",
      " <END> aRecord.put(\"type\", USER_TYPE_VALUE);\n",
      " aRecord.put(\"name\", fullName);\n",
      " aRecord.put(\"emailaddress\", emailAddress);\n",
      " list.add(aRecord);\n",
      " } } else {\n",
      "list = new ArrayList<Map<String, String>>(0);\n",
      " } } catch (Exception ex) {\n",
      "Logger.warn(UserAjax.class, \"::processUsersList -> Could not process list of users.\");\n",
      " list = new ArrayList<Map<String, String>>(0);\n",
      " } results.put(\"data\", list);\n",
      " results.put(\"total\", totalItemCount);\n",
      " return results;\n",
      " }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "You can reduce this to map(\"id\", aUser.getUserId(), \"type\", USER_TYPE_VALUE ....) from CollectionUtils.map\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public Map<String, Object> perform() {\n",
      "ArrayList<Map<String, String>> list = null;\n",
      " Map<String, Object> results = new HashMap<String, Object>(2);\n",
      " int totalItemCount = 0;\n",
      " List<User> users = null;\n",
      " int realUserCount = 0;\n",
      " try {\n",
      "totalItemCount = getUserCount();\n",
      " if (start < totalItemCount) {\n",
      "users = getUsers();\n",
      " realUserCount = users.size();\n",
      " } if (users != null) {\n",
      "int pageSize = realUserCount;\n",
      " list = new ArrayList<Map<String, String>>(pageSize);\n",
      " for (User aUser : users) {\n",
      "final Map<String, String> aRecord = map( \"id\", aUser.getUserId(), \"type\", USER_TYPE_VALUE, \"name\", UtilMethods.isSet(aUser.getFullName()) ? aUser.getFullName() : \" \", \"emailaddress\", UtilMethods.isSet(aUser.getEmailAddress()) ? aUser.getEmailAddress() : \" \");\n",
      " list.add(aRecord);\n",
      " } } else {\n",
      "list = EMPTY_MAP_LIST;\n",
      " } } catch (Exception ex) {\n",
      "Logger.warn(UserAjax.class, \"::processUsersList -> Could not process list of users.\");\n",
      " list = new ArrayList<Map<String, String>>(0);\n",
      " } results.put(\"data\", list);\n",
      " results.put(\"total\", totalItemCount);\n",
      " return results;\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\n",
      "String requestUri = request.getRequestURI();\n",
      "logger.debug(\"Starting execution of proxy request for {}\", requestUri);\n",
      "SiteContext siteContext = SiteContext.getCurrent();\n",
      "if (siteContext == null) {\n",
      "throw new IllegalStateException(\"Can't resolve site context for current request\");\n",
      "} String siteName = siteContext.getSiteName();\n",
      "logger.debug(\"Resolved site {} for proxy request {}\", siteName, requestUri);\n",
      "String targetUrl = getTargetUrl(siteContext, requestUri);\n",
      "logger.debug(\"Resolved target url {} for proxy request {}\", targetUrl, requestUri);\n",
      "if (request.getRequestURL().toString().contains(targetUrl)) {\n",
      "logger.debug(\"Resolved target url for request {} is local, will skip proxy\", requestUri);\n",
      "<START> throw new HttpProxyException(\"Local target url detected\");\n",
      "<END> } request.setAttribute(ATTR_TARGET_URI, targetUrl);\n",
      "request.setAttribute(ATTR_TARGET_HOST, URIUtils.extractHost(URI.create(targetUrl)));\n",
      "super.service(request, response);\n",
      "}\n",
      "```\n",
      "Review: \n",
      "```\n",
      "I think it might be better to use another exception specific to this case, something like LocalTargetUrlProxyException.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "protected void service(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException {\n",
      "String requestUri = request.getRequestURI();\n",
      "logger.debug(\"Starting execution of proxy request for {}\", requestUri);\n",
      "SiteContext siteContext = SiteContext.getCurrent();\n",
      "if (siteContext == null) {\n",
      "throw new IllegalStateException(\"Can't resolve site context for current request\");\n",
      "} String siteName = siteContext.getSiteName();\n",
      "logger.debug(\"Resolved site {} for proxy request {}\", siteName, requestUri);\n",
      "String targetUrl = getTargetUrl(siteContext, requestUri);\n",
      "logger.debug(\"Resolved target url {} for proxy request {}\", targetUrl, requestUri);\n",
      "if (request.getRequestURL().toString().contains(targetUrl)) {\n",
      "logger.debug(\"Resolved target url for request {} is local, will skip proxy\", requestUri);\n",
      "throw new LocalTargetUrlProxyException(\"Local target url detected\");\n",
      "} request.setAttribute(ATTR_TARGET_URI, targetUrl);\n",
      "request.setAttribute(ATTR_TARGET_HOST, URIUtils.extractHost(URI.create(targetUrl)));\n",
      "super.service(request, response);\n",
      "}\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -280,9 +280,14 @@ private void doWaitTransfer() {\n",
      "                 if (!this.requestsRead.isEmpty()) {\n",
      "                     for (CommitLog.GroupCommitRequest req : this.requestsRead) {\n",
      "                         boolean transferOK = HAService.this.push2SlaveMaxOffset.get() >= req.getNextOffset();\n",
      "-                        for (int i = 0; !transferOK && i < 5; i++) {\n",
      "+                        long waitUntillWhen = HAService.this.defaultMessageStore.getSystemClock().now()\n",
      "+                            + HAService.this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout();\n",
      "+                        while (HAService.this.defaultMessageStore.getSystemClock().now() < waitUntillWhen) {\n",
      "```\n",
      "Review: \n",
      "```\n",
      "you should check transferok to reduce unnecessary block\n",
      "```\n",
      "New code: \n",
      "```\n",
      "boolean transferOK = HAService.this.push2SlaveMaxOffset.get() >= req.getNextOffset();\n",
      " long waitUntillWhen = HAService.this.defaultMessageStore.getSystemClock().now() + HAService.this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout();\n",
      " while (!transferOK && HAService.this.defaultMessageStore.getSystemClock().now() < waitUntillWhen) {\n",
      "this.notifyTransferObject.waitForRunning(1000);\n",
      " transferOK = HAService.this.push2SlaveMaxOffset.get() >= req.getNextOffset();\n",
      " } if (!transferOK) {\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -201,7 +201,7 @@ public void test() throws Exception {\n",
      "                 \"ifnull\", \"least\", \"link-schema\", \"lock-mode\", \"lock-timeout\",\n",
      "                 \"memory-free\", \"memory-used\", \"nextval\", \"nullif\", \"nvl2\",\n",
      "                 \"readonly\", \"rownum\", \"schema\", \"scope-identity\", \"session-id\",\n",
      "-                \"set\", \"table\", \"transaction-id\", \"truncate-value\", \"unnest\", \"user\" }) {\n",
      "+                \"set\", \"table\", \"transaction-id\", \"truncate-value\", \"unnest\", \"user\", \"last-insert-id\" }) {\n",
      "```\n",
      "Review: \n",
      "```\n",
      "This list is sorted alphabetically.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "\"cast\", \"coalesce\", \"convert\", \"csvread\", \"csvwrite\", \"currval\", \"database-path\", \"database\", \"decode\", \"disk-space-used\", \"file-read\", \"file-write\", \"greatest\", \"h2version\", \"identity\", \"ifnull\", \"last-insert-id\", \"least\", \"link-schema\", \"lock-mode\", \"lock-timeout\", \"memory-free\", \"memory-used\", \"nextval\", \"nullif\", \"nvl2\", \"readonly\", \"rownum\", \"schema\", \"scope-identity\", \"session-id\", \"set\", \"table\", \"transaction-id\", \"truncate-value\", \"unnest\", \"user\" }) {\n",
      "testScript(\"functions/system/\" + s + \".sql\");\n",
      " } for (String s : new String[] {\n",
      "\"add_months\", \"current_date\", \"current_timestamp\",\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -274,39 +274,46 @@ private void finishDeploy(SingularityRequestWithState requestWithState, Optional\n",
      " \n",
      "     if (deploy.isPresent() && deploy.get().getRunImmediately().isPresent()) {\n",
      "       String requestId = deploy.get().getRequestId();\n",
      "-      String deployId = deploy.get().getId();\n",
      "-      long timestamp = deployResult.getTimestamp();\n",
      "       SingularityRunNowRequest runNowRequest = deploy.get().getRunImmediately().get();\n",
      "-      Optional<String> runId = runNowRequest.getRunId().or(Optional.of(UUID.randomUUID().toString()));\n",
      "-      Optional<String> message = runNowRequest.getMessage()\n",
      "-          .or(pendingDeploy.getDeployMarker().getMessage());\n",
      "-      Optional<String> user = pendingDeploy.getDeployMarker().getUser();\n",
      "-      Optional<List<String>> commandLineArgs = runNowRequest.getCommandLineArgs();\n",
      "-      Optional<Boolean> skipHealthChecks = runNowRequest.getSkipHealthchecks().or(request.getSkipHealthchecks());\n",
      "-      Optional<Resources> resources = runNowRequest.getResources();\n",
      "       List<SingularityTaskId> activeTasks = taskManager.getActiveTaskIdsForRequest(requestId);\n",
      "       List<SingularityPendingTaskId> pendingTasks = taskManager.getPendingTaskIdsForRequest(requestId);\n",
      " \n",
      "+      SingularityPendingRequestBuilder builder = new SingularityPendingRequestBuilder()\n",
      "+          .setRequestId(requestId)\n",
      "+          .setDeployId(deploy.get().getId())\n",
      "+          .setTimestamp(deployResult.getTimestamp())\n",
      "+          .setUser(pendingDeploy.getDeployMarker().getUser())\n",
      "+          .setCmdLineArgsList(runNowRequest.getCommandLineArgs())\n",
      "+          .setRunId(runNowRequest.getRunId().or(Optional.of(UUID.randomUUID().toString())))\n",
      "+          .setSkipHealthchecks(runNowRequest.getSkipHealthchecks().or(request.getSkipHealthchecks()))\n",
      "+          .setMessage(runNowRequest.getMessage()\n",
      "+              .or(pendingDeploy.getDeployMarker().getMessage()))\n",
      "+          .setResources(runNowRequest.getResources())\n",
      "+          .setEnvOverrides(runNowRequest.getEnvOverrides())\n",
      "+          .setRunAt(runNowRequest.getRunAt());\n",
      "+\n",
      "+      PendingType pendingType = null;\n",
      "       if (request.isScheduled()) {\n",
      "         if (activeTasks.isEmpty()) {\n",
      "-          PendingType pendingType = canceledOr(deployResult.getDeployState(), PendingType.IMMEDIATE);\n",
      "-          requestManager.addToPendingQueue(new SingularityPendingRequest(requestId, deployId, timestamp, user, pendingType, commandLineArgs, runId, skipHealthChecks, message, Optional.absent(), resources, runNowRequest.getRunAt()));\n",
      "+          pendingType = PendingType.IMMEDIATE;\n",
      "         } else {\n",
      "           // Don't run scheduled task over a running task. Will be picked up on the next run.\n",
      "-          PendingType pendingType = canceledOr(deployResult.getDeployState(), PendingType.NEW_DEPLOY);\n",
      "-          requestManager.addToPendingQueue(new SingularityPendingRequest(requestId, deployId, timestamp, user, pendingType, commandLineArgs, runId, skipHealthChecks, message, Optional.absent(), resources, runNowRequest.getRunAt()));\n",
      "+          pendingType = PendingType.NEW_DEPLOY;\n",
      "         }\n",
      "       } else if (!request.isLongRunning()) {\n",
      "         if (request.getInstances().isPresent()\n",
      "             && (activeTasks.size() + pendingTasks.size() < request.getInstances().get())) {\n",
      "-          PendingType pendingType = canceledOr(deployResult.getDeployState(), PendingType.ONEOFF);\n",
      "-          requestManager.addToPendingQueue(new SingularityPendingRequest(requestId, deployId, timestamp, user, pendingType, commandLineArgs, runId, skipHealthChecks, message, Optional.absent(), resources, runNowRequest.getRunAt()));\n",
      "+          pendingType = PendingType.ONEOFF;\n",
      "         } else {\n",
      "           // Don't run one-off / on-demand task when already at instance count cap\n",
      "-          PendingType pendingType = canceledOr(deployResult.getDeployState(), PendingType.NEW_DEPLOY);\n",
      "-          requestManager.addToPendingQueue(new SingularityPendingRequest(requestId, deployId, timestamp, user, pendingType, commandLineArgs, runId, skipHealthChecks, message, Optional.absent(), resources, runNowRequest.getRunAt()));\n",
      "+          pendingType = PendingType.NEW_DEPLOY;\n",
      "         }\n",
      "       }\n",
      "+      if (pendingType != null) {\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Should we be handling the case where pendingType == null here?\n",
      "```\n",
      "New code: \n",
      "```\n",
      "if (deploy.isPresent() && deploy.get().getRunImmediately().isPresent()) {\n",
      "String requestId = deploy.get().getRequestId();\n",
      " String deployId = deploy.get().getId();\n",
      " SingularityRunNowRequest runNowRequest = deploy.get().getRunImmediately().get();\n",
      " List<SingularityTaskId> activeTasks = taskManager.getActiveTaskIdsForRequest(requestId);\n",
      " List<SingularityPendingTaskId> pendingTasks = taskManager.getPendingTaskIdsForRequest(requestId);\n",
      " SingularityPendingRequestBuilder builder = new SingularityPendingRequestBuilder() .setRequestId(requestId) .setDeployId(deployId) .setTimestamp(deployResult.getTimestamp()) .setUser(pendingDeploy.getDeployMarker().getUser()) .setCmdLineArgsList(runNowRequest.getCommandLineArgs())\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -152,25 +153,57 @@ private String getLines(SlotsLines lines) {\n",
      "   private String getSingleSlotHtml(TestSlot s, String icon) {\n",
      "     StringBuilder builder = new StringBuilder();\n",
      "     TestSession session = s.getSession();\n",
      "+    String htmlClass = \"\";\n",
      "+    String title = s.getCapabilities().toString();\n",
      "+    String imgSrc = icon;\n",
      "+    String browserName = s.getCapabilities().get(CapabilityType.BROWSER_NAME).toString().toLowerCase();\n",
      "+\n",
      "+    if (browserName.contains(BrowserType.GOOGLECHROME) || browserName.contains(BrowserType.CHROME))\n",
      "+      if (!s.isGoogleChromeAvailable()) {\n",
      "+        htmlClass += \"browserNotAvailable \";\n",
      "+        imgSrc = imgSrc.split(\".png\")[0].concat(\"_unavailable.png\");\n",
      "+        title = \"browser not available\";\n",
      "```\n",
      "Review: \n",
      "```\n",
      "mentioned in IRC to change wording here and the 3 others below\n",
      "```\n",
      "New code: \n",
      "```\n",
      "if (!s.isGoogleChromeAvailable()) {\n",
      "htmlClass += \"browserNotAvailable \";\n",
      " imgSrc = imgSrc.split(\".png\")[0].concat(\"_unavailable.png\");\n",
      " title = \"browser not installed / found\";\n",
      " } else {\n",
      "htmlClass += \"browserAvailable \";\n",
      " } else if (browserName.contains(BrowserType.IE) || browserName.contains(BrowserType.IEXPLORE)) if (!s.isInternetExplorerAvailable()) {\n",
      "htmlClass += \"browserNotAvailable \";\n",
      " imgSrc = imgSrc.split(\".png\")[0].concat(\"_unavailable.png\");\n",
      " title = \"browser not installed / found\";\n",
      " } else {\n",
      "htmlClass += \"browserAvailable \";\n",
      " } else if (browserName.contains(BrowserType.FIREFOX) || browserName.contains(BrowserType.FIREFOX_2)\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public void testBuildBlobId() throws Exception {\n",
      "BlobId blobId = new BlobId(version, referenceType, referenceDatacenterId, referenceAccountId, referenceContainerId, referencePartitionId, referenceIsEncrypted);\n",
      "<START> System.out.println(blobId.getID());\n",
      "<END> assertEquals(\"Wrong blobId version\", version, getVersionFromBlobString(blobId.getID()));\n",
      "assertBlobIdFieldValues(version, blobId, referenceType, referenceDatacenterId, referenceAccountId, referenceContainerId, referencePartitionId, referenceIsEncrypted);\n",
      "}\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Remove?\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public void testBuildBlobId() throws Exception {\n",
      "BlobId blobId = new BlobId(version, referenceType, referenceDatacenterId, referenceAccountId, referenceContainerId, referencePartitionId, referenceIsEncrypted);\n",
      "assertEquals(\"Wrong blobId version\", version, getVersionFromBlobString(blobId.getID()));\n",
      "assertBlobIdFieldValues(version, blobId, referenceType, referenceDatacenterId, referenceAccountId, referenceContainerId, referencePartitionId, referenceIsEncrypted);\n",
      "}\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Discarded\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -48,12 +48,14 @@\n",
      "   /**\n",
      "    * Store the assigned locations in the data store.\n",
      "    */\n",
      "-  void setFutureLocations(Collection<Assignment> assignments) throws DistributedStoreException;\n",
      "+  void setFutureLocations(Collection<Assignment> assignments);\n",
      " \n",
      "   /**\n",
      "    * Tablet servers will update the data store with the location when they bring the tablet online\n",
      "    */\n",
      "-  void setLocations(Collection<Assignment> assignments) throws DistributedStoreException;\n",
      "+  // void setLocations(Collection<Assignment> assignments) throws DistributedStoreException;\n",
      "+\n",
      "+  void setLocations(Assignment assignment, TServerInstance prevLastLoc);\n",
      "```\n",
      "Review: \n",
      "```\n",
      "```suggestion void setLocation(Assignment assignment, TServerInstance prevLastLoc); ```\n",
      "```\n",
      "New code: \n",
      "```\n",
      "/** * Store the assigned locations in the data store. */ void setFutureLocation(Assignment assignment);\n",
      " /** * Tablet servers will update the data store with the location when they bring the tablet online */ void setLocation(Assignment assignment, TServerInstance prevLastLoc);\n",
      " /** * Mark the tablets as having no known or future location.\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public static JsonParser enterPath(JsonParser parser, String path) throws IOException {\n",
      "if (!parser.isExpectedStartObjectToken()) return null;\n",
      " JsonToken value;\n",
      " while ((value = parser.nextValue()) != JsonToken.END_OBJECT) {\n",
      "if (value == null) {\n",
      "<START> throw new IOException(\"End of input while parsing object.\");\n",
      " <END> } if (parser.getCurrentName().equals(path) && value != JsonToken.VALUE_NULL) {\n",
      "return parser;\n",
      " } else {\n",
      "parser.skipChildren();\n",
      " } } return null;\n",
      " }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "our old code didn't throw I think, rather returned null\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public static JsonParser enterPath(JsonParser parser, String path) throws IOException {\n",
      "if (!parser.isExpectedStartObjectToken()) return null;\n",
      " JsonToken value;\n",
      " while ((value = parser.nextValue()) != JsonToken.END_OBJECT) {\n",
      "if (value == null) {\n",
      "return null;\n",
      " } if (parser.getCurrentName().equals(path) && value != JsonToken.VALUE_NULL) {\n",
      "return parser;\n",
      " } else {\n",
      "parser.skipChildren();\n",
      " } } return null;\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -172,7 +171,8 @@ public void initialize(NodeEngine nodeEngine, long jobId, long executionId, Snap\n",
      " \n",
      "                 ProbeBuilder probeBuilder = this.nodeEngine.getMetricsRegistry().newProbeBuilder()\n",
      "                         .withTag(\"module\", \"jet\")\n",
      "-                        .withTag(\"job\", idToString(jobId))\n",
      "+                        .withTag(\"job\", Long.toHexString(jobId))\n",
      "```\n",
      "Review: \n",
      "```\n",
      "it would be better to use idToString for readability and consistency with logs. Saving a few characters doesn't matter in this case.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "ProbeBuilder probeBuilder = this.nodeEngine.getMetricsRegistry().newProbeBuilder() .withTag(\"module\", \"jet\") .withTag(\"job\", idToString(jobId)) .withTag(\"exId\", idToString(executionId)) .withTag(\"vertex\", vertex.name());\n",
      " if (vertex.inboundEdges().size() == 0) {\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -0,0 +1,167 @@\n",
      "+/**\n",
      "+ * Licensed to the Apache Software Foundation (ASF) under one\n",
      "+ * or more contributor license agreements. See the NOTICE file\n",
      "+ * distributed with this work for additional information\n",
      "+ * regarding copyright ownership. The ASF licenses this file\n",
      "+ * to you under the Apache License, Version 2.0 (the\n",
      "+ * \"License\"); you may not use this file except in compliance\n",
      "+ * with the License. You may obtain a copy of the License at\n",
      "+ *\n",
      "+ * http://www.apache.org/licenses/LICENSE-2.0\n",
      "+ *\n",
      "+ * Unless required by applicable law or agreed to in writing,\n",
      "+ * software distributed under the License is distributed on an\n",
      "+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n",
      "+ * KIND, either express or implied. See the License for the\n",
      "+ * specific language governing permissions and limitations\n",
      "+ * under the License.\n",
      "+ */\n",
      "+package org.apache.fineract.integrationtests;\n",
      "+import java.math.BigDecimal;\n",
      "+import java.util.ArrayList;\n",
      "+import java.util.List;\n",
      "+import org.apache.fineract.accounting.closure.command.GLClosureCommand;\n",
      "+import org.apache.fineract.accounting.closure.data.IncomeAndExpenseBookingData;\n",
      "+import org.apache.fineract.accounting.closure.data.IncomeAndExpenseJournalEntryData;\n",
      "+import org.apache.fineract.accounting.closure.exception.RunningBalanceNotCalculatedException;\n",
      "+import org.apache.fineract.accounting.closure.service.CalculateIncomeAndExpenseBookingImpl;\n",
      "+import org.apache.fineract.accounting.closure.service.IncomeAndExpenseReadPlatformService;\n",
      "+import org.apache.fineract.organisation.office.service.OfficeReadPlatformService;\n",
      "+import org.joda.time.LocalDate;\n",
      "+import org.junit.After;\n",
      "+import org.junit.Assert;\n",
      "+import org.junit.Before;\n",
      "+import org.junit.Test;\n",
      "+import org.junit.runner.RunWith;\n",
      "+import org.mockito.InjectMocks;\n",
      "+import org.mockito.Mock;\n",
      "+import org.mockito.runners.MockitoJUnitRunner;\n",
      "+\n",
      "+@RunWith(MockitoJUnitRunner.class)\n",
      "+public class CalculateIncomeAndExpanseBookingIntegrationTest {\n",
      "+    /*\n",
      "+    Test class CalculateIncomeAndExpenseBookingImpl\n",
      "+     */\n",
      "+    @Mock private JsonCommandWrapperTest jsonCommandWrapperTest;\n",
      "+    @Mock private IncomeAndExpenseReadPlatformService incomeAndExpenseReadPlatformService;\n",
      "+    @Mock private OfficeReadPlatformService officeReadPlatformService;\n",
      "+\n",
      "+    @InjectMocks\n",
      "+    private CalculateIncomeAndExpenseBookingImpl calculateIncomeAndExpenseBooking;\n",
      "+\n",
      "+    @Before\n",
      "+    public void setup() {\n",
      "+        calculateIncomeAndExpenseBooking =  new CalculateIncomeAndExpenseBookingImpl(null, null, null, null, incomeAndExpenseReadPlatformService,officeReadPlatformService);\n",
      "+     }\n",
      "+\n",
      "+    @After\n",
      "+    public void tearDown() {\n",
      "+\n",
      "+    }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "remove this empty method: ```suggestion ```\n",
      "```\n",
      "New code: \n",
      "```\n",
      "calculateIncomeAndExpenseBooking =  new CalculateIncomeAndExpenseBookingImpl(null, null, null, null, incomeAndExpenseReadPlatformService,officeReadPlatformService);\n",
      " } /* Case 1: All running balances has to be calculated before booking off income and expense account If not running balances, then throw exception\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -275,20 +316,60 @@ protected void onAuthCookieAcquired(String authCookie) {\n",
      "         isMultipleUploadsPrepared = false;\n",
      "         mwApi.setAuthCookie(authCookie);\n",
      "         if (!ExternalStorageUtils.isStoragePermissionGranted(this)) {\n",
      "-            ExternalStorageUtils.requestExternalStoragePermission(this);\n",
      "+            //If permission is not there, handle the negative cases\n",
      "+            askDexterToHandleExternalStoragePermission();\n",
      "             isMultipleUploadsPrepared = false;\n",
      "             return; // Postpone operation to do after gettion permission\n",
      "         } else {\n",
      "             isMultipleUploadsPrepared = true;\n",
      "-            prepareMultipleUpoadList();\n",
      "+            prepareMultipleUploadList();\n",
      "+        }\n",
      "+    }\n",
      "+\n",
      "+    private void askDexterToHandleExternalStoragePermission() {\n",
      "+        Timber.d(TAG, \"External storage permission is being requested\");\n",
      "+        if (null == dexterStoragePermissionBuilder) {\n",
      "+            dexterStoragePermissionBuilder = Dexter.withActivity(this)\n",
      "+                    .withPermission(permission.WRITE_EXTERNAL_STORAGE)\n",
      "+                    .withListener(new BasePermissionListener() {\n",
      "+                        @Override\n",
      "+                        public void onPermissionGranted(PermissionGrantedResponse response) {\n",
      "+                            Timber.d(TAG,\n",
      "+                                    \"User has granted us the permission for writing the external storage\");\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Please don't split this line, it does not improve readability. :)\n",
      "```\n",
      "New code: \n",
      "```\n",
      "} } /** * This method initialised the Dexter's permission builder (if not already initialised). Also makes sure that the builder is initialised * only once, otherwise we would'nt know on which instance of it, the user is working on. And after the builder is initialised, it checks for the required * permission and then handles the permission status, thanks to Dexter's appropriate callbacks. */ private void askDexterToHandleExternalStoragePermission() {\n",
      "Timber.d(TAG, \"External storage permission is being requested\");\n",
      " if (null == dexterStoragePermissionBuilder) {\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "<START> protected JaxbListWrapper<OnmsIpInterface> createListWrapper(Collection<OnmsIpInterface> list) {\n",
      "<END> return new OnmsIpInterfaceList(list);\n",
      "}\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Should be final.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "protected final JaxbListWrapper<OnmsIpInterface> createListWrapper(Collection<OnmsIpInterface> list) {\n",
      "return new OnmsIpInterfaceList(list);\n",
      "}\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -42,7 +44,11 @@ public void execute(CommandContext commandContext, PlanItemInstanceEntity planIt\n",
      "             Expression expressionObject = CommandContextUtil.getCmmnEngineConfiguration(commandContext).getExpressionManager().createExpression(expression);\n",
      "             value = expressionObject.getValue(planItemInstanceEntity);\n",
      "             if (resultVariable != null) {\n",
      "-                planItemInstanceEntity.setVariable(resultVariable, value);\n",
      "+                if(storeResultVariableAsTransient) {\n",
      "```\n",
      "Review: \n",
      "```\n",
      "missing space \"if (\"\n",
      "```\n",
      "New code: \n",
      "```\n",
      "Expression expressionObject = CommandContextUtil.getCmmnEngineConfiguration(commandContext).getExpressionManager().createExpression(expression);\n",
      " value = expressionObject.getValue(planItemInstanceEntity);\n",
      " if (resultVariable != null) {\n",
      "if (storeResultVariableAsTransient) {\n",
      "planItemInstanceEntity.setTransientVariable(resultVariable, value);\n",
      " } else {\n",
      "planItemInstanceEntity.setVariable(resultVariable, value);\n",
      "\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "private <T extends Timestamped> T deserialize(StorageObject object, Class<T> clas, boolean current_version) throws java.io.UnsupportedEncodingException {\n",
      "try {\n",
      "ByteArrayOutputStream output = new java.io.ByteArrayOutputStream();\n",
      " Storage.Objects.Get getter = obj_api.get(object.getBucket(), object.getName());\n",
      " if (!current_version) {\n",
      "getter.setGeneration(object.getGeneration());\n",
      " } Closure timeExecuteClosure = new Closure<String>(this, this) {\n",
      "public Object doCall() throws Exception {\n",
      "mediaDownloadTimer.record(new Callable() {\n",
      "public Void call() throws Exception {\n",
      "getter.executeMediaAndDownloadTo(output);\n",
      " return null;\n",
      " } });\n",
      " return Closure.DONE;\n",
      " } };\n",
      " doRetry(timeExecuteClosure, \"deserialize\", object.getName());\n",
      " String json = output.toString(\"UTF8\");\n",
      " return objectMapper.readValue(json, clas);\n",
      " } catch (Exception ex) {\n",
      "if (current_version) {\n",
      "log.error(\"Error reading {}: {}\", value(\"object\", object.getName()), ex.getMessage());\n",
      " } else {\n",
      "log.error(\"Error reading {} generation={}: {}\", value(\"object\", object.getName()), value(\"generation\", object.getGeneration()), <START> ex.getMessage());\n",
      " <END> } return null;\n",
      " } }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Since we don't rethrow here, is it maybe valuable to print more than the message and include the stack trace?\n",
      "```\n",
      "New code: \n",
      "```\n",
      "private <T extends Timestamped> T deserialize(StorageObject object, Class<T> clas, boolean current_version) throws java.io.UnsupportedEncodingException {\n",
      "try {\n",
      "ByteArrayOutputStream output = new java.io.ByteArrayOutputStream();\n",
      " Storage.Objects.Get getter = obj_api.get(object.getBucket(), object.getName());\n",
      " if (!current_version) {\n",
      "getter.setGeneration(object.getGeneration());\n",
      " } Closure timeExecuteClosure = new Closure<String>(this, this) {\n",
      "public Object doCall() throws Exception {\n",
      "mediaDownloadTimer.record(new Callable() {\n",
      "public Void call() throws Exception {\n",
      "getter.executeMediaAndDownloadTo(output);\n",
      " return null;\n",
      " } });\n",
      " return Closure.DONE;\n",
      " } };\n",
      " doRetry(timeExecuteClosure, \"deserialize\", object.getName());\n",
      " String json = output.toString(\"UTF8\");\n",
      " return objectMapper.readValue(json, clas);\n",
      " } catch (Exception ex) {\n",
      "if (current_version) {\n",
      "log.error(\"Error reading {}: \", value(\"object\", object.getName()), ex);\n",
      " } else {\n",
      "log.error(\"Error reading {} generation={}: \", value(\"object\", object.getName()), value(\"generation\", object.getGeneration()), ex);\n",
      " } return null;\n",
      " } }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -259,6 +256,52 @@ public CompilationUnit parse(String startPackage, String filename) {\n",
      "         }\n",
      "     }\n",
      " \n",
      "+    private FileVisitResult callback(Path absolutePath, ParserConfiguration configuration, Callback callback) throws IOException {\n",
      "+        if (!Files.exists(absolutePath)) {\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Should this happen?\n",
      "```\n",
      "New code: \n",
      "```\n",
      "} private FileVisitResult callback(Path absolutePath, ParserConfiguration configuration, Callback callback) throws IOException {\n",
      "Path localPath = root.relativize(absolutePath);\n",
      " Log.trace(\"Parsing %s\", localPath);\n",
      " ParseResult<CompilationUnit> result = new JavaParser(configuration).parse(COMPILATION_UNIT, provider(absolutePath));\n",
      "\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Discarded\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public void testRebalance() throws IOException, HelixRebalanceException, JMException {\n",
      "_metadataStore.clearMetadataStore();\n",
      " <START> WagedRebalancer rebalancer = new WagedRebalancer(_metadataStore, _algorithm, null);\n",
      " <END> ResourceControllerDataProvider clusterData = setupClusterDataCache();\n",
      " Map<String, Resource> resourceMap = clusterData.getIdealStates().entrySet().stream() .collect(Collectors.toMap(entry -> entry.getKey(), entry -> {\n",
      "Resource resource = new Resource(entry.getKey());\n",
      " entry.getValue().getPartitionSet().stream() .forEach(partition -> resource.addPartition(partition));\n",
      " return resource;\n",
      " }));\n",
      " Map<String, IdealState> newIdealStates = rebalancer.computeNewIdealStates(clusterData, resourceMap, new CurrentStateOutput());\n",
      " Map<String, ResourceAssignment> algorithmResult = _algorithm.getRebalanceResult();\n",
      " validateRebalanceResult(resourceMap, newIdealStates, algorithmResult);\n",
      " }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Not sure about all the usage, but if all test code is passing null, we can just remove this parameter from this constructor.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public void testRebalance() throws IOException, HelixRebalanceException {\n",
      "_metadataStore.clearMetadataStore();\n",
      " WagedRebalancer rebalancer = new WagedRebalancer(_metadataStore, _algorithm, new DelayedAutoRebalancer());\n",
      " ResourceControllerDataProvider clusterData = setupClusterDataCache();\n",
      " Map<String, Resource> resourceMap = clusterData.getIdealStates().entrySet().stream() .collect(Collectors.toMap(entry -> entry.getKey(), entry -> {\n",
      "Resource resource = new Resource(entry.getKey());\n",
      " entry.getValue().getPartitionSet().stream() .forEach(partition -> resource.addPartition(partition));\n",
      " return resource;\n",
      " }));\n",
      " Map<String, IdealState> newIdealStates = rebalancer.computeNewIdealStates(clusterData, resourceMap, new CurrentStateOutput());\n",
      " Map<String, ResourceAssignment> algorithmResult = _algorithm.getRebalanceResult();\n",
      " validateRebalanceResult(resourceMap, newIdealStates, algorithmResult);\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Discarded\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -124,6 +137,9 @@ public void setLoadData(LoadData loadData) {\n",
      " \n",
      "     @Override\n",
      "     public int hashCode() {\n",
      "+        if (LoadDataBatch.getInstance().isEnableBatchLoadData() && !Objects.isNull(loadData) && !Strings.isNullOrEmpty(loadData.getFileName())) {\n",
      "```\n",
      "Review: \n",
      "```\n",
      "maybe cause problems in some hashmap. for example, two object A and B, which A equals B, but A.hashCode() not equals B.hashCode().\n",
      "```\n",
      "New code: \n",
      "```\n",
      "@Override public int hashCode() {\n",
      "return name.hashCode();\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -689,38 +707,42 @@ private void markMetaChanged() {\n",
      " \n",
      "     private void readStoreHeader() {\n",
      "         Chunk newest = null;\n",
      "-        boolean assumeCleanShutdown = true;\n",
      "+        // We only need to check the validity of recent chunks for calling sync() \n",
      "+        // after writeStoreHeader() in the method storeNow().\n",
      "+        // @since 2019-08-09 little-pan\n",
      "+        final Chunk[] lastCandidates = new Chunk[SYNC_MAX_DIFF + 2/* last + new chunk(maybe write header failed)*/];\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Please do not use \"final\" to qualify method variables, contrary to the style of this code base, unless it is used in anonymous inner class. This does not contribute much to code readability.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "// We only need to check the validity of recent chunks for calling sync() // after writeStoreHeader() in the method storeNow(). // @since 2019-08-09 little-pan Chunk[] lastCandidates = new Chunk[SYNC_MAX_DIFF + 2/* last + new chunk(maybe write header failed)*/];\n",
      " // find out which chunk and version are the newest, and as the last chunk // Step-1: read the newest chunk from the first two blocks(file header)\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -59,6 +60,7 @@\n",
      "  */\n",
      " @Configuration\n",
      " @EnableConfigurationProperties(ZipkinUiProperties.class)\n",
      "+@ConditionalOnProperty(value = \"zipkin.ui.enabled\", havingValue = \"true\", matchIfMissing = true)\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Nits: `name` might be more clear than `value` (which is an alias for `name`). Maybe it is just me but `value = x, havingValue = y` reads kind of funny. Also, the default of `havingValue` should be sufficient for our purposes. Specifying `\"true\"` might mean something like `\"TRUE\"` doesn't work.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "*/ @Configuration @EnableConfigurationProperties(ZipkinUiProperties.class) @ConditionalOnProperty(name = \"zipkin.ui.enabled\", matchIfMissing = true) @RestController public class ZipkinUiAutoConfiguration extends WebMvcConfigurerAdapter {\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -48,17 +48,19 @@\n",
      "  * Compression related stuff.\n",
      "  */\n",
      " public final class Compression {\n",
      "-  static final Logger log = LoggerFactory.getLogger(Compression.class);\n",
      "+\n",
      "+  private static final Logger LOG = LoggerFactory.getLogger(Compression.class);\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Keeping `log` as lower case would be consistent with other Accumulo code.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "*/ public final class Compression {\n",
      "private static final Logger log = LoggerFactory.getLogger(Compression.class);\n",
      " /** * Prevent the instantiation of this class.\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public final LogResult postLog(final Geocache cache, final LogType logType, final Calendar date, final String log, final String logPassword, final List<TrackableLog> trackableLogs) {\n",
      "<START> final LogResult result = ECApi.postLog(cache, logType, date, log);\n",
      "<END> return result;\n",
      "}\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Please do not create useless variables, it is more readable if you directly use:  java return ECApi.postLog(cache, logType, date, log);\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public final LogResult postLog(final Geocache cache, final LogType logType, final Calendar date, final String log, final String logPassword, final List<TrackableLog> trackableLogs) {\n",
      "return ECApi.postLog(cache, logType, date, log);\n",
      "}\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public void resolvePropertiesNotSetAndOverrideTrue() {\n",
      "<START> Map<String, String> originalProperties = new HashMap<>();\n",
      " <END> originalProperties.put(\"foo\", \"bar\");\n",
      " Map<String, String> resolvedProperties = cloudHubArtifactDeployer.resolveProperties(originalProperties, null, true);\n",
      " assertThat(\"originalProperties should have the same size\", resolvedProperties.size(), equalTo(1));\n",
      " assertThat(\"resolvedProperties should contains the (foo,bar) entry\", resolvedProperties, hasEntry(\"foo\", \"bar\"));\n",
      " }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Extract this to a setUp method in a test and make _originalProperties_ a field\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public void resolvePropertiesNotSetAndOverrideTrue() {\n",
      "Map<String, String> resolvedProperties = cloudHubArtifactDeployer.resolveProperties(originalProperties, null, true);\n",
      " assertThat(\"originalProperties should have the same size\", resolvedProperties.size(), equalTo(1));\n",
      " assertThat(\"resolvedProperties should contains the (foo,bar) entry\", resolvedProperties, hasEntry(\"foo\", \"bar\"));\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public void dispose() {\n",
      "phone.mCM.unregisterForSIMLockedOrAbsent(this);\n",
      "phone.mCM.unregisterForOffOrNotAvailable(this);\n",
      "phone.mCM.unregisterForSIMReady(this);\n",
      "<START> this.removeCallbacksAndMessages(null);\n",
      "<END> this.absentRegistrants = null;\n",
      "this.pinLockedRegistrants = null;\n",
      "this.networkLockedRegistrants = null;\n",
      "this.status = null;\n",
      "this.phone = null;\n",
      "}\n",
      "```\n",
      "Review: \n",
      "```\n",
      "> Use this.removeCallbacksAndMessages(null) instead. Done in Patch set 2\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public void dispose() {\n",
      "phone.mCM.unregisterForSIMLockedOrAbsent(this);\n",
      "phone.mCM.unregisterForOffOrNotAvailable(this);\n",
      "phone.mCM.unregisterForSIMReady(this);\n",
      "}\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public LogicalPlanner(Session session, List<PlanOptimizer> planOptimizers, PlanSanityChecker planSanityChecker, PlanNodeIdAllocator idAllocator, Metadata metadata, SqlParser sqlParser, StatsCalculator statsCalculator, CostCalculator costCalculator) {\n",
      "requireNonNull(session, \"session is null\");\n",
      " requireNonNull(planOptimizers, \"planOptimizers is null\");\n",
      " requireNonNull(planSanityChecker, \"planSanityChecker is null\");\n",
      " requireNonNull(idAllocator, \"idAllocator is null\");\n",
      " requireNonNull(metadata, \"metadata is null\");\n",
      " requireNonNull(sqlParser, \"sqlParser is null\");\n",
      " <START> requireNonNull(statsCalculator, \"statsCalculator is null\");\n",
      " <END> requireNonNull(costCalculator, \"costCalculator is null\");\n",
      " this.session = session;\n",
      " this.planOptimizers = planOptimizers;\n",
      " this.planSanityChecker = planSanityChecker;\n",
      " this.idAllocator = idAllocator;\n",
      " this.metadata = metadata;\n",
      " this.sqlParser = sqlParser;\n",
      " this.statisticsAggregationPlanner = new StatisticsAggregationPlanner(symbolAllocator, metadata);\n",
      " this.statsCalculator = statsCalculator;\n",
      " this.costCalculator = costCalculator;\n",
      " }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Inline all the requireNonNulls in a separate commit\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public LogicalPlanner(Session session, List<PlanOptimizer> planOptimizers, PlanSanityChecker planSanityChecker, PlanNodeIdAllocator idAllocator, Metadata metadata, SqlParser sqlParser, StatsCalculator statsCalculator, CostCalculator costCalculator) {\n",
      "this.session = requireNonNull(session, \"session is null\");\n",
      " this.planOptimizers = requireNonNull(planOptimizers, \"planOptimizers is null\");\n",
      " this.planSanityChecker = requireNonNull(planSanityChecker, \"planSanityChecker is null\");\n",
      " this.idAllocator = requireNonNull(idAllocator, \"idAllocator is null\");\n",
      " this.metadata = requireNonNull(metadata, \"metadata is null\");\n",
      " this.sqlParser = requireNonNull(sqlParser, \"sqlParser is null\");\n",
      " this.statisticsAggregationPlanner = new StatisticsAggregationPlanner(symbolAllocator, metadata);\n",
      " this.statsCalculator = requireNonNull(statsCalculator, \"statsCalculator is null\");\n",
      " this.costCalculator = requireNonNull(costCalculator, \"costCalculator is null\");\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -304,6 +317,31 @@ public boolean isDseGraphEnabled() {\n",
      "     }\n",
      " \n",
      "     /**\n",
      "+     * Return the host id value for the host.\n",
      "+     * <p/>\n",
      "+     * The host id is the main identifier used by Cassandra on the server for internal\n",
      "+     * communication (gossip). It is referenced as the column {@code host_id} in the\n",
      "+     * {@code system.local} or {@code system.peers} table.\n",
      "+     *\n",
      "+     * @return the node's host id value.\n",
      "+     */\n",
      "+    public UUID getHostId() {\n",
      "+        return hostId;\n",
      "+    }\n",
      "+\n",
      "+    /**\n",
      "+     * Return the current schema version for the host.\n",
      "+     * <p/>\n",
      "+     * Schema versions in Cassandra are used to insure all the nodes agree on the current\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Small nit: `insure` should be `ensure`\n",
      "```\n",
      "New code: \n",
      "```\n",
      "/** * Return the current schema version for the host. * <p/> * Schema versions in Cassandra are used to ensure all the nodes agree on the current * Cassandra schema when it is modified. For more information see {@link ExecutionInfo#isSchemaInAgreement()} * * @return the node's current schema version value.\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -31,7 +31,7 @@\n",
      "   // TODO: Determine reasonable defaults here\n",
      "   public static final int DEFAULT_PIVOT_DISTANCE_FROM_HEAD = 500;\n",
      "   public static final float DEFAULT_FULL_VALIDATION_RATE = .1f;\n",
      "-  public static final int DEFAULT_FAST_SYNC_MINIMUM_PEERS = 5;\n",
      "+  public static final int DEFAULT_FAST_SYNC_MINIMUM_PEERS = 1;\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Is this a dev setting?\n",
      "```\n",
      "New code: \n",
      "```\n",
      "// TODO: Determine reasonable defaults here public static final int DEFAULT_PIVOT_DISTANCE_FROM_HEAD = 500;\n",
      " public static final float DEFAULT_FULL_VALIDATION_RATE = .1f;\n",
      " public static final int DEFAULT_FAST_SYNC_MINIMUM_PEERS = 5;\n",
      " private static final Duration DEFAULT_FAST_SYNC_MAXIMUM_PEER_WAIT_TIME = Duration.ofMinutes(5);\n",
      " private static final int DEFAULT_WORLD_STATE_HASH_COUNT_PER_REQUEST = 200;\n",
      " private static final int DEFAULT_WORLD_STATE_REQUEST_PARALLELISM = 10;\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public boolean hasAnyTicket(String username) {\n",
      "<START> Collection<Ticket> tickets = ticketRepository.findAllByOwnerUsername(username);\n",
      "<END> return tickets.stream().anyMatch(Ticket::isValid);\n",
      "}\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Then I would turn this in a one-liner.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public boolean hasAnyTicket(String username) {\n",
      "return ticketRepository.findAllByOwnerUsername(username).stream().anyMatch(Ticket::isValid);\n",
      "}\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public void slightlyOccupiedAABBTest() {\n",
      "Level check = new Level(emptyPlayer, emptyUnit, new Grid<>(Arrays.asList( Cell.WALL, Cell.WALL, Cell.WALL, Cell.WALL, Cell.EMPTY, Cell.WALL, Cell.WALL, Cell.WALL, Cell.WALL), 3, 3));\n",
      "CollisionHandler handler = new CollisionHandler(check);\n",
      "Cell cell = handler.checkLevelAABB( new AABB(new Point(1.5, 1.5), new Point(2.5, 2.5)), new Point(0, 0));\n",
      "<START> assertFalse(cell.getType() == Cell.EMPTY);\n",
      "<END> }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Use assertNotEquals instead of == operator combined with assertFalse, == does not work properly for non-objects. <testing\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public void slightlyOccupiedAABBTest() {\n",
      "Level check = new Level(emptyPlayer, emptyUnit, new Grid<>(Arrays.asList( Cell.WALL, Cell.WALL, Cell.WALL, Cell.WALL, Cell.EMPTY, Cell.WALL, Cell.WALL, Cell.WALL, Cell.WALL), 3, 3));\n",
      "CollisionHandler handler = new CollisionHandler(check);\n",
      "Cell cell = handler.checkLevelAABB( new AABB(new Point(1.5, 1.5), new Point(2.5, 2.5)), new Point(0, 0));\n",
      "assertNotEquals(cell, Cell.EMPTY);\n",
      "}\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "<START> public static void commit(ResourceResolver resourceResolver) {\n",
      "<END> if (resourceResolver == null || !resourceResolver.isLive()) {\n",
      "LOGGER.error(\"Resource resolver is null or not live while committing resourceResolver\");\n",
      " return;\n",
      " } Session session = resourceResolver.adaptTo(Session.class);\n",
      " if (session == null || !session.isLive()) {\n",
      "LOGGER.error(\"Resource resolver is null or not live while committing resourceResolver\");\n",
      " return;\n",
      " } try {\n",
      "resourceResolver.refresh();\n",
      " session.refresh(true);\n",
      " if (resourceResolver.hasChanges()) {\n",
      "resourceResolver.commit();\n",
      " } if (session.hasPendingChanges()) {\n",
      "session.save();\n",
      " } } catch (PersistenceException | RepositoryException e) {\n",
      "LOGGER.error(\"Error occurred while committing resource resolver\", e);\n",
      " } }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "In this method you are doing the commit on both the ResourceResolver and the JCR Session wrapped with the RR. Please just stick to the RR and omit doing the same for the JCR session here, it's not necessary (because the RR is doing that internally already).\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public static void commit(ResourceResolver resourceResolver) {\n",
      "if (resourceResolver == null || !resourceResolver.isLive()) {\n",
      "LOGGER.error(\"Resource resolver is null or not live while committing resourceResolver\");\n",
      " return;\n",
      " } try {\n",
      "resourceResolver.refresh();\n",
      " if (resourceResolver.hasChanges()) {\n",
      "resourceResolver.commit();\n",
      " } } catch (PersistenceException e) {\n",
      "LOGGER.error(\"Error occurred while committing resource resolver\", e);\n",
      " } }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -113,7 +113,11 @@ public void when_jobSuspendedByUser_then_suspensionCauseSaysSo() {\n",
      "         assertJobStatusEventually(job, RUNNING);\n",
      "         job.suspend();\n",
      "         assertJobStatusEventually(job, SUSPENDED);\n",
      "-        assertEquals(\"Requested by user\", job.getSuspensionCause());\n",
      "```\n",
      "Review: \n",
      "```\n",
      "You can keep this assert against the `description` method.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "job.suspend();\n",
      " assertJobStatusEventually(job, SUSPENDED);\n",
      " assertThat(job.getSuspensionCause()).matches(JobSuspensionCause::requestedByUser);\n",
      " assertThat(job.getSuspensionCause().description()).isEqualTo(\"Requested by user\");\n",
      " assertThatThrownBy(job.getSuspensionCause()::errorCause) .isInstanceOf(IllegalStateException.class) .hasMessage(\"Suspension not caused by an error\");\n",
      " cancelAndJoin(job);\n",
      "\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "private boolean isAllowed(MutableHttpServletRequest request, String paramName) {\n",
      "String layersParam = request.getParameterIgnoreCase(paramName);\n",
      " List<Layer> all = layerService.findAll();\n",
      " boolean match = false;\n",
      " for (Layer layer : all) {\n",
      "if (layer.getSource() instanceof ImageWmsLayerDataSource) {\n",
      "ImageWmsLayerDataSource source = (ImageWmsLayerDataSource) layer.getSource();\n",
      " if (source.getLayerNames().equalsIgnoreCase(layersParam) && source.getUrl().equalsIgnoreCase(request.getContextPath() + \"/geoserver.action\")) {\n",
      "<START> match = true;\n",
      " <END> } } } return match;\n",
      " }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "We can skip the loop now.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "private boolean isAllowed(MutableHttpServletRequest request, String paramName) {\n",
      "String layersParam = request.getParameterIgnoreCase(paramName);\n",
      " List<Layer> all = layerService.findAll();\n",
      " boolean match = false;\n",
      " for (Layer layer : all) {\n",
      "if (layer.getSource() instanceof ImageWmsLayerDataSource) {\n",
      "ImageWmsLayerDataSource source = (ImageWmsLayerDataSource) layer.getSource();\n",
      " if (source.getLayerNames().equalsIgnoreCase(layersParam) && source.getUrl().equalsIgnoreCase(request.getContextPath() + \"/geoserver.action\")) {\n",
      "match = true;\n",
      " break;\n",
      " } } } return match;\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public boolean contains(Command command) {\n",
      "final Message message = Commands.getMessage(command);\n",
      " if (messages.contains(message)) {\n",
      "final int messageIndex = messages.indexOf(message);\n",
      " final CommandContext actualContext = command.getContext();\n",
      " <START> final CommandContext expectedContext = contexts.get(messageIndex);\n",
      " <END> return actualContext.equals(expectedContext);\n",
      " } return false;\n",
      " }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "storedContext.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public boolean contains(Command command) {\n",
      "final Message message = Commands.getMessage(command);\n",
      " if (messages.contains(message)) {\n",
      "final int messageIndex = messages.indexOf(message);\n",
      " final CommandContext actualContext = command.getContext();\n",
      " final CommandContext storedContext = contexts.get(messageIndex);\n",
      " return actualContext.equals(storedContext);\n",
      " } return false;\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -77,7 +77,8 @@ private UserPreferences(){}\n",
      "     // Network\n",
      "     private static final String PREF_ENQUEUE_DOWNLOADED = \"prefEnqueueDownloaded\";\n",
      "     public static final String PREF_UPDATE_INTERVAL = \"prefAutoUpdateIntervall\";\n",
      "-    private static final String PREF_MOBILE_UPDATE = \"prefMobileUpdate\";\n",
      "+    public static final String PREF_MOBILE_UPDATE_OLD = \"prefMobileUpdate\";\n",
      "```\n",
      "Review: \n",
      "```\n",
      "we can never get rid of this...\n",
      "```\n",
      "New code: \n",
      "```\n",
      "// Network private static final String PREF_ENQUEUE_DOWNLOADED = \"prefEnqueueDownloaded\";\n",
      " public static final String PREF_UPDATE_INTERVAL = \"prefAutoUpdateIntervall\";\n",
      " public static final String PREF_MOBILE_UPDATE = \"prefMobileUpdateAllowed\";\n",
      " public static final String PREF_EPISODE_CLEANUP = \"prefEpisodeCleanup\";\n",
      " public static final String PREF_PARALLEL_DOWNLOADS = \"prefParallelDownloads\";\n",
      "\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Discarded\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -46,7 +46,7 @@ public boolean hasNext() {\n",
      "       inner.next();\n",
      "       return result;\n",
      "     } catch (IOException ex) {\n",
      "-      throw new NoSuchElementException();\n",
      "+      throw new UncheckedIOException(ex);\n",
      "```\n",
      "Review: \n",
      "```\n",
      "The NSEE makes a little more sense here, since it matches the Iterator interface's behavior when calling next without any more elements.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "inner.next();\n",
      " return result;\n",
      " } catch (IOException ex) {\n",
      "throw new NoSuchElementException();\n",
      " } }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "private static DetailNode getFirstChildOfType(DetailNode node, int tokenType, int offset) {\n",
      "return Arrays.stream(node.getChildren()) .filter(child -> child.getIndex() >= offset && child.getType() == tokenType) .findFirst() <START> .orElse(null);\n",
      "<END> }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "it is better to either throw an exception or return Optional for such case. I see no good handling for null values in invocations of getFirstChildOfType method\n",
      "```\n",
      "New code: \n",
      "```\n",
      "private static Optional<DetailNode> getFirstChildOfType(DetailNode node, int tokenType, int offset) {\n",
      "return Arrays.stream(node.getChildren()) .filter(child -> child.getIndex() >= offset && child.getType() == tokenType) .findFirst();\n",
      "}\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -182,13 +183,39 @@ public int compare(ByteBuffer buf1, ByteBuffer buf2) {\n",
      "     private CharSeqComparator() {\n",
      "     }\n",
      " \n",
      "+    private boolean isCharInUTF16HighSurrogateRange(char c1) {\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Here's an example, I think this was removed in a later version. Similarly, the extra newline on line 201 was fixed in another version.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "private CharSeqComparator() {\n",
      "} /** * Java character supports only upto 3 byte UTF-8 characters. 4 byte UTF-8 character is represented using two Java * characters (using UTF-16 surrogate pairs). Character by character comparison may yield incorrect results\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Discarded\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -1268,6 +1268,20 @@ public void testQueryByUnassignedOr() {\n",
      "         assertThat(query.count()).isEqualTo(11);\n",
      "         assertThat(query.list()).hasSize(11);\n",
      "     }\n",
      "+    \n",
      "+    @Test\n",
      "+    public void testQueryByAssigned() {\n",
      "+        TaskQuery query = taskService.createTaskQuery().taskAssigned();\n",
      "+        assertThat(query.count()).isEqualTo(1);\n",
      "+        assertThat(query.list()).hasSize(1);\n",
      "+    }\n",
      "+\n",
      "+    @Test\n",
      "+    public void testQueryByAssignedOr() {\n",
      "+        TaskQuery query = taskService.createTaskQuery().or().taskId(\"invalid\").taskAssigned();\n",
      "+        assertThat(query.count()).isEqualTo(0);\n",
      "```\n",
      "Review: \n",
      "```\n",
      "It seems like the `or` is not working correctly. This should have a count of `1` since there is 1 assigned task.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "@Test public void testQueryByAssignedOr() {\n",
      "TaskQuery query = taskService.createTaskQuery().or().taskId(\"invalid\").taskAssigned();\n",
      " assertThat(query.count()).isEqualTo(1);\n",
      " assertThat(query.list()).hasSize(1);\n",
      " } @Test\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public void unsupportedDatabaseTypeIdentified() {\n",
      "<START> IllegalArgumentException thrown = Assertions.assertThrows(IllegalArgumentException.class, <END> () -> new DatabaseInitializer(\"a2\", ds, environmentCreateOnStartup(\"true\")));\n",
      "assertThat(thrown.getMessage(), CoreMatchers.containsString(\"No ddl script found\"));\n",
      "}\n",
      "```\n",
      "Review: \n",
      "```\n",
      "static import\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public void unsupportedDatabaseTypeIdentified() {\n",
      "IllegalArgumentException thrown = assertThrows(IllegalArgumentException.class, () -> new DatabaseInitializer(\"a2\", ds, environmentCreateOnStartup(\"true\")));\n",
      "assertThat(thrown.getMessage(), containsString(\"No ddl script found\"));\n",
      "}\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Discarded\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -157,6 +158,9 @@\n",
      "     protected int cleanInstancesEndedAfterNumberOfDays = 365;\n",
      "     protected HistoryCleaningManager historyCleaningManager;\n",
      " \n",
      "+    // eventMessage\n",
      "+    protected int eventMessageLength = 163;\n",
      "+    protected int eventMessageSubLength = 163;\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Shouldn't this value be 160 and not 163 (to leave room for `...`)?\n",
      "```\n",
      "New code: \n",
      "```\n",
      "// eventMessage protected int eventMessageLength = 163;\n",
      " protected int eventMessageSubLength = 160;\n",
      " /** postprocessor for a task builder */ protected TaskPostProcessor taskPostProcessor = null;\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "private ResourceEstimates parseResourceEstimate(HttpServletRequest servletRequest) {\n",
      "ResourceEstimateBuilder builder = new ResourceEstimateBuilder();\n",
      " for (String header : splitSessionHeader(servletRequest.getHeaders(PRESTO_RESOURCE_ESTIMATE))) {\n",
      "List<String> nameValue = Splitter.on('=').limit(2).trimResults().splitToList(header);\n",
      " assertRequest(nameValue.size() == 2, \"Invalid %s header\", PRESTO_RESOURCE_ESTIMATE);\n",
      " String name = nameValue.get(0);\n",
      " long value;\n",
      " try {\n",
      "value = Long.parseLong(nameValue.get(1));\n",
      " } catch (NumberFormatException ignored) {\n",
      "throw badRequest(format(\"Expected integral value for resource estimate %s\", name));\n",
      " } <START> if (name.equalsIgnoreCase(ResourceEstimates.EXECUTION_TIME_MILLIS)) {\n",
      "<END> builder.setExecutionTimeMillis(value);\n",
      " } else if (name.equalsIgnoreCase(ResourceEstimates.CPU_TIME_MILLIS)) {\n",
      "builder.setCpuTimeMillis(value);\n",
      " } else if (name.equalsIgnoreCase(ResourceEstimates.PEAK_MEMORY_BYTES)) {\n",
      "builder.setPeakMemoryBytes(value);\n",
      " } else {\n",
      "throw badRequest(format(\"Unsupported resource estimate %s\", name));\n",
      " } } return builder.build();\n",
      " }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Let's use underscore so it's consistent with session properties\n",
      "```\n",
      "New code: \n",
      "```\n",
      "private ResourceEstimates parseResourceEstimate(HttpServletRequest servletRequest) {\n",
      "ResourceEstimateBuilder builder = new ResourceEstimateBuilder();\n",
      " for (String header : splitSessionHeader(servletRequest.getHeaders(PRESTO_RESOURCE_ESTIMATE))) {\n",
      "List<String> nameValue = Splitter.on('=').limit(2).trimResults().splitToList(header);\n",
      " assertRequest(nameValue.size() == 2, \"Invalid %s header\", PRESTO_RESOURCE_ESTIMATE);\n",
      " String name = nameValue.get(0);\n",
      " String value = nameValue.get(1);\n",
      " try {\n",
      "switch (name.toUpperCase()) {\n",
      "case ResourceEstimates.EXECUTION_TIME: builder.setExecutionTime(Duration.valueOf(value));\n",
      " break;\n",
      " case ResourceEstimates.CPU_TIME: builder.setCpuTime(Duration.valueOf(value));\n",
      " break;\n",
      " case ResourceEstimates.PEAK_MEMORY: builder.setPeakMemory(DataSize.valueOf(value));\n",
      " break;\n",
      " default: throw badRequest(format(\"Unsupported resource name %s\", name));\n",
      " } } catch (IllegalArgumentException e) {\n",
      "throw badRequest(format(\"Unsupported format for resource estimate '%s': %s\", value, e));\n",
      " } } return builder.build();\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -0,0 +1,82 @@\n",
      "+/**\n",
      "+ * BSD-style license; for more info see http://pmd.sourceforge.net/license.html\n",
      "+ */\n",
      "+\n",
      "+package net.sourceforge.pmd.lang.ast;\n",
      "+\n",
      "+import java.util.List;\n",
      "+\n",
      "+import org.jaxen.JaxenException;\n",
      "+\n",
      "+/**\n",
      "+ * Base interface for all Antlr-based implementation of Node interface.\n",
      "+ * <p>\n",
      "+ * Initially all the methods implemented here will be no-op due to scope limitations\n",
      "+ */\n",
      "+public interface AntlrNode extends Node {\n",
      "+\n",
      "+    @Override\n",
      "+    default void jjtOpen() {\n",
      "+        throw new UnsupportedOperationException(\"Won't be needed on Antlr implementation\");\n",
      "+    }\n",
      "+\n",
      "+    @Override\n",
      "+    default void jjtClose() {\n",
      "+        throw new UnsupportedOperationException(\"Won't be needed on Antlr implementation\");\n",
      "+    }\n",
      "+\n",
      "+    @Override\n",
      "+    default void jjtSetParent(final Node parent) {\n",
      "+        throw new UnsupportedOperationException(\"Out of scope for antlr current implementations\");\n",
      "+    }\n",
      "+\n",
      "+    @Override\n",
      "+    default void jjtAddChild(final Node child, final int index) {\n",
      "+        throw new UnsupportedOperationException(\"Out of scope for antlr current implementations\");\n",
      "+    }\n",
      "+\n",
      "+    @Override\n",
      "+    default void jjtSetChildIndex(final int index) {\n",
      "+        throw new UnsupportedOperationException(\"Out of scope for antlr current implementations\");\n",
      "+    }\n",
      "+\n",
      "+    @Override\n",
      "+    default int jjtGetChildIndex() {\n",
      "+        throw new UnsupportedOperationException(\"Out of scope for antlr current implementations\");\n",
      "+    }\n",
      "+\n",
      "+    @Override\n",
      "+    default int jjtGetId() {\n",
      "+        throw new UnsupportedOperationException(\"Out of scope for antlr current implementations\");\n",
      "+    }\n",
      "+\n",
      "+    @Override\n",
      "+    default String getImage() {\n",
      "+        throw new UnsupportedOperationException(\"Out of scope for antlr current implementations\");\n",
      "+    }\n",
      "+\n",
      "+    @Override\n",
      "+    default void setImage(final String image) {\n",
      "+        throw new UnsupportedOperationException(\"Out of scope for antlr current implementations\");\n",
      "+    }\n",
      "+\n",
      "+    @Override\n",
      "+    default boolean hasImageEqualTo(final String image) {\n",
      "+        throw new UnsupportedOperationException(\"Out of scope for antlr current implementations\");\n",
      "+    }\n",
      "+\n",
      "+    @Override\n",
      "+    default void remove() {\n",
      "+        throw new UnsupportedOperationException(\"Out of scope for antlr current implementations\");\n",
      "+    }\n",
      "+\n",
      "+    @Override\n",
      "+    default void removeChildAtIndex(final int childIndex) {\n",
      "+        throw new UnsupportedOperationException(\"Out of scope for antlr current implementations\");\n",
      "+    }\n",
      "+\n",
      "+    @Override\n",
      "+    default List<Node> findChildNodesWithXPath(final String xpathString) throws JaxenException {\n",
      "```\n",
      "Review: \n",
      "```\n",
      "this is implemented in `Node`, do we really need to have it \"unsupported\" here?\n",
      "```\n",
      "New code: \n",
      "```\n",
      "default void removeChildAtIndex(final int childIndex) {\n",
      "throw new UnsupportedOperationException(\"Out of scope for antlr current implementations\");\n",
      " } }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "protected void onCreate(@Nullable Bundle savedInstanceState) {\n",
      "super.onCreate(savedInstanceState);\n",
      " setContentView(R.layout.activity_project_management);\n",
      " pref = PreferenceManager.getDefaultSharedPreferences(this);\n",
      " db = ((TranslationRecorderApp)getApplication()).getDatabase();\n",
      " Toolbar mToolbar = (Toolbar) findViewById(R.id.project_management_toolbar);\n",
      " setSupportActionBar(mToolbar);\n",
      " if (getSupportActionBar() != null) {\n",
      "ImageView imageView = findViewById(R.id.identicon);\n",
      " getSupportActionBar().setDisplayShowTitleEnabled(false);\n",
      " int userId = pref.getInt(Settings.KEY_PROFILE, -1);\n",
      " final User user = db.getUser(userId);\n",
      " String svg = Jdenticon.Companion.toSvg(user.getHash(), 512, 0f);\n",
      " imageView.setBackground(Sharp.loadString(svg).getDrawable());\n",
      " imageView.setLayerType(View.LAYER_TYPE_SOFTWARE, null);\n",
      " <START> imageView.setOnClickListener(identiconPlayerClick(user.getAudio().toString()));\n",
      " <END> } if (savedInstanceState != null) {\n",
      "mZipping = savedInstanceState.getBoolean(STATE_ZIPPING, false);\n",
      " mExporting = savedInstanceState.getBoolean(STATE_EXPORTING, false);\n",
      " mProgress = savedInstanceState.getInt(STATE_PROGRESS, 0);\n",
      " mProgressTitle = savedInstanceState.getString(STATE_PROGRESS_TITLE, null);\n",
      " mDbResyncing = savedInstanceState.getBoolean(STATE_RESYNC, false);\n",
      " } }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "maybe group this all into a function \"initializeIdenticon\" or something like that\n",
      "```\n",
      "New code: \n",
      "```\n",
      "protected void onCreate(@Nullable Bundle savedInstanceState) {\n",
      "super.onCreate(savedInstanceState);\n",
      " setContentView(R.layout.activity_project_management);\n",
      " pref = PreferenceManager.getDefaultSharedPreferences(this);\n",
      " db = ((TranslationRecorderApp)getApplication()).getDatabase();\n",
      " Toolbar mToolbar = (Toolbar) findViewById(R.id.project_management_toolbar);\n",
      " setSupportActionBar(mToolbar);\n",
      " if (getSupportActionBar() != null) {\n",
      "getSupportActionBar().setDisplayShowTitleEnabled(false);\n",
      " initializeIdenticon();\n",
      " } if (savedInstanceState != null) {\n",
      "mZipping = savedInstanceState.getBoolean(STATE_ZIPPING, false);\n",
      " mExporting = savedInstanceState.getBoolean(STATE_EXPORTING, false);\n",
      " mProgress = savedInstanceState.getInt(STATE_PROGRESS, 0);\n",
      " mProgressTitle = savedInstanceState.getString(STATE_PROGRESS_TITLE, null);\n",
      " mDbResyncing = savedInstanceState.getBoolean(STATE_RESYNC, false);\n",
      " } }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public void executeCommand() {\n",
      "addAuditLogForPartialVMs();\n",
      "super.executeCommand();\n",
      "if (getParameters().isImagesExistOnTargetStorageDomain()) {\n",
      "if (!getImages().isEmpty()) {\n",
      "findAndSaveDiskCopies();\n",
      "<START> for (DiskImage diskImage : getImages()) {\n",
      "initQcowVersionForDisks(diskImage.getId());\n",
      "} <END> } unregisteredOVFDataDao.removeEntity(ovfEntityData.getEntityId(), null);\n",
      "unregisteredDisksDao.removeUnregisteredDiskRelatedToVM(ovfEntityData.getEntityId(), null);\n",
      "} setActionReturnValue(getVmTemplate().getId());\n",
      "setSucceeded(true);\n",
      "}\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Just use forEach\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public void executeCommand() {\n",
      "addAuditLogForPartialVMs();\n",
      "super.executeCommand();\n",
      "if (getParameters().isImagesExistOnTargetStorageDomain()) {\n",
      "if (!getImages().isEmpty()) {\n",
      "findAndSaveDiskCopies();\n",
      "getImages().stream().forEach(diskImage -> {\n",
      "initQcowVersionForDisks(diskImage.getId());\n",
      "});\n",
      "} unregisteredOVFDataDao.removeEntity(ovfEntityData.getEntityId(), null);\n",
      "unregisteredDisksDao.removeUnregisteredDiskRelatedToVM(ovfEntityData.getEntityId(), null);\n",
      "} setActionReturnValue(getVmTemplate().getId());\n",
      "setSucceeded(true);\n",
      "}\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -130,27 +121,30 @@ String processedIndexHtml(Resource indexHtml) {\n",
      "       lensIndex = HttpFileBuilder.of(HttpData.of(processedLensIndexHtml().getBytes(UTF_8)));\n",
      "     }\n",
      " \n",
      "-    legacyIndex.setHeaders(INDEX_HEADERS);\n",
      "-    lensIndex.setHeaders(INDEX_HEADERS);\n",
      "+    ServerCacheControl maxAgeMinute = new ServerCacheControlBuilder().maxAgeSeconds(60).build();\n",
      "+    legacyIndex.contentType(MediaType.HTML_UTF_8).cacheControl(maxAgeMinute);\n",
      "+    lensIndex.contentType(MediaType.HTML_UTF_8).cacheControl(maxAgeMinute);\n",
      " \n",
      "     return new IndexSwitchingService(\n",
      "       legacyIndex.build().asService(), lensIndex.build().asService());\n",
      "   }\n",
      " \n",
      "   @Bean @Lazy ArmeriaServerConfigurator uiServerConfigurator(\n",
      "-    IndexSwitchingService indexSwitchingService)\n",
      "-    throws IOException {\n",
      "+    IndexSwitchingService indexSwitchingService) throws IOException {\n",
      "+    ServerCacheControl maxAgeYear =\n",
      "+      new ServerCacheControlBuilder().maxAgeSeconds(TimeUnit.DAYS.toSeconds(365)).build();\n",
      "     Service<HttpRequest, HttpResponse> uiFileService =\n",
      "-      new AddHttpHeadersService(HttpFileService.forClassPath(\"zipkin-ui\")\n",
      "-        .orElse(HttpFileService.forClassPath(\"zipkin-lens\")), CACHE_YEAR);\n",
      "-\n",
      "-\n",
      "+      HttpFileServiceBuilder.forClassPath(\"zipkin-ui\").cacheControl(maxAgeYear).build()\n",
      "+        .orElse(HttpFileServiceBuilder.forClassPath(\"zipkin-lens\").cacheControl(maxAgeYear).build());\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Our JS/CSS bundles get a hash appended right?\n",
      "```\n",
      "New code: \n",
      "```\n",
      "legacyIndex.contentType(MediaType.HTML_UTF_8).cacheControl(maxAgeMinute);\n",
      " lensIndex.contentType(MediaType.HTML_UTF_8).cacheControl(maxAgeMinute);\n",
      " // In both our old and new UI, assets have hashes in the filenames (generated by webpack). // This allows us to host both simultaneously without conflict as long as we change the index // file to point to the correct files. return new IndexSwitchingService( legacyIndex.build().asService(), lensIndex.build().asService());\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Discarded\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -6844,4 +6844,24 @@ boolean isAllowedPutMembership(Principal principal, final AthenzDomain domain, f\n",
      "         return false;\n",
      "     }\n",
      " \n",
      "+    @Override\n",
      "+    public DomainRoleMembership getPendingDomainRoleMembersList(ResourceContext ctx) {\n",
      "+        final String caller = \"getpendingdomainrolememberslist\";\n",
      "+        metric.increment(ZMSConsts.HTTP_GET);\n",
      "+        metric.increment(ZMSConsts.HTTP_REQUEST);\n",
      "+        metric.increment(caller);\n",
      "+        final String principalDomain = getPrincipalDomain(ctx);\n",
      "+        Object timerMetric = metric.startTiming(\"getpendingdomainrolememberslist_timing\", null, principalDomain);\n",
      "+        logPrincipal(ctx);\n",
      "+        validateRequest(ctx.request(), caller);\n",
      "+        Principal ctxPrincipal = ((RsrcCtxWrapper) ctx).principal();\n",
      "```\n",
      "Review: \n",
      "```\n",
      "since we get the principal object only for debug we should included it within the if block or just reference it directly in the debug call\n",
      "```\n",
      "New code: \n",
      "```\n",
      "Object timerMetric = metric.startTiming(\"getpendingdomainrolememberslist_timing\", null, principalDomain);\n",
      " logPrincipal(ctx);\n",
      " validateRequest(ctx.request(), caller);\n",
      " if (LOG.isDebugEnabled()) {\n",
      "LOG.debug(\"getpendingdomainrolememberslist:(\" + ((RsrcCtxWrapper) ctx).principal() + \")\");\n",
      " } DomainRoleMembership domainRoleMembership = dbService.getPendingDomainRoleMembersList(ctx);\n",
      " metric.stopTiming(timerMetric, null, principalDomain);\n",
      "\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -154,6 +167,9 @@ void reset(Watermark wm) {\n",
      " \n",
      "     @Override\n",
      "     public boolean saveToSnapshot() {\n",
      "+        if (inComplete) {\n",
      "```\n",
      "Review: \n",
      "```\n",
      "this needs more explanation, like in SessionWindowP. Do we perhaps need better support for this in ProcessorTasklet?\n",
      "```\n",
      "New code: \n",
      "```\n",
      "@Override public boolean saveToSnapshot() {\n",
      "if (inComplete) {\n",
      "// If we are in completing phase, we can have a half-emitted item. Instead of finishing it and // writing a snapshot, we finish the final items and save no state. return complete();\n",
      " } if (snapshotTraverser == null) {\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -44,7 +44,7 @@ public String getURI() {\n",
      "     @Override\n",
      "     public Value atomize() throws XPathException {\n",
      "         if (value == null) {\n",
      "-            Object v = attribute.getValue();\n",
      "+            final Object v = attribute.getValue();\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Maybe inline that variable\n",
      "```\n",
      "New code: \n",
      "```\n",
      "} @Override public Value atomize() {\n",
      "if (value == null) {\n",
      "value = SaxonXPathRuleQuery.getAtomicRepresentation(attribute.getValue());\n",
      " } return value;\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -119,8 +119,15 @@ synchronized private static Configuration getXmlConfig() {\n",
      " \n",
      "   @Override\n",
      "   public String get(Property property) {\n",
      "-    String key = property.getKey();\n",
      "+    return get(property, true);\n",
      "+  }\n",
      " \n",
      "+  public String get(Property property, boolean useDefault) {\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Instead of putting this functionality into SiteConfig did you consider creating another config layer bettween DefaultConfig and SiteConfig?\n",
      "```\n",
      "New code: \n",
      "```\n",
      "@Override public String get(Property property) {\n",
      "if (CliConfiguration.get(property) != null) {\n",
      "return CliConfiguration.get(property);\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Discarded\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public T createHosted(@ApiParam(hidden = true) @Auth User user, @ApiParam(value = \"The Docker registry (Tools only)\") @QueryParam(\"registry\") String registry, @ApiParam(value = \"The repository name\", required = true) @QueryParam(\"name\") String name, @ApiParam(value = \"The descriptor type (Workflows only)\") @QueryParam(\"descriptorType\") String descriptorType, @ApiParam(value = \"The Docker namespace (Tools only)\") @QueryParam(\"namespace\") String namespace, @ApiParam(value = \"Optional entry name (Tools only)\") @QueryParam(\"entryName\") String entryName) {\n",
      "final long currentCount = getEntryDAO().countAllHosted(user.getId());\n",
      " <START> User updatedUser = userDAO.findById(user.getId());\n",
      " <END> final int limit = updatedUser.getHostedEntryCountLimit() != null ? updatedUser.getHostedEntryCountLimit() : calculatedEntryLimit;\n",
      " if (currentCount >= limit) {\n",
      "throw new CustomWebApplicationException(\"You have \" + currentCount + \" workflows which is at the current limit of \" + limit, HttpStatus.SC_PAYMENT_REQUIRED);\n",
      " } DescriptorLanguage convertedDescriptorType = checkType(descriptorType);\n",
      " Registry convertedRegistry = checkRegistry(registry);\n",
      " T entry = getEntry(user, convertedRegistry, name, convertedDescriptorType, namespace, entryName);\n",
      " checkForDuplicatePath(entry);\n",
      " long l = getEntryDAO().create(entry);\n",
      " T byId = getEntryDAO().findById(l);\n",
      " elasticManager.handleIndexUpdate(byId, ElasticMode.UPDATE);\n",
      " return byId;\n",
      " }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Hmmm, might be more efficient to just invalidate the cache when a user's limits are changed rather than checking each time. <LINK_0>\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public T createHosted(@ApiParam(hidden = true) @Auth User user, @ApiParam(value = \"The Docker registry (Tools only)\") @QueryParam(\"registry\") String registry, @ApiParam(value = \"The repository name\", required = true) @QueryParam(\"name\") String name, @ApiParam(value = \"The descriptor type (Workflows only)\") @QueryParam(\"descriptorType\") String descriptorType, @ApiParam(value = \"The Docker namespace (Tools only)\") @QueryParam(\"namespace\") String namespace, @ApiParam(value = \"Optional entry name (Tools only)\") @QueryParam(\"entryName\") String entryName) {\n",
      "final long currentCount = getEntryDAO().countAllHosted(user.getId());\n",
      " final int limit = user.getHostedEntryCountLimit() != null ? user.getHostedEntryCountLimit() : calculatedEntryLimit;\n",
      " if (currentCount >= limit) {\n",
      "throw new CustomWebApplicationException(\"You have \" + currentCount + \" workflows which is at the current limit of \" + limit, HttpStatus.SC_PAYMENT_REQUIRED);\n",
      " } DescriptorLanguage convertedDescriptorType = checkType(descriptorType);\n",
      " Registry convertedRegistry = checkRegistry(registry);\n",
      " T entry = getEntry(user, convertedRegistry, name, convertedDescriptorType, namespace, entryName);\n",
      " checkForDuplicatePath(entry);\n",
      " long l = getEntryDAO().create(entry);\n",
      " T byId = getEntryDAO().findById(l);\n",
      " elasticManager.handleIndexUpdate(byId, ElasticMode.UPDATE);\n",
      " return byId;\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "private synchronized Map<String, ThriftSerializedObject> partialSnapshot(TDeserializer td) {\n",
      "int attempts = 0;\n",
      " while (true) {\n",
      "try {\n",
      "return partialDeserializeLatestVersion(td);\n",
      " } catch (Exception e) {\n",
      "attempts++;\n",
      " if (attempts >= 10) {\n",
      "if (e.getCause() instanceof TProtocolException) {\n",
      "<START> LOG.warn(\"LocalState file is corrupted, resetting state\");\n",
      " <END> return new HashMap<>();\n",
      " } throw new RuntimeException(e);\n",
      " } } } }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "Sorry just one more minor thing. Do you think it makes sense to have the exception plus stack trace here as well? Otherwise it might be hard to debug if this case is hit unexpectedly.\n",
      "```\n",
      "New code: \n",
      "```\n",
      "private synchronized Map<String, ThriftSerializedObject> partialSnapshot(TDeserializer td) {\n",
      "int attempts = 0;\n",
      " while (true) {\n",
      "try {\n",
      "return partialDeserializeLatestVersion(td);\n",
      " } catch (Exception e) {\n",
      "attempts++;\n",
      " if (attempts >= 10) {\n",
      "if (e.getCause() instanceof TProtocolException) {\n",
      "LOG.warn(\"LocalState file is corrupted, resetting state.\", e);\n",
      " return new HashMap<>();\n",
      " } throw new RuntimeException(e);\n",
      " } } } }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "@@ -638,7 +639,11 @@ void finalizeJob(@Nullable Throwable failure) {\n",
      "                         && mc.jobConfig().getProcessingGuarantee() != NONE\n",
      "                 ) {\n",
      "                     mc.setJobStatus(SUSPENDED);\n",
      "-                    mc.jobExecutionRecord().setSuspended(true);\n",
      "+                    mc.jobExecutionRecord().setSuspended(\"Requested by user\");\n",
      "+                    nonSynchronizedAction = () -> mc.writeJobExecutionRecord(false);\n",
      "+                } else if (failure != null && !wasCancelled && mc.jobConfig().isSuspendOnFailure()) {\n",
      "+                    mc.setJobStatus(SUSPENDED);\n",
      "+                    mc.jobExecutionRecord().setSuspended(\"Due to failure:\\n\" + ExceptionUtil.stackTraceToString(failure));\n",
      "```\n",
      "Review: \n",
      "```\n",
      "```suggestion mc.jobExecutionRecord().setSuspended(\"Execution failure:\\n\" + ExceptionUtil.stackTraceToString(failure)); ```\n",
      "```\n",
      "New code: \n",
      "```\n",
      "nonSynchronizedAction = () -> mc.writeJobExecutionRecord(false);\n",
      " } else if (failure != null && !wasCancelled && mc.jobConfig().isSuspendOnFailure()) {\n",
      "mc.setJobStatus(SUSPENDED);\n",
      " mc.jobExecutionRecord().setSuspended(\"Execution failure:\\n\" + ExceptionUtil.stackTraceToString(failure));\n",
      " nonSynchronizedAction = () -> mc.writeJobExecutionRecord(false);\n",
      " } else {\n",
      "mc.setJobStatus(isSuccess(failure) ? COMPLETED : FAILED);\n",
      "\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "public void multiRequestMixedReduced() throws IOException {\n",
      "init();\n",
      "ViewMultipleRequest<String, Object> multi = db.getViewRequestBuilder(\"example\", \"by_tag\") .newMultipleRequest(Key.Type.STRING, Object.class) .reduce(false).keys(\"java\") .add() .reduce(true) .add() .build();\n",
      "List<ViewResponse<String, Object>> responses = multi.getViewResponses();\n",
      "<START> assertEquals(2, responses.size(), \"There should be 2 respones for 2 requests\");\n",
      "<END> List<String> javaTagKeys = responses.get(0).getKeys();\n",
      "assertEquals(1, javaTagKeys.size(), \"There should be 1 java tag result\");\n",
      "assertEquals(\"java\", javaTagKeys.get(0), \"The key should be java\");\n",
      "List<Object> allTagsReduced = responses.get(1).getValues();\n",
      "assertEquals(1, allTagsReduced.size(), \"There should be 1 reduced result\");\n",
      "assertEquals(4, ((Number) allTagsReduced.get(0)).intValue(), \"The result should be 4\");\n",
      "}\n",
      "```\n",
      "Review: \n",
      "```\n",
      "respones -> responses\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public void multiRequestMixedReduced() throws IOException {\n",
      "init();\n",
      "ViewMultipleRequest<String, Object> multi = db.getViewRequestBuilder(\"example\", \"by_tag\") .newMultipleRequest(Key.Type.STRING, Object.class) .reduce(false).keys(\"java\") .add() .reduce(true) .add() .build();\n",
      "List<ViewResponse<String, Object>> responses = multi.getViewResponses();\n",
      "assertEquals(2, responses.size(), \"There should be 2 responses for 2 requests\");\n",
      "List<String> javaTagKeys = responses.get(0).getKeys();\n",
      "assertEquals(1, javaTagKeys.size(), \"There should be 1 java tag result\");\n",
      "assertEquals(\"java\", javaTagKeys.get(0), \"The key should be java\");\n",
      "List<Object> allTagsReduced = responses.get(1).getValues();\n",
      "assertEquals(1, allTagsReduced.size(), \"There should be 1 reduced result\");\n",
      "assertEquals(4, ((Number) allTagsReduced.get(0)).intValue(), \"The result should be 4\");\n",
      "}\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "Valid\n",
      "prompt:\n",
      "\n",
      "Task:\n",
      "You are an experienced code quality evaluator. Classify the given dataset instance (Old code, Review, New code) as valid or discarded based on strict rules.\n",
      "Classification Criteria (mark as discarded if ANY condition is met):\n",
      "Unclear Review: The Review is too vague for humans to infer the required change (e.g., \"Fix this\" without context).\n",
      "No Change Asked: The Review is not requesting any change (e.g., “Awesome work so far, Eli!”)\n",
      "Ignored Review: Code changes deviate from the Review’s intent (e.g., Review requests a bug fix, but new features are added).\n",
      "Wrong Linking: Old code has been linked to a wrong New code while mining the dataset.\n",
      "Evaluation Steps:\n",
      "Check Review Intent: Does the Review explicitly request a code change? If not (e.g., praise or no actionable request), mark discarded.\n",
      "Assess Review Clarity: Is the Review specific enough to infer what to modify? If unclear (e.g., \"Improve this\"), mark discarded.\n",
      "Verify Modification Alignment: Does the New code directly address the Review’s request? If changes ignore or contradict the Review, mark discarded.\n",
      "Validate Code Relevance: Are Old and New code logically linked (e.g., same function/variable scope)? If unrelated, mark discarded.\n",
      "Input Format for Classification:\n",
      "Classify the following dataset instance:\n",
      "Old code: \n",
      "```\n",
      "<START> public void queryFile2FullHistory() throws CoreException {\n",
      "<END> final List<RevCommit> expectedHistory = Arrays.asList(masterCommit2, masterCommit3);\n",
      " for (RevCommit ref : commits) {\n",
      "testRepository.checkoutBranch(ref.getName());\n",
      " final IFileHistory history = historyProvider.getFileHistoryFor( iFile2, IFileHistoryProvider.NONE, new NullProgressMonitor());\n",
      " assertNotNull(history);\n",
      " final IFileRevision[] revisions = history.getFileRevisions();\n",
      " assertEquals(2, revisions.length);\n",
      " final List<RevCommit> commitList = new ArrayList<RevCommit>( expectedHistory);\n",
      " assertMatchingRevisions(Arrays.asList(revisions), commitList);\n",
      " } }\n",
      "```\n",
      "Review: \n",
      "```\n",
      "I think you should factor out the common code this test shares with the previous one\n",
      "```\n",
      "New code: \n",
      "```\n",
      "public void queryFile2FullHistory() throws CoreException {\n",
      "final List<RevCommit> expectedHistory = Arrays.asList(masterCommit2, masterCommit3);\n",
      " assertFullHistoryMatches(iFile2, expectedHistory);\n",
      " }\n",
      "```\n",
      "Output Format:\n",
      "Only respond with valid or discarded. No explanations.\n",
      "answer:\n",
      "valid\n",
      "Accuracy: 0.7671232876712328\n"
     ]
    }
   ],
   "source": [
    "###评估test_dataset 微调前\n",
    "import model\n",
    "with open(\"/mnt/ssd2/wangke/dataset/finetuning_datasets/test.json\", \"r\") as f:\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    records = json.load(f)\n",
    "    for record in records:\n",
    "        output = record[\"output\"]\n",
    "        instruction = record[\"instruction\"]\n",
    "        _, wofinetune_output = model.get_model_response(instruction)\n",
    "        record[\"wofinetune_output\"] = wofinetune_output\n",
    "        if wofinetune_output.strip().startswith(\"valid\") or wofinetune_output.strip().startswith(\"Valid\"): wofinetune_output = \"valid\"\n",
    "        elif wofinetune_output.strip().startswith(\"discarded\") or wofinetune_output.strip().startswith(\"Discarded\"): wofinetune_output = \"discarded\"\n",
    "        else: print(f\"Invalid model output: {wofinetune_output}\")\n",
    "        if output == wofinetune_output:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    print(f\"Accuracy: {correct/total}\")\n",
    "    with open(\"/mnt/ssd2/wangke/dataset/finetuning_datasets/test_wofinetune.json\", \"w\") as f:\n",
    "        json.dump(records, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt:\n",
      "\n",
      "Task Prompt for Evaluating Code Review Comments:\n",
      "As an experienced human evaluator, you receive a reviewer's comment on a specific piece of code that requires modification. Your task involves a thoughtful step-by-step approach to consider the proposed changes. Begin by examining the provided code block and the reviewer’s comment to determine if the intended modifications can be achieved by editing the code in-place.\n",
      "Instructions:Review the Comment and Code Block:\n",
      "Comment Provided: Is the name \"head\" a convention for health checking? Regardless it caught me by surprise, maybe add some docs to this function on why it exist? It should also say what 204.\n",
      "Associated Code Block:\n",
      "```\n",
      "         self.redirect(\"/static/visualiser/index.html\")\n",
      "     def head(self):\n",
      "         self.set_status(204)\n",
      "         self.finish()\n",
      "```\n",
      "Make Two Key Judgments:\n",
      "1.Feasibility: Determine if the proposed changes are feasible within the given code block alone. Consider if the comment:\n",
      "References elements not included in the code block, which would imply that in-place modification is insufficient.\n",
      "Is clear and specific enough to guide your modifications confidently. If the comment is vague or lacks direction, it may not inspire a successful modification.\n",
      "2.Additional Context Requirements: Decide if additional context from outside the given code snippet is needed to properly implement the changes. This may involve:\n",
      "External functions or variables mentioned but not defined within the code block.\n",
      "Specific files or repository knowledge that could influence the modification.\n",
      "Output Requirements: Provide your analysis in a JSON format detailing your conclusions on feasibility and the need for additional context:\n",
      "```{\"Feasibility\": \"Enter 1 (feasible) or 0 (not feasible)\",\"Reason_for_feasibility\": \"Explain why the modification is feasible or not based on the code block and comment clarity.\",\"Additional_context_required\": \"Enter 1 (yes) or 0 (no)\",\"Reason_for_additional_context\": \"Describe why additional context is needed or not, including specific elements or information required for modification.\"}```\n",
      "Note: Your responses should be direct and supported by specific observations from the reviewer's comment and the code snippet. Your goal is to assess whether the changes suggested by the reviewer can be accomplished with the current information or if external details are necessary.Your response should only include the json object with four keys and their corresponding values.\n",
      "answer:\n",
      "Here is the JSON object with my analysis:\n",
      "\n",
      "```\n",
      "{\"Feasibility\": \"1\", \"Reason_for_feasibility\": \"The modification is feasible within the given code block alone, as the comment provides clear and specific guidance on what changes to make. The comment references the 'head' function and the 'set_status' method, which are both present in the code block.\", \"Additional_context_required\": \"0\", \"Reason_for_additional_context\": \"No additional context is required, as the comment provides all the necessary information to implement the changes. The code block is self-contained and the comment is clear and specific, making it possible to modify the code without external knowledge or references.\"}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import model\n",
    "input_file = \"/mnt/ssd2/wangke/CR_data/dataset/map_result/dataset_sorted_llama.json\"\n",
    "output_file = \"/mnt/ssd2/wangke/dataset/cr_data/dataset_sorted_llama_instructed.json\"\n",
    "with open(input_file, \"r\") as f:\n",
    "    records = json.load(f)\n",
    "    for record in records:\n",
    "        old, review = record[\"old\"], record[\"review\"]\n",
    "        prompt_for_context_requirement = model.prompt_for_context_requirement(old, review)\n",
    "        _, result_json = model.get_model_response(prompt_for_context_requirement)\n",
    "        record[\"prompt_for_context_requirement\"] = prompt_for_context_requirement\n",
    "        record[\"result_json\"] = result_json\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(records, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 4422, f1a1: 1, f1a0: 4235, f0a1: 186, f0a0: 0, error: 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import model\n",
    "import re\n",
    "input_file = \"/mnt/ssd2/wangke/dataset/cr_data/dataset_sorted_llama_instructed.json\"\n",
    "output_file = \"/mnt/ssd2/wangke/dataset/cr_data/dataset_sorted_llama_instructed_processed.json\"\n",
    "with open(input_file, \"r\") as f:\n",
    "    records = json.load(f)\n",
    "    _records = []\n",
    "    total = 0\n",
    "    f0a0 = 0\n",
    "    f0a1 = 0\n",
    "    f1a0 = 0\n",
    "    f1a1 = 0\n",
    "    error = 0\n",
    "    for record in records:\n",
    "        try:\n",
    "            result_json = record[\"result_json\"]\n",
    "            #采用正则表达式截取result_json中Feasibility后出现的第一个数字,先匹配Feasibility,再匹配第一个数字\n",
    "            feasibility = re.search(r'\"Feasibility\": \"(\\d)\"', result_json).group(1)\n",
    "            additional_context_required = re.search(r'\"Additional_context_required\": \"(\\d)\"', result_json).group(1)\n",
    "            # feasibility = re.search(r'\"Feasibility\": \"(\\d)\"', result_json).group(1)\n",
    "            # additional_context_required = re.search(r'\"Additional_context_required\": \"(\\d)\"', result_json).group(1)\n",
    "            if feasibility == \"1\" and additional_context_required == \"1\":\n",
    "                # _records.append(record)\n",
    "                f1a1 += 1\n",
    "            elif feasibility == \"1\" and additional_context_required == \"0\": \n",
    "                f1a0 += 1\n",
    "            elif feasibility == \"0\" and additional_context_required == \"1\": \n",
    "                f0a1 += 1\n",
    "                _records.append(record)\n",
    "            elif feasibility == \"0\" and additional_context_required == \"0\": \n",
    "                f0a0 += 1\n",
    "                _records.append(record)\n",
    "            else: error += 1\n",
    "            total += 1\n",
    "        except:\n",
    "            pass\n",
    "    print(f\"total: {total}, f1a1: {f1a1}, f1a0: {f1a0}, f0a1: {f0a1}, f0a0: {f0a0}, error: {error}\")\n",
    "    with open(output_file, \"w\") as f1:\n",
    "        json.dump(_records, f1, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 8678, f1: 5581, f0: 3097, error: 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import model\n",
    "import re\n",
    "# input_file = \"/mnt/ssd2/wangke/dataset/cr_data/dataset_sorted_llama_instructed_map_deepseek.json\"\n",
    "# output_file = \"/mnt/ssd2/wangke/dataset/cr_data/dataset_sorted_llama_instructed_map_deepseek_processed.json\"\n",
    "input_file = \"/mnt/ssd2/wangke/dataset/cr_data/new_datasets_instructed_map_deepseek.json\"\n",
    "output_file = \"/mnt/ssd2/wangke/dataset/cr_data/new_datasets_instructed_map_deepseek_processed.json\"\n",
    "with open(input_file, \"r\") as f:\n",
    "    records = [json.loads(line) for line in f]\n",
    "    _records = []\n",
    "    total = 0\n",
    "    a1 = 0\n",
    "    a0 = 0\n",
    "    error = 0\n",
    "    for record in records:\n",
    "        try:\n",
    "            result_json = '\\n'.join(record[\"repository_context_result_json\"])\n",
    "            #采用正则表达式截取result_json中Feasibility后出现的第一个数字,先匹配Feasibility,再匹配第一个数字\n",
    "            # additional_context_required = re.search(r'\"Additional_context_required\": \"(\\d)\"', result_json).group(1)\n",
    "            additional_context_required = re.search(r'(\\d+)', result_json.split(\"Additional_context_required\")[1]).group(0)\n",
    "            if additional_context_required == \"1\":\n",
    "                _records.append(record)\n",
    "                a1 += 1\n",
    "            elif additional_context_required == \"0\": \n",
    "                # _records.append(record)\n",
    "                a0 += 1\n",
    "            else: error += 1\n",
    "            total += 1\n",
    "        except:\n",
    "            pass\n",
    "    print(f\"total: {total}, f1: {a1}, f0: {a0}, error: {error}\")\n",
    "    with open(output_file, \"w\") as f1:\n",
    "        json.dump(_records, f1, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing `json` enables handling of structured data, parsing JSON files, and serializing data. It provides methods for encoding, decoding, and validating JSON data, ensuring proper formatting and security through features like `json.dumps()` with `indent` and `ensure_ascii`, while maintaining compatibility with different text encodings.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "result_json = [\n",
    "                \"{\\\"Summary\\\": \\\"Importing `json` enables handling of structured data, parsing JSON files, and serializing data. It provides methods for encoding, decoding, and validating JSON data, ensuring proper formatting and security through features like `json.dumps()` with `indent` and `ensure_ascii`, while maintaining compatibility with different text encodings.\\\"}\",\n",
    "            ]\n",
    "result_json = '\\n'.join(result_json)\n",
    "additional_context_required = re.search(r'(\\d+)', result_json.split(\"Additional_context_required\")[1]).group(0)\n",
    "element_name_to_retrieve = re.search(r'[a-zA-Z_]+', result_json.split(\"Element_name_to_retrieve\")[1]).group(0)\n",
    "details_to_retrieve = re.search(r'\"Details_to_retrieve\"\\s*:\\s*\"((?:[^\"\\\\]|\\\\.)*)\"', result_json).group(1)\n",
    "print(additional_context_required)\n",
    "print(element_name_to_retrieve)\n",
    "print(details_to_retrieve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "line = \"dfasdjfklasdhlkf\"\n",
    "print(line.index(\"jfk\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing `json` enables handling of structured data, parsing JSON files, and serializing data. It provides methods for encoding, decoding, and validating JSON data, ensuring proper formatting and security through features like `json.dumps()` with `indent` and `ensure_ascii`, while maintaining compatibility with different text encodings.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "result_json = [\n",
    "                \"{\\\"Summary\\\": \\\"Importing `json` enables handling of structured data, parsing JSON files, and serializing data. It provides methods for encoding, decoding, and validating JSON data, ensuring proper formatting and security through features like `json.dumps()` with `indent` and `ensure_ascii`, while maintaining compatibility with different text encodings.\\\"}\",\n",
    "            ]\n",
    "result_json = '\\n'.join(result_json)\n",
    "\n",
    "def get_json_value_string(str, key):\n",
    "        try:\n",
    "            return re.search(rf'\"{key}\"\\s*:\\s*\"((?:[^\"\\\\]|\\\\.)*)\"', str).group(1)\n",
    "        except:\n",
    "            return \"\"\n",
    "        \n",
    "str = get_json_value_string(result_json, \"Summary\")\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import traceback\n",
    "config = {\n",
    "    \"dataset_path\": \"/mnt/ssd2/wangke/dataset/AgentRefiner/datasets/CR_and_CRN.json\",\n",
    "    \"output_path\": \"/mnt/ssd2/wangke/dataset/AgentRefiner/datasets/CR_and_CRN_estimated.json\"\n",
    "}\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = re.sub(r'\\W+','', text)\n",
    "    return text\n",
    "\n",
    "with open(config[\"dataset_path\"], \"r\") as f:\n",
    "    records = [json.loads(line) for line in f]\n",
    "    for record in records:\n",
    "        try:\n",
    "            if record[\"review\"].find(\"suggestion\") != -1:#含有suggestion的不太可能需要上下文\n",
    "                continue\n",
    "\n",
    "            if record[\"repo_context_dependency_estimation\"][\"Additional_context_required\"] == \"0\":\n",
    "                continue\n",
    "            old = record[\"old\"]\n",
    "\n",
    "            comment = record[\"comment\"]\n",
    "            diff_hunk_lines = comment[\"diff_hunk\"].split('\\n')\n",
    "            start = int(re.findall(r'(\\d+)', diff_hunk_lines[0])[2])\n",
    "            if comment[\"original_start_line\"] and comment[\"original_start_line\"]-start+1 < len(diff_hunk_lines):\n",
    "                comment[\"review_hunk_start_line\"] = diff_hunk_lines[comment[\"original_start_line\"]-start+1][1:] #加1是因为第一行是code_diff_hunk的prefix\n",
    "            index = len(diff_hunk_lines)-1 # 指向review_position_line\n",
    "            for i in range(index, -1, -1):\n",
    "                line = diff_hunk_lines[i][1:]\n",
    "                if line:\n",
    "                    comment[\"review_position_line\"] = line\n",
    "                    break\n",
    "\n",
    "            review_line = record[\"comment\"][\"review_position_line\"]\n",
    "            flag = False\n",
    "            for line in old.split(\"\\n\"):\n",
    "                if normalize_text(line) == normalize_text(review_line):\n",
    "                    flag = True\n",
    "                    break\n",
    "            if not flag: continue\n",
    "            with open(config[\"output_path\"], \"a\") as f0:\n",
    "                f0.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "        except Exception as e:\n",
    "             print(e)\n",
    "             traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "config = {\n",
    "    \"dataset_path\": \"/mnt/ssd2/wangke/dataset/AgentRefiner/datasets/CR_and_CRN_4_6.json\",\n",
    "    # \"dataset_path\": \"/mnt/ssd2/wangke/dataset/AgentRefiner/result_4_6.json\",\n",
    "    \"output_path\": \"/mnt/ssd2/wangke/dataset/AgentRefiner/tmp_result.json\"\n",
    "}\n",
    "with open(config[\"dataset_path\"], \"r\") as f:\n",
    "    records = [json.loads(line) for line in f]\n",
    "    print(len(records))\n",
    "    record = records[11]\n",
    "\n",
    "with open(config[\"output_path\"], \"w\") as f1:\n",
    "    json.dump(record, f1, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from getProjectCommitState import CLBPP\n",
    "\n",
    "config = {\n",
    "    \"dataset_path\": \"/mnt/ssd2/wangke/dataset/datasets.json\",\n",
    "    \"output_path\": \"/mnt/ssd2/wangke/dataset/AgentRefiner/datasets/new_datasets.json\"\n",
    "}\n",
    "\n",
    "with open(config[\"dataset_path\"], \"r\") as f:\n",
    "    records = [json.loads(line) for line in f]\n",
    "    for record in records:\n",
    "        if record[\"_id\"] <= 1937: continue\n",
    "        try:\n",
    "            record = CLBPP(record)\n",
    "        except Exception as e:\n",
    "            id = record[\"_id\"]\n",
    "            print(f\"Error in processing {id}\")\n",
    "            print(e)\n",
    "            continue\n",
    "        with open(config[\"output_path\"], \"a\") as f:\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "# with open(config[\"output_path\"], \"r\") as f:\n",
    "#     records = [json.loads(line) for line in f]\n",
    "#     print(len(records))\n",
    "#     print(records[-1][\"_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: reference is not a tree: a99a729c6b62980a5d2dfaa4960f6d067de381f6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git checkout a99a729c6b62980a5d2dfaa4960f6d067de381f6 failed. Fetching parent commit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: reference is not a tree: 351e83b93a4ec6daecbcef4584ea5bde4531308e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git checkout 351e83b93a4ec6daecbcef4584ea5bde4531308e failed. Fetching parent commit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: reference is not a tree: ffd18e02af436542d098107ed0220df24bbe7126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git checkout ffd18e02af436542d098107ed0220df24bbe7126 failed. Fetching parent commit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: reference is not a tree: d5646985a2ac9adeec16fc024c817383c88a6291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git checkout d5646985a2ac9adeec16fc024c817383c88a6291 failed. Fetching parent commit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: reference is not a tree: c110a125f9096ff9c4d758368388a905519427c9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git checkout c110a125f9096ff9c4d758368388a905519427c9 failed. Fetching parent commit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: reference is not a tree: 106b6c7c571247a2c5f9654aa2034fcdbcc9f7c5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git checkout 106b6c7c571247a2c5f9654aa2034fcdbcc9f7c5 failed. Fetching parent commit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: reference is not a tree: 2722754fea454382301fe5a20d7c6319cb54ba54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git checkout 2722754fea454382301fe5a20d7c6319cb54ba54 failed. Fetching parent commit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: reference is not a tree: b7f49aeda933137c4a387a8ef9f79d854977cbb0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git checkout b7f49aeda933137c4a387a8ef9f79d854977cbb0 failed. Fetching parent commit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: reference is not a tree: fb1b7a72d0dc9e68948d536dfba3973db044c37d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git checkout fb1b7a72d0dc9e68948d536dfba3973db044c37d failed. Fetching parent commit.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: reference is not a tree: 6991fb0dbf8be5263207287a7677c7ac1b8ddd05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git checkout 6991fb0dbf8be5263207287a7677c7ac1b8ddd05 failed. Fetching parent commit.\n",
      "Successfully checked out to commit 6c92c5a539276d387b85eedc89be1f888962647d after 10 searches\n",
      "Untracked files and dirs cleaned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: switching to '6c92c5a539276d387b85eedc89be1f888962647d'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by switching back to a branch.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -c with the switch command. Example:\n",
      "\n",
      "  git switch -c <new-branch-name>\n",
      "\n",
      "Or undo this operation with:\n",
      "\n",
      "  git switch -\n",
      "\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\n",
      "\n",
      "HEAD is now at 6c92c5a5 [pre-commit.ci] pre-commit autoupdate (#12542)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied patch for machine_learning/ridge_regression.py commit_info:6991fb0dbf8be5263207287a7677c7ac1b8ddd05\n",
      "Applied patch for machine_learning/ridge_regression.py commit_info:fb1b7a72d0dc9e68948d536dfba3973db044c37d\n",
      "Applied patch for machine_learning/ridge_regression.py commit_info:b7f49aeda933137c4a387a8ef9f79d854977cbb0\n",
      "Applied patch for machine_learning/ridge_regression.py commit_info:2722754fea454382301fe5a20d7c6319cb54ba54\n",
      "Applied patch for machine_learning/ridge_regression.py commit_info:106b6c7c571247a2c5f9654aa2034fcdbcc9f7c5\n",
      "Applied patch for machine_learning/ridge_regression.py commit_info:c110a125f9096ff9c4d758368388a905519427c9\n",
      "Applied patch for machine_learning/ridge_regression.py commit_info:d5646985a2ac9adeec16fc024c817383c88a6291\n",
      "Applied patch for machine_learning/ridge_regression.py commit_info:ffd18e02af436542d098107ed0220df24bbe7126\n",
      "Applied patch for machine_learning/ridge_regression.py commit_info:351e83b93a4ec6daecbcef4584ea5bde4531308e\n",
      "Applied patch for machine_learning/ridge_regression.py commit_info:a99a729c6b62980a5d2dfaa4960f6d067de381f6\n",
      "Successfully processed record 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:SEND Error: Host unreachable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find definition: numpy in /home/wangke/venv/alpaca-lora/lib/python3.10/site-packages/numpy/__init__.py\n",
      "Find definition: numpy in /home/wangke/venv/alpaca-lora/lib/python3.10/site-packages/numpy/__init__.py\n",
      "Find definition: matplotlib in /home/wangke/venv/alpaca-lora/lib/python3.10/site-packages/matplotlib/__init__.py\n",
      "Find definition: pyplot in /home/wangke/venv/alpaca-lora/lib/python3.10/site-packages/matplotlib/pyplot.py\n",
      "Find definition: pyplot in /home/wangke/venv/alpaca-lora/lib/python3.10/site-packages/matplotlib/pyplot.py\n",
      "No definition found in /mnt/ssd2/wangke/CR_data/repo/Python/machine_learning/ridge_regression.py at (4,6)\n",
      "No definition found in /mnt/ssd2/wangke/CR_data/repo/Python/machine_learning/ridge_regression.py at (4,21)\n",
      "[{'name': 'numpy', 'path': 'numpy', 'type': 'module', 'text': '\"\"\"\\nNumPy\\n=====\\n\\nProvides\\n  1. An array object of arbitrary homogeneous items\\n  2. Fast mathematical operations over arrays\\n  3. Linear Algebra, Fourier Transforms, Random Number Generation\\n\\nHow to use the documentation\\n----------------------------\\nDocumentation is available in two forms: docstrings provided\\nwith the code, and a loose standing reference guide, available from\\n`the NumPy homepage <https://numpy.org>`_.\\n\\nWe recommend exploring the docstrings using\\n`IPython <https://ipython.org>`_, an advanced Python shell with\\nTAB-completion and introspection capabilities.  See below for further\\ninstructions.\\n\\nThe docstring examples assume that `numpy` has been imported as ``np``::\\n\\n  >>> import numpy as np\\n\\nCode snippets are indicated by three greater-than signs::\\n\\n  >>> x = 42\\n  >>> x = x + 1\\n\\nUse the built-in ``help`` function to view a function\\'s docstring::\\n\\n  >>> help(np.sort)\\n  ... # doctest: +SKIP\\n\\nFor some objects, ``np.info(obj)`` may provide additional help.  This is\\nparticularly true if you see the line \"Help on ufunc object:\" at the top\\nof the help() page.  Ufuncs are implemented in C, not Python, for speed.\\nThe native Python help() does not know how to view their help, but our\\nnp.info() function does.\\n\\nTo search for documents containing a keyword, do::\\n\\n  >>> np.lookfor(\\'keyword\\')\\n  ... # doctest: +SKIP\\n\\nGeneral-purpose documents like a glossary and help on the basic concepts\\nof numpy are available under the ``doc`` sub-module::\\n\\n  >>> from numpy import doc\\n  >>> help(doc)\\n  ... # doctest: +SKIP\\n\\nAvailable subpackages\\n---------------------\\nlib\\n    Basic functions used by several sub-packages.\\nrandom\\n    Core Random Tools\\nlinalg\\n    Core Linear Algebra Tools\\nfft\\n    Core FFT routines\\npolynomial\\n    Polynomial tools\\ntesting\\n    NumPy testing tools\\ndistutils\\n    Enhancements to distutils with support for\\n    Fortran compilers support and more  (for Python <= 3.11).\\n\\nUtilities\\n---------\\ntest\\n    Run numpy unittests\\nshow_config\\n    Show numpy build configuration\\nmatlib\\n    Make everything matrices.\\n__version__\\n    NumPy version string\\n\\nViewing documentation using IPython\\n-----------------------------------\\n\\nStart IPython and import `numpy` usually under the alias ``np``: `import\\nnumpy as np`.  Then, directly past or use the ``%cpaste`` magic to paste\\nexamples into the shell.  To see which functions are available in `numpy`,\\ntype ``np.<TAB>`` (where ``<TAB>`` refers to the TAB key), or use\\n``np.*cos*?<ENTER>`` (where ``<ENTER>`` refers to the ENTER key) to narrow\\ndown the list.  To view the docstring for a function, use\\n``np.cos?<ENTER>`` (to view the docstring) and ``np.cos??<ENTER>`` (to view\\nthe source code).\\n\\nCopies vs. in-place operation\\n-----------------------------\\nMost of the functions in `numpy` return a copy of the array argument\\n(e.g., `np.sort`).  In-place versions of these functions are often\\navailable as array methods, i.e. ``x = np.array([1,2,3]); x.sort()``.\\nExceptions to this rule are documented.\\n\\n\"\"\"\\nimport sys\\nimport warnings\\n\\nfrom ._globals import _NoValue, _CopyMode\\n# These exceptions were moved in 1.25 and are hidden from __dir__()\\nfrom .exceptions import (\\n    ComplexWarning, ModuleDeprecationWarning, VisibleDeprecationWarning,\\n    TooHardError, AxisError)\\n\\n\\n# If a version with git hash was stored, use that instead\\nfrom . import version\\nfrom .version import __version__\\n\\n# We first need to detect if we\\'re being called as part of the numpy setup\\n# procedure itself in a reliable manner.\\ntry:\\n    __NUMPY_SETUP__\\nexcept NameError:\\n    __NUMPY_SETUP__ = False\\n\\nif __NUMPY_SETUP__:\\n    sys.stderr.write(\\'Running from numpy source directory.\\\\n\\')\\nelse:\\n    # Allow distributors to run custom init code before importing numpy.core\\n    from . import _distributor_init\\n\\n    try:\\n        from numpy.__config__ import show as show_config\\n    except ImportError as e:\\n        msg = \"\"\"Error importing numpy: you should not try to import numpy from\\n        its source directory; please exit the numpy source tree, and relaunch\\n        your python interpreter from there.\"\"\"\\n        raise ImportError(msg) from e\\n\\n    __all__ = [\\n        \\'exceptions\\', \\'ModuleDeprecationWarning\\', \\'VisibleDeprecationWarning\\',\\n        \\'ComplexWarning\\', \\'TooHardError\\', \\'AxisError\\']\\n\\n    # mapping of {name: (value, deprecation_msg)}\\n    __deprecated_attrs__ = {}\\n\\n    from . import core\\n    from .core import *\\n    from . import compat\\n    from . import exceptions\\n    from . import dtypes\\n    from . import lib\\n    # NOTE: to be revisited following future namespace cleanup.\\n    # See gh-14454 and gh-15672 for discussion.\\n    from .lib import *\\n\\n    from . import linalg\\n    from . import fft\\n    from . import polynomial\\n    from . import random\\n    from . import ctypeslib\\n    from . import ma\\n    from . import matrixlib as _mat\\n    from .matrixlib import *\\n\\n    # Deprecations introduced in NumPy 1.20.0, 2020-06-06\\n    import builtins as _builtins\\n\\n    _msg = (\\n        \"module \\'numpy\\' has no attribute \\'{n}\\'.\\\\n\"\\n        \"`np.{n}` was a deprecated alias for the builtin `{n}`. \"\\n        \"To avoid this error in existing code, use `{n}` by itself. \"\\n        \"Doing this will not modify any behavior and is safe. {extended_msg}\\\\n\"\\n        \"The aliases was originally deprecated in NumPy 1.20; for more \"\\n        \"details and guidance see the original release note at:\\\\n\"\\n        \"    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\")\\n\\n    _specific_msg = (\\n        \"If you specifically wanted the numpy scalar type, use `np.{}` here.\")\\n\\n    _int_extended_msg = (\\n        \"When replacing `np.{}`, you may wish to use e.g. `np.int64` \"\\n        \"or `np.int32` to specify the precision. If you wish to review \"\\n        \"your current use, check the release note link for \"\\n        \"additional information.\")\\n\\n    _type_info = [\\n        (\"object\", \"\"),  # The NumPy scalar only exists by name.\\n        (\"bool\", _specific_msg.format(\"bool_\")),\\n        (\"float\", _specific_msg.format(\"float64\")),\\n        (\"complex\", _specific_msg.format(\"complex128\")),\\n        (\"str\", _specific_msg.format(\"str_\")),\\n        (\"int\", _int_extended_msg.format(\"int\"))]\\n\\n    __former_attrs__ = {\\n         n: _msg.format(n=n, extended_msg=extended_msg)\\n         for n, extended_msg in _type_info\\n     }\\n\\n    # Future warning introduced in NumPy 1.24.0, 2022-11-17\\n    _msg = (\\n        \"`np.{n}` is a deprecated alias for `{an}`.  (Deprecated NumPy 1.24)\")\\n\\n    # Some of these are awkward (since `np.str` may be preferable in the long\\n    # term), but overall the names ending in 0 seem undesirable\\n    _type_info = [\\n        (\"bool8\", bool_, \"np.bool_\"),\\n        (\"int0\", intp, \"np.intp\"),\\n        (\"uint0\", uintp, \"np.uintp\"),\\n        (\"str0\", str_, \"np.str_\"),\\n        (\"bytes0\", bytes_, \"np.bytes_\"),\\n        (\"void0\", void, \"np.void\"),\\n        (\"object0\", object_,\\n            \"`np.object0` is a deprecated alias for `np.object_`. \"\\n            \"`object` can be used instead.  (Deprecated NumPy 1.24)\")]\\n\\n    # Some of these could be defined right away, but most were aliases to\\n    # the Python objects and only removed in NumPy 1.24.  Defining them should\\n    # probably wait for NumPy 1.26 or 2.0.\\n    # When defined, these should possibly not be added to `__all__` to avoid\\n    # import with `from numpy import *`.\\n    __future_scalars__ = {\"bool\", \"long\", \"ulong\", \"str\", \"bytes\", \"object\"}\\n\\n    __deprecated_attrs__.update({\\n        n: (alias, _msg.format(n=n, an=an)) for n, alias, an in _type_info})\\n\\n    import math\\n\\n    __deprecated_attrs__[\\'math\\'] = (math,\\n        \"`np.math` is a deprecated alias for the standard library `math` \"\\n        \"module (Deprecated Numpy 1.25). Replace usages of `np.math` with \"\\n        \"`math`\")\\n\\n    del math, _msg, _type_info\\n\\n    from .core import abs\\n    # now that numpy modules are imported, can initialize limits\\n    core.getlimits._register_known_types()\\n\\n    __all__.extend([\\'__version__\\', \\'show_config\\'])\\n    __all__.extend(core.__all__)\\n    __all__.extend(_mat.__all__)\\n    __all__.extend(lib.__all__)\\n    __all__.extend([\\'linalg\\', \\'fft\\', \\'random\\', \\'ctypeslib\\', \\'ma\\'])\\n\\n    # Remove min and max from __all__ to avoid `from numpy import *` override\\n    # the builtins min/max. Temporary fix for 1.25.x/1.26.x, see gh-24229.\\n    __all__.remove(\\'min\\')\\n    __all__.remove(\\'max\\')\\n    __all__.remove(\\'round\\')\\n\\n    # Remove one of the two occurrences of `issubdtype`, which is exposed as\\n    # both `numpy.core.issubdtype` and `numpy.lib.issubdtype`.\\n    __all__.remove(\\'issubdtype\\')\\n\\n    # These are exported by np.core, but are replaced by the builtins below\\n    # remove them to ensure that we don\\'t end up with `np.long == np.int_`,\\n    # which would be a breaking change.\\n    del long, unicode\\n    __all__.remove(\\'long\\')\\n    __all__.remove(\\'unicode\\')\\n\\n    # Remove things that are in the numpy.lib but not in the numpy namespace\\n    # Note that there is a test (numpy/tests/test_public_api.py:test_numpy_namespace)\\n    # that prevents adding more things to the main namespace by accident.\\n    # The list below will grow until the `from .lib import *` fixme above is\\n    # taken care of\\n    __all__.remove(\\'Arrayterator\\')\\n    del Arrayterator\\n\\n    # These names were removed in NumPy 1.20.  For at least one release,\\n    # attempts to access these names in the numpy namespace will trigger\\n    # a warning, and calling the function will raise an exception.\\n    _financial_names = [\\'fv\\', \\'ipmt\\', \\'irr\\', \\'mirr\\', \\'nper\\', \\'npv\\', \\'pmt\\',\\n                        \\'ppmt\\', \\'pv\\', \\'rate\\']\\n    __expired_functions__ = {\\n        name: (f\\'In accordance with NEP 32, the function {name} was removed \\'\\n               \\'from NumPy version 1.20.  A replacement for this function \\'\\n               \\'is available in the numpy_financial library: \\'\\n               \\'https://pypi.org/project/numpy-financial\\')\\n        for name in _financial_names}\\n\\n    # Filter out Cython harmless warnings\\n    warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\\n    warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\\n    warnings.filterwarnings(\"ignore\", message=\"numpy.ndarray size changed\")\\n\\n    # oldnumeric and numarray were removed in 1.9. In case some packages import\\n    # but do not use them, we define them here for backward compatibility.\\n    oldnumeric = \\'removed\\'\\n    numarray = \\'removed\\'\\n\\n    def __getattr__(attr):\\n        # Warn for expired attributes, and return a dummy function\\n        # that always raises an exception.\\n        import warnings\\n        import math\\n        try:\\n            msg = __expired_functions__[attr]\\n        except KeyError:\\n            pass\\n        else:\\n            warnings.warn(msg, DeprecationWarning, stacklevel=2)\\n\\n            def _expired(*args, **kwds):\\n                raise RuntimeError(msg)\\n\\n            return _expired\\n\\n        # Emit warnings for deprecated attributes\\n        try:\\n            val, msg = __deprecated_attrs__[attr]\\n        except KeyError:\\n            pass\\n        else:\\n            warnings.warn(msg, DeprecationWarning, stacklevel=2)\\n            return val\\n\\n        if attr in __future_scalars__:\\n            # And future warnings for those that will change, but also give\\n            # the AttributeError\\n            warnings.warn(\\n                f\"In the future `np.{attr}` will be defined as the \"\\n                \"corresponding NumPy scalar.\", FutureWarning, stacklevel=2)\\n\\n        if attr in __former_attrs__:\\n            raise AttributeError(__former_attrs__[attr])\\n\\n        if attr == \\'testing\\':\\n            import numpy.testing as testing\\n            return testing\\n        elif attr == \\'Tester\\':\\n            \"Removed in NumPy 1.25.0\"\\n            raise RuntimeError(\"Tester was removed in NumPy 1.25.\")\\n\\n        raise AttributeError(\"module {!r} has no attribute \"\\n                             \"{!r}\".format(__name__, attr))\\n\\n    def __dir__():\\n        public_symbols = globals().keys() | {\\'testing\\'}\\n        public_symbols -= {\\n            \"core\", \"matrixlib\",\\n            # These were moved in 1.25 and may be deprecated eventually:\\n            \"ModuleDeprecationWarning\", \"VisibleDeprecationWarning\",\\n            \"ComplexWarning\", \"TooHardError\", \"AxisError\"\\n        }\\n        return list(public_symbols)\\n\\n    # Pytest testing\\n    from numpy._pytesttester import PytestTester\\n    test = PytestTester(__name__)\\n    del PytestTester\\n\\n    def _sanity_check():\\n        \"\"\"\\n        Quick sanity checks for common bugs caused by environment.\\n        There are some cases e.g. with wrong BLAS ABI that cause wrong\\n        results under specific runtime conditions that are not necessarily\\n        achieved during test suite runs, and it is useful to catch those early.\\n\\n        See https://github.com/numpy/numpy/issues/8577 and other\\n        similar bug reports.\\n\\n        \"\"\"\\n        try:\\n            x = ones(2, dtype=float32)\\n            if not abs(x.dot(x) - float32(2.0)) < 1e-5:\\n                raise AssertionError()\\n        except AssertionError:\\n            msg = (\"The current Numpy installation ({!r}) fails to \"\\n                   \"pass simple sanity checks. This can be caused for example \"\\n                   \"by incorrect BLAS library being linked in, or by mixing \"\\n                   \"package managers (pip, conda, apt, ...). Search closed \"\\n                   \"numpy issues for similar problems.\")\\n            raise RuntimeError(msg.format(__file__)) from None\\n\\n    _sanity_check()\\n    del _sanity_check\\n\\n    def _mac_os_check():\\n        \"\"\"\\n        Quick Sanity check for Mac OS look for accelerate build bugs.\\n        Testing numpy polyfit calls init_dgelsd(LAPACK)\\n        \"\"\"\\n        try:\\n            c = array([3., 2., 1.])\\n            x = linspace(0, 2, 5)\\n            y = polyval(c, x)\\n            _ = polyfit(x, y, 2, cov=True)\\n        except ValueError:\\n            pass\\n\\n    if sys.platform == \"darwin\":\\n        from . import exceptions\\n        with warnings.catch_warnings(record=True) as w:\\n            _mac_os_check()\\n            # Throw runtime error, if the test failed Check for warning and error_message\\n            if len(w) > 0:\\n                for _wn in w:\\n                    if _wn.category is exceptions.RankWarning:\\n                        # Ignore other warnings, they may not be relevant (see gh-25433).\\n                        error_message = f\"{_wn.category.__name__}: {str(_wn.message)}\"\\n                        msg = (\\n                            \"Polyfit sanity test emitted a warning, most likely due \"\\n                            \"to using a buggy Accelerate backend.\"\\n                            \"\\\\nIf you compiled yourself, more information is available at:\"\\n                            \"\\\\nhttps://numpy.org/devdocs/building/index.html\"\\n                            \"\\\\nOtherwise report this to the vendor \"\\n                            \"that provided NumPy.\\\\n\\\\n{}\\\\n\".format(error_message))\\n                        raise RuntimeError(msg)\\n                del _wn\\n            del w\\n    del _mac_os_check\\n\\n    # We usually use madvise hugepages support, but on some old kernels it\\n    # is slow and thus better avoided.\\n    # Specifically kernel version 4.6 had a bug fix which probably fixed this:\\n    # https://github.com/torvalds/linux/commit/7cf91a98e607c2f935dbcc177d70011e95b8faff\\n    import os\\n    use_hugepage = os.environ.get(\"NUMPY_MADVISE_HUGEPAGE\", None)\\n    if sys.platform == \"linux\" and use_hugepage is None:\\n        # If there is an issue with parsing the kernel version,\\n        # set use_hugepages to 0. Usage of LooseVersion will handle\\n        # the kernel version parsing better, but avoided since it\\n        # will increase the import time. See: #16679 for related discussion.\\n        try:\\n            use_hugepage = 1\\n            kernel_version = os.uname().release.split(\".\")[:2]\\n            kernel_version = tuple(int(v) for v in kernel_version)\\n            if kernel_version < (4, 6):\\n                use_hugepage = 0\\n        except ValueError:\\n            use_hugepages = 0\\n    elif use_hugepage is None:\\n        # This is not Linux, so it should not matter, just enable anyway\\n        use_hugepage = 1\\n    else:\\n        use_hugepage = int(use_hugepage)\\n\\n    # Note that this will currently only make a difference on Linux\\n    core.multiarray._set_madvise_hugepage(use_hugepage)\\n    del use_hugepage\\n\\n    # Give a warning if NumPy is reloaded or imported on a sub-interpreter\\n    # We do this from python, since the C-module may not be reloaded and\\n    # it is tidier organized.\\n    core.multiarray._multiarray_umath._reload_guard()\\n\\n    # default to \"weak\" promotion for \"NumPy 2\".\\n    core._set_promotion_state(\\n        os.environ.get(\"NPY_PROMOTION_STATE\",\\n                       \"weak\" if _using_numpy2_behavior() else \"legacy\"))\\n\\n    # Tell PyInstaller where to find hook-numpy.py\\n    def _pyinstaller_hooks_dir():\\n        from pathlib import Path\\n        return [str(Path(__file__).with_name(\"_pyinstaller\").resolve())]\\n\\n    # Remove symbols imported for internal use\\n    del os\\n\\n\\n# Remove symbols imported for internal use\\ndel sys, warnings\\n', 'caller': 'default_function'}, {'name': 'matplotlib', 'path': 'matplotlib', 'type': 'module', 'text': '\"\"\"\\nAn object-oriented plotting library.\\n\\nA procedural interface is provided by the companion pyplot module,\\nwhich may be imported directly, e.g.::\\n\\n    import matplotlib.pyplot as plt\\n\\nor using ipython::\\n\\n    ipython\\n\\nat your terminal, followed by::\\n\\n    In [1]: %matplotlib\\n    In [2]: import matplotlib.pyplot as plt\\n\\nat the ipython shell prompt.\\n\\nFor the most part, direct use of the explicit object-oriented library is\\nencouraged when programming; the implicit pyplot interface is primarily for\\nworking interactively. The exceptions to this suggestion are the pyplot\\nfunctions `.pyplot.figure`, `.pyplot.subplot`, `.pyplot.subplots`, and\\n`.pyplot.savefig`, which can greatly simplify scripting.  See\\n:ref:`api_interfaces` for an explanation of the tradeoffs between the implicit\\nand explicit interfaces.\\n\\nModules include:\\n\\n:mod:`matplotlib.axes`\\n    The `~.axes.Axes` class.  Most pyplot functions are wrappers for\\n    `~.axes.Axes` methods.  The axes module is the highest level of OO\\n    access to the library.\\n\\n:mod:`matplotlib.figure`\\n    The `.Figure` class.\\n\\n:mod:`matplotlib.artist`\\n    The `.Artist` base class for all classes that draw things.\\n\\n:mod:`matplotlib.lines`\\n    The `.Line2D` class for drawing lines and markers.\\n\\n:mod:`matplotlib.patches`\\n    Classes for drawing polygons.\\n\\n:mod:`matplotlib.text`\\n    The `.Text` and `.Annotation` classes.\\n\\n:mod:`matplotlib.image`\\n    The `.AxesImage` and `.FigureImage` classes.\\n\\n:mod:`matplotlib.collections`\\n    Classes for efficient drawing of groups of lines or polygons.\\n\\n:mod:`matplotlib.colors`\\n    Color specifications and making colormaps.\\n\\n:mod:`matplotlib.cm`\\n    Colormaps, and the `.ScalarMappable` mixin class for providing color\\n    mapping functionality to other classes.\\n\\n:mod:`matplotlib.ticker`\\n    Calculation of tick mark locations and formatting of tick labels.\\n\\n:mod:`matplotlib.backends`\\n    A subpackage with modules for various GUI libraries and output formats.\\n\\nThe base matplotlib namespace includes:\\n\\n`~matplotlib.rcParams`\\n    Default configuration settings; their defaults may be overridden using\\n    a :file:`matplotlibrc` file.\\n\\n`~matplotlib.use`\\n    Setting the Matplotlib backend.  This should be called before any\\n    figure is created, because it is not possible to switch between\\n    different GUI backends after that.\\n\\nThe following environment variables can be used to customize the behavior:\\n\\n:envvar:`MPLBACKEND`\\n    This optional variable can be set to choose the Matplotlib backend. See\\n    :ref:`what-is-a-backend`.\\n\\n:envvar:`MPLCONFIGDIR`\\n    This is the directory used to store user customizations to\\n    Matplotlib, as well as some caches to improve performance. If\\n    :envvar:`MPLCONFIGDIR` is not defined, :file:`{HOME}/.config/matplotlib`\\n    and :file:`{HOME}/.cache/matplotlib` are used on Linux, and\\n    :file:`{HOME}/.matplotlib` on other platforms, if they are\\n    writable. Otherwise, the Python standard library\\'s `tempfile.gettempdir`\\n    is used to find a base directory in which the :file:`matplotlib`\\n    subdirectory is created.\\n\\nMatplotlib was initially written by John D. Hunter (1968-2012) and is now\\ndeveloped and maintained by a host of others.\\n\\nOccasionally the internal documentation (python docstrings) will refer\\nto MATLAB®, a registered trademark of The MathWorks, Inc.\\n\\n\"\"\"\\n\\n__all__ = [\\n    \"__bibtex__\",\\n    \"__version__\",\\n    \"__version_info__\",\\n    \"set_loglevel\",\\n    \"ExecutableNotFoundError\",\\n    \"get_configdir\",\\n    \"get_cachedir\",\\n    \"get_data_path\",\\n    \"matplotlib_fname\",\\n    \"MatplotlibDeprecationWarning\",\\n    \"RcParams\",\\n    \"rc_params\",\\n    \"rc_params_from_file\",\\n    \"rcParamsDefault\",\\n    \"rcParams\",\\n    \"rcParamsOrig\",\\n    \"defaultParams\",\\n    \"rc\",\\n    \"rcdefaults\",\\n    \"rc_file_defaults\",\\n    \"rc_file\",\\n    \"rc_context\",\\n    \"use\",\\n    \"get_backend\",\\n    \"interactive\",\\n    \"is_interactive\",\\n    \"colormaps\",\\n    \"multivar_colormaps\",\\n    \"bivar_colormaps\",\\n    \"color_sequences\",\\n]\\n\\n\\nimport atexit\\nfrom collections import namedtuple\\nfrom collections.abc import MutableMapping\\nimport contextlib\\nimport functools\\nimport importlib\\nimport inspect\\nfrom inspect import Parameter\\nimport locale\\nimport logging\\nimport os\\nfrom pathlib import Path\\nimport pprint\\nimport re\\nimport shutil\\nimport subprocess\\nimport sys\\nimport tempfile\\n\\nfrom packaging.version import parse as parse_version\\n\\n# cbook must import matplotlib only within function\\n# definitions, so it is safe to import from it here.\\nfrom . import _api, _version, cbook, _docstring, rcsetup\\nfrom matplotlib._api import MatplotlibDeprecationWarning\\nfrom matplotlib.rcsetup import cycler  # noqa: F401\\n\\n\\n_log = logging.getLogger(__name__)\\n\\n__bibtex__ = r\"\"\"@Article{Hunter:2007,\\n  Author    = {Hunter, J. D.},\\n  Title     = {Matplotlib: A 2D graphics environment},\\n  Journal   = {Computing in Science \\\\& Engineering},\\n  Volume    = {9},\\n  Number    = {3},\\n  Pages     = {90--95},\\n  abstract  = {Matplotlib is a 2D graphics package used for Python\\n  for application development, interactive scripting, and\\n  publication-quality image generation across user\\n  interfaces and operating systems.},\\n  publisher = {IEEE COMPUTER SOC},\\n  year      = 2007\\n}\"\"\"\\n\\n# modelled after sys.version_info\\n_VersionInfo = namedtuple(\\'_VersionInfo\\',\\n                          \\'major, minor, micro, releaselevel, serial\\')\\n\\n\\ndef _parse_to_version_info(version_str):\\n    \"\"\"\\n    Parse a version string to a namedtuple analogous to sys.version_info.\\n\\n    See:\\n    https://packaging.pypa.io/en/latest/version.html#packaging.version.parse\\n    https://docs.python.org/3/library/sys.html#sys.version_info\\n    \"\"\"\\n    v = parse_version(version_str)\\n    if v.pre is None and v.post is None and v.dev is None:\\n        return _VersionInfo(v.major, v.minor, v.micro, \\'final\\', 0)\\n    elif v.dev is not None:\\n        return _VersionInfo(v.major, v.minor, v.micro, \\'alpha\\', v.dev)\\n    elif v.pre is not None:\\n        releaselevel = {\\n            \\'a\\': \\'alpha\\',\\n            \\'b\\': \\'beta\\',\\n            \\'rc\\': \\'candidate\\'}.get(v.pre[0], \\'alpha\\')\\n        return _VersionInfo(v.major, v.minor, v.micro, releaselevel, v.pre[1])\\n    else:\\n        # fallback for v.post: guess-next-dev scheme from setuptools_scm\\n        return _VersionInfo(v.major, v.minor, v.micro + 1, \\'alpha\\', v.post)\\n\\n\\ndef _get_version():\\n    \"\"\"Return the version string used for __version__.\"\"\"\\n    # Only shell out to a git subprocess if really needed, i.e. when we are in\\n    # a matplotlib git repo but not in a shallow clone, such as those used by\\n    # CI, as the latter would trigger a warning from setuptools_scm.\\n    root = Path(__file__).resolve().parents[2]\\n    if ((root / \".matplotlib-repo\").exists()\\n            and (root / \".git\").exists()\\n            and not (root / \".git/shallow\").exists()):\\n        try:\\n            import setuptools_scm\\n        except ImportError:\\n            pass\\n        else:\\n            return setuptools_scm.get_version(\\n                root=root,\\n                dist_name=\"matplotlib\",\\n                version_scheme=\"release-branch-semver\",\\n                local_scheme=\"node-and-date\",\\n                fallback_version=_version.version,\\n            )\\n    # Get the version from the _version.py file if not in repo or setuptools_scm is\\n    # unavailable.\\n    return _version.version\\n\\n\\n@_api.caching_module_getattr\\nclass __getattr__:\\n    __version__ = property(lambda self: _get_version())\\n    __version_info__ = property(\\n        lambda self: _parse_to_version_info(self.__version__))\\n\\n\\ndef _check_versions():\\n\\n    # Quickfix to ensure Microsoft Visual C++ redistributable\\n    # DLLs are loaded before importing kiwisolver\\n    from . import ft2font  # noqa: F401\\n\\n    for modname, minver in [\\n            (\"cycler\", \"0.10\"),\\n            (\"dateutil\", \"2.7\"),\\n            (\"kiwisolver\", \"1.3.1\"),\\n            (\"numpy\", \"1.23\"),\\n            (\"pyparsing\", \"2.3.1\"),\\n    ]:\\n        module = importlib.import_module(modname)\\n        if parse_version(module.__version__) < parse_version(minver):\\n            raise ImportError(f\"Matplotlib requires {modname}>={minver}; \"\\n                              f\"you have {module.__version__}\")\\n\\n\\n_check_versions()\\n\\n\\n# The decorator ensures this always returns the same handler (and it is only\\n# attached once).\\n@functools.cache\\ndef _ensure_handler():\\n    \"\"\"\\n    The first time this function is called, attach a `StreamHandler` using the\\n    same format as `logging.basicConfig` to the Matplotlib root logger.\\n\\n    Return this handler every time this function is called.\\n    \"\"\"\\n    handler = logging.StreamHandler()\\n    handler.setFormatter(logging.Formatter(logging.BASIC_FORMAT))\\n    _log.addHandler(handler)\\n    return handler\\n\\n\\ndef set_loglevel(level):\\n    \"\"\"\\n    Configure Matplotlib\\'s logging levels.\\n\\n    Matplotlib uses the standard library `logging` framework under the root\\n    logger \\'matplotlib\\'.  This is a helper function to:\\n\\n    - set Matplotlib\\'s root logger level\\n    - set the root logger handler\\'s level, creating the handler\\n      if it does not exist yet\\n\\n    Typically, one should call ``set_loglevel(\"info\")`` or\\n    ``set_loglevel(\"debug\")`` to get additional debugging information.\\n\\n    Users or applications that are installing their own logging handlers\\n    may want to directly manipulate ``logging.getLogger(\\'matplotlib\\')`` rather\\n    than use this function.\\n\\n    Parameters\\n    ----------\\n    level : {\"notset\", \"debug\", \"info\", \"warning\", \"error\", \"critical\"}\\n        The log level of the handler.\\n\\n    Notes\\n    -----\\n    The first time this function is called, an additional handler is attached\\n    to Matplotlib\\'s root handler; this handler is reused every time and this\\n    function simply manipulates the logger and handler\\'s level.\\n\\n    \"\"\"\\n    _log.setLevel(level.upper())\\n    _ensure_handler().setLevel(level.upper())\\n\\n\\ndef _logged_cached(fmt, func=None):\\n    \"\"\"\\n    Decorator that logs a function\\'s return value, and memoizes that value.\\n\\n    After ::\\n\\n        @_logged_cached(fmt)\\n        def func(): ...\\n\\n    the first call to *func* will log its return value at the DEBUG level using\\n    %-format string *fmt*, and memoize it; later calls to *func* will directly\\n    return that value.\\n    \"\"\"\\n    if func is None:  # Return the actual decorator.\\n        return functools.partial(_logged_cached, fmt)\\n\\n    called = False\\n    ret = None\\n\\n    @functools.wraps(func)\\n    def wrapper(**kwargs):\\n        nonlocal called, ret\\n        if not called:\\n            ret = func(**kwargs)\\n            called = True\\n            _log.debug(fmt, ret)\\n        return ret\\n\\n    return wrapper\\n\\n\\n_ExecInfo = namedtuple(\"_ExecInfo\", \"executable raw_version version\")\\n\\n\\nclass ExecutableNotFoundError(FileNotFoundError):\\n    \"\"\"\\n    Error raised when an executable that Matplotlib optionally\\n    depends on can\\'t be found.\\n    \"\"\"\\n    pass\\n\\n\\n@functools.cache\\ndef _get_executable_info(name):\\n    \"\"\"\\n    Get the version of some executable that Matplotlib optionally depends on.\\n\\n    .. warning::\\n       The list of executables that this function supports is set according to\\n       Matplotlib\\'s internal needs, and may change without notice.\\n\\n    Parameters\\n    ----------\\n    name : str\\n        The executable to query.  The following values are currently supported:\\n        \"dvipng\", \"gs\", \"inkscape\", \"magick\", \"pdftocairo\", \"pdftops\".  This\\n        list is subject to change without notice.\\n\\n    Returns\\n    -------\\n    tuple\\n        A namedtuple with fields ``executable`` (`str`) and ``version``\\n        (`packaging.Version`, or ``None`` if the version cannot be determined).\\n\\n    Raises\\n    ------\\n    ExecutableNotFoundError\\n        If the executable is not found or older than the oldest version\\n        supported by Matplotlib.  For debugging purposes, it is also\\n        possible to \"hide\" an executable from Matplotlib by adding it to the\\n        :envvar:`_MPLHIDEEXECUTABLES` environment variable (a comma-separated\\n        list), which must be set prior to any calls to this function.\\n    ValueError\\n        If the executable is not one that we know how to query.\\n    \"\"\"\\n\\n    def impl(args, regex, min_ver=None, ignore_exit_code=False):\\n        # Execute the subprocess specified by args; capture stdout and stderr.\\n        # Search for a regex match in the output; if the match succeeds, the\\n        # first group of the match is the version.\\n        # Return an _ExecInfo if the executable exists, and has a version of\\n        # at least min_ver (if set); else, raise ExecutableNotFoundError.\\n        try:\\n            output = subprocess.check_output(\\n                args, stderr=subprocess.STDOUT,\\n                text=True, errors=\"replace\")\\n        except subprocess.CalledProcessError as _cpe:\\n            if ignore_exit_code:\\n                output = _cpe.output\\n            else:\\n                raise ExecutableNotFoundError(str(_cpe)) from _cpe\\n        except OSError as _ose:\\n            raise ExecutableNotFoundError(str(_ose)) from _ose\\n        match = re.search(regex, output)\\n        if match:\\n            raw_version = match.group(1)\\n            version = parse_version(raw_version)\\n            if min_ver is not None and version < parse_version(min_ver):\\n                raise ExecutableNotFoundError(\\n                    f\"You have {args[0]} version {version} but the minimum \"\\n                    f\"version supported by Matplotlib is {min_ver}\")\\n            return _ExecInfo(args[0], raw_version, version)\\n        else:\\n            raise ExecutableNotFoundError(\\n                f\"Failed to determine the version of {args[0]} from \"\\n                f\"{\\' \\'.join(args)}, which output {output}\")\\n\\n    if name in os.environ.get(\"_MPLHIDEEXECUTABLES\", \"\").split(\",\"):\\n        raise ExecutableNotFoundError(f\"{name} was hidden\")\\n\\n    if name == \"dvipng\":\\n        return impl([\"dvipng\", \"-version\"], \"(?m)^dvipng(?: .*)? (.+)\", \"1.6\")\\n    elif name == \"gs\":\\n        execs = ([\"gswin32c\", \"gswin64c\", \"mgs\", \"gs\"]  # \"mgs\" for miktex.\\n                 if sys.platform == \"win32\" else\\n                 [\"gs\"])\\n        for e in execs:\\n            try:\\n                return impl([e, \"--version\"], \"(.*)\", \"9\")\\n            except ExecutableNotFoundError:\\n                pass\\n        message = \"Failed to find a Ghostscript installation\"\\n        raise ExecutableNotFoundError(message)\\n    elif name == \"inkscape\":\\n        try:\\n            # Try headless option first (needed for Inkscape version < 1.0):\\n            return impl([\"inkscape\", \"--without-gui\", \"-V\"],\\n                        \"Inkscape ([^ ]*)\")\\n        except ExecutableNotFoundError:\\n            pass  # Suppress exception chaining.\\n        # If --without-gui is not accepted, we may be using Inkscape >= 1.0 so\\n        # try without it:\\n        return impl([\"inkscape\", \"-V\"], \"Inkscape ([^ ]*)\")\\n    elif name == \"magick\":\\n        if sys.platform == \"win32\":\\n            # Check the registry to avoid confusing ImageMagick\\'s convert with\\n            # Windows\\'s builtin convert.exe.\\n            import winreg\\n            binpath = \"\"\\n            for flag in [0, winreg.KEY_WOW64_32KEY, winreg.KEY_WOW64_64KEY]:\\n                try:\\n                    with winreg.OpenKeyEx(\\n                            winreg.HKEY_LOCAL_MACHINE,\\n                            r\"Software\\\\Imagemagick\\\\Current\",\\n                            0, winreg.KEY_QUERY_VALUE | flag) as hkey:\\n                        binpath = winreg.QueryValueEx(hkey, \"BinPath\")[0]\\n                except OSError:\\n                    pass\\n            path = None\\n            if binpath:\\n                for name in [\"convert.exe\", \"magick.exe\"]:\\n                    candidate = Path(binpath, name)\\n                    if candidate.exists():\\n                        path = str(candidate)\\n                        break\\n            if path is None:\\n                raise ExecutableNotFoundError(\\n                    \"Failed to find an ImageMagick installation\")\\n        else:\\n            path = \"convert\"\\n        info = impl([path, \"--version\"], r\"^Version: ImageMagick (\\\\S*)\")\\n        if info.raw_version == \"7.0.10-34\":\\n            # https://github.com/ImageMagick/ImageMagick/issues/2720\\n            raise ExecutableNotFoundError(\\n                f\"You have ImageMagick {info.version}, which is unsupported\")\\n        return info\\n    elif name == \"pdftocairo\":\\n        return impl([\"pdftocairo\", \"-v\"], \"pdftocairo version (.*)\")\\n    elif name == \"pdftops\":\\n        info = impl([\"pdftops\", \"-v\"], \"^pdftops version (.*)\",\\n                    ignore_exit_code=True)\\n        if info and not (\\n                3 <= info.version.major or\\n                # poppler version numbers.\\n                parse_version(\"0.9\") <= info.version < parse_version(\"1.0\")):\\n            raise ExecutableNotFoundError(\\n                f\"You have pdftops version {info.version} but the minimum \"\\n                f\"version supported by Matplotlib is 3.0\")\\n        return info\\n    else:\\n        raise ValueError(f\"Unknown executable: {name!r}\")\\n\\n\\ndef _get_xdg_config_dir():\\n    \"\"\"\\n    Return the XDG configuration directory, according to the XDG base\\n    directory spec:\\n\\n    https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html\\n    \"\"\"\\n    return os.environ.get(\\'XDG_CONFIG_HOME\\') or str(Path.home() / \".config\")\\n\\n\\ndef _get_xdg_cache_dir():\\n    \"\"\"\\n    Return the XDG cache directory, according to the XDG base directory spec:\\n\\n    https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html\\n    \"\"\"\\n    return os.environ.get(\\'XDG_CACHE_HOME\\') or str(Path.home() / \".cache\")\\n\\n\\ndef _get_config_or_cache_dir(xdg_base_getter):\\n    configdir = os.environ.get(\\'MPLCONFIGDIR\\')\\n    if configdir:\\n        configdir = Path(configdir)\\n    elif sys.platform.startswith((\\'linux\\', \\'freebsd\\')):\\n        # Only call _xdg_base_getter here so that MPLCONFIGDIR is tried first,\\n        # as _xdg_base_getter can throw.\\n        configdir = Path(xdg_base_getter(), \"matplotlib\")\\n    else:\\n        configdir = Path.home() / \".matplotlib\"\\n    # Resolve the path to handle potential issues with inaccessible symlinks.\\n    configdir = configdir.resolve()\\n    try:\\n        configdir.mkdir(parents=True, exist_ok=True)\\n    except OSError as exc:\\n        _log.warning(\"mkdir -p failed for path %s: %s\", configdir, exc)\\n    else:\\n        if os.access(str(configdir), os.W_OK) and configdir.is_dir():\\n            return str(configdir)\\n        _log.warning(\"%s is not a writable directory\", configdir)\\n    # If the config or cache directory cannot be created or is not a writable\\n    # directory, create a temporary one.\\n    try:\\n        tmpdir = tempfile.mkdtemp(prefix=\"matplotlib-\")\\n    except OSError as exc:\\n        raise OSError(\\n            f\"Matplotlib requires access to a writable cache directory, but there \"\\n            f\"was an issue with the default path ({configdir}), and a temporary \"\\n            f\"directory could not be created; set the MPLCONFIGDIR environment \"\\n            f\"variable to a writable directory\") from exc\\n    os.environ[\"MPLCONFIGDIR\"] = tmpdir\\n    atexit.register(shutil.rmtree, tmpdir)\\n    _log.warning(\\n        \"Matplotlib created a temporary cache directory at %s because there was \"\\n        \"an issue with the default path (%s); it is highly recommended to set the \"\\n        \"MPLCONFIGDIR environment variable to a writable directory, in particular to \"\\n        \"speed up the import of Matplotlib and to better support multiprocessing.\",\\n        tmpdir, configdir)\\n    return tmpdir\\n\\n\\n@_logged_cached(\\'CONFIGDIR=%s\\')\\ndef get_configdir():\\n    \"\"\"\\n    Return the string path of the configuration directory.\\n\\n    The directory is chosen as follows:\\n\\n    1. If the MPLCONFIGDIR environment variable is supplied, choose that.\\n    2. On Linux, follow the XDG specification and look first in\\n       ``$XDG_CONFIG_HOME``, if defined, or ``$HOME/.config``.  On other\\n       platforms, choose ``$HOME/.matplotlib``.\\n    3. If the chosen directory exists and is writable, use that as the\\n       configuration directory.\\n    4. Else, create a temporary directory, and use it as the configuration\\n       directory.\\n    \"\"\"\\n    return _get_config_or_cache_dir(_get_xdg_config_dir)\\n\\n\\n@_logged_cached(\\'CACHEDIR=%s\\')\\ndef get_cachedir():\\n    \"\"\"\\n    Return the string path of the cache directory.\\n\\n    The procedure used to find the directory is the same as for\\n    `get_configdir`, except using ``$XDG_CACHE_HOME``/``$HOME/.cache`` instead.\\n    \"\"\"\\n    return _get_config_or_cache_dir(_get_xdg_cache_dir)\\n\\n\\n@_logged_cached(\\'matplotlib data path: %s\\')\\ndef get_data_path():\\n    \"\"\"Return the path to Matplotlib data.\"\"\"\\n    return str(Path(__file__).with_name(\"mpl-data\"))\\n\\n\\ndef matplotlib_fname():\\n    \"\"\"\\n    Get the location of the config file.\\n\\n    The file location is determined in the following order\\n\\n    - ``$PWD/matplotlibrc``\\n    - ``$MATPLOTLIBRC`` if it is not a directory\\n    - ``$MATPLOTLIBRC/matplotlibrc``\\n    - ``$MPLCONFIGDIR/matplotlibrc``\\n    - On Linux,\\n        - ``$XDG_CONFIG_HOME/matplotlib/matplotlibrc`` (if ``$XDG_CONFIG_HOME``\\n          is defined)\\n        - or ``$HOME/.config/matplotlib/matplotlibrc`` (if ``$XDG_CONFIG_HOME``\\n          is not defined)\\n    - On other platforms,\\n      - ``$HOME/.matplotlib/matplotlibrc`` if ``$HOME`` is defined\\n    - Lastly, it looks in ``$MATPLOTLIBDATA/matplotlibrc``, which should always\\n      exist.\\n    \"\"\"\\n\\n    def gen_candidates():\\n        # rely on down-stream code to make absolute.  This protects us\\n        # from having to directly get the current working directory\\n        # which can fail if the user has ended up with a cwd that is\\n        # non-existent.\\n        yield \\'matplotlibrc\\'\\n        try:\\n            matplotlibrc = os.environ[\\'MATPLOTLIBRC\\']\\n        except KeyError:\\n            pass\\n        else:\\n            yield matplotlibrc\\n            yield os.path.join(matplotlibrc, \\'matplotlibrc\\')\\n        yield os.path.join(get_configdir(), \\'matplotlibrc\\')\\n        yield os.path.join(get_data_path(), \\'matplotlibrc\\')\\n\\n    for fname in gen_candidates():\\n        if os.path.exists(fname) and not os.path.isdir(fname):\\n            return fname\\n\\n    raise RuntimeError(\"Could not find matplotlibrc file; your Matplotlib \"\\n                       \"install is broken\")\\n\\n\\n# rcParams deprecated and automatically mapped to another key.\\n# Values are tuples of (version, new_name, f_old2new, f_new2old).\\n_deprecated_map = {}\\n# rcParams deprecated; some can manually be mapped to another key.\\n# Values are tuples of (version, new_name_or_None).\\n_deprecated_ignore_map = {}\\n# rcParams deprecated; can use None to suppress warnings; remain actually\\n# listed in the rcParams.\\n# Values are tuples of (version,)\\n_deprecated_remain_as_none = {}\\n\\n\\n@_docstring.Substitution(\\n    \"\\\\n\".join(map(\"- {}\".format, sorted(rcsetup._validators, key=str.lower)))\\n)\\nclass RcParams(MutableMapping, dict):\\n    \"\"\"\\n    A dict-like key-value store for config parameters, including validation.\\n\\n    Validating functions are defined and associated with rc parameters in\\n    :mod:`matplotlib.rcsetup`.\\n\\n    The list of rcParams is:\\n\\n    %s\\n\\n    See Also\\n    --------\\n    :ref:`customizing-with-matplotlibrc-files`\\n    \"\"\"\\n\\n    validate = rcsetup._validators\\n\\n    # validate values on the way in\\n    def __init__(self, *args, **kwargs):\\n        self.update(*args, **kwargs)\\n\\n    def _set(self, key, val):\\n        \"\"\"\\n        Directly write data bypassing deprecation and validation logic.\\n\\n        Notes\\n        -----\\n        As end user or downstream library you almost always should use\\n        ``rcParams[key] = val`` and not ``_set()``.\\n\\n        There are only very few special cases that need direct data access.\\n        These cases previously used ``dict.__setitem__(rcParams, key, val)``,\\n        which is now deprecated and replaced by ``rcParams._set(key, val)``.\\n\\n        Even though private, we guarantee API stability for ``rcParams._set``,\\n        i.e. it is subject to Matplotlib\\'s API and deprecation policy.\\n\\n        :meta public:\\n        \"\"\"\\n        dict.__setitem__(self, key, val)\\n\\n    def _get(self, key):\\n        \"\"\"\\n        Directly read data bypassing deprecation, backend and validation\\n        logic.\\n\\n        Notes\\n        -----\\n        As end user or downstream library you almost always should use\\n        ``val = rcParams[key]`` and not ``_get()``.\\n\\n        There are only very few special cases that need direct data access.\\n        These cases previously used ``dict.__getitem__(rcParams, key, val)``,\\n        which is now deprecated and replaced by ``rcParams._get(key)``.\\n\\n        Even though private, we guarantee API stability for ``rcParams._get``,\\n        i.e. it is subject to Matplotlib\\'s API and deprecation policy.\\n\\n        :meta public:\\n        \"\"\"\\n        return dict.__getitem__(self, key)\\n\\n    def _update_raw(self, other_params):\\n        \"\"\"\\n        Directly update the data from *other_params*, bypassing deprecation,\\n        backend and validation logic on both sides.\\n\\n        This ``rcParams._update_raw(params)`` replaces the previous pattern\\n        ``dict.update(rcParams, params)``.\\n\\n        Parameters\\n        ----------\\n        other_params : dict or `.RcParams`\\n            The input mapping from which to update.\\n        \"\"\"\\n        if isinstance(other_params, RcParams):\\n            other_params = dict.items(other_params)\\n        dict.update(self, other_params)\\n\\n    def _ensure_has_backend(self):\\n        \"\"\"\\n        Ensure that a \"backend\" entry exists.\\n\\n        Normally, the default matplotlibrc file contains *no* entry for \"backend\" (the\\n        corresponding line starts with ##, not #; we fill in _auto_backend_sentinel\\n        in that case.  However, packagers can set a different default backend\\n        (resulting in a normal `#backend: foo` line) in which case we should *not*\\n        fill in _auto_backend_sentinel.\\n        \"\"\"\\n        dict.setdefault(self, \"backend\", rcsetup._auto_backend_sentinel)\\n\\n    def __setitem__(self, key, val):\\n        try:\\n            if key in _deprecated_map:\\n                version, alt_key, alt_val, inverse_alt = _deprecated_map[key]\\n                _api.warn_deprecated(\\n                    version, name=key, obj_type=\"rcparam\", alternative=alt_key)\\n                key = alt_key\\n                val = alt_val(val)\\n            elif key in _deprecated_remain_as_none and val is not None:\\n                version, = _deprecated_remain_as_none[key]\\n                _api.warn_deprecated(version, name=key, obj_type=\"rcparam\")\\n            elif key in _deprecated_ignore_map:\\n                version, alt_key = _deprecated_ignore_map[key]\\n                _api.warn_deprecated(\\n                    version, name=key, obj_type=\"rcparam\", alternative=alt_key)\\n                return\\n            elif key == \\'backend\\':\\n                if val is rcsetup._auto_backend_sentinel:\\n                    if \\'backend\\' in self:\\n                        return\\n            try:\\n                cval = self.validate[key](val)\\n            except ValueError as ve:\\n                raise ValueError(f\"Key {key}: {ve}\") from None\\n            self._set(key, cval)\\n        except KeyError as err:\\n            raise KeyError(\\n                f\"{key} is not a valid rc parameter (see rcParams.keys() for \"\\n                f\"a list of valid parameters)\") from err\\n\\n    def __getitem__(self, key):\\n        if key in _deprecated_map:\\n            version, alt_key, alt_val, inverse_alt = _deprecated_map[key]\\n            _api.warn_deprecated(\\n                version, name=key, obj_type=\"rcparam\", alternative=alt_key)\\n            return inverse_alt(self._get(alt_key))\\n\\n        elif key in _deprecated_ignore_map:\\n            version, alt_key = _deprecated_ignore_map[key]\\n            _api.warn_deprecated(\\n                version, name=key, obj_type=\"rcparam\", alternative=alt_key)\\n            return self._get(alt_key) if alt_key else None\\n\\n        # In theory, this should only ever be used after the global rcParams\\n        # has been set up, but better be safe e.g. in presence of breakpoints.\\n        elif key == \"backend\" and self is globals().get(\"rcParams\"):\\n            val = self._get(key)\\n            if val is rcsetup._auto_backend_sentinel:\\n                from matplotlib import pyplot as plt\\n                plt.switch_backend(rcsetup._auto_backend_sentinel)\\n\\n        return self._get(key)\\n\\n    def _get_backend_or_none(self):\\n        \"\"\"Get the requested backend, if any, without triggering resolution.\"\"\"\\n        backend = self._get(\"backend\")\\n        return None if backend is rcsetup._auto_backend_sentinel else backend\\n\\n    def __repr__(self):\\n        class_name = self.__class__.__name__\\n        indent = len(class_name) + 1\\n        with _api.suppress_matplotlib_deprecation_warning():\\n            repr_split = pprint.pformat(dict(self), indent=1,\\n                                        width=80 - indent).split(\\'\\\\n\\')\\n        repr_indented = (\\'\\\\n\\' + \\' \\' * indent).join(repr_split)\\n        return f\\'{class_name}({repr_indented})\\'\\n\\n    def __str__(self):\\n        return \\'\\\\n\\'.join(map(\\'{0[0]}: {0[1]}\\'.format, sorted(self.items())))\\n\\n    def __iter__(self):\\n        \"\"\"Yield sorted list of keys.\"\"\"\\n        with _api.suppress_matplotlib_deprecation_warning():\\n            yield from sorted(dict.__iter__(self))\\n\\n    def __len__(self):\\n        return dict.__len__(self)\\n\\n    def find_all(self, pattern):\\n        \"\"\"\\n        Return the subset of this RcParams dictionary whose keys match,\\n        using :func:`re.search`, the given ``pattern``.\\n\\n        .. note::\\n\\n            Changes to the returned dictionary are *not* propagated to\\n            the parent RcParams dictionary.\\n\\n        \"\"\"\\n        pattern_re = re.compile(pattern)\\n        return RcParams((key, value)\\n                        for key, value in self.items()\\n                        if pattern_re.search(key))\\n\\n    def copy(self):\\n        \"\"\"Copy this RcParams instance.\"\"\"\\n        rccopy = RcParams()\\n        for k in self:  # Skip deprecations and revalidation.\\n            rccopy._set(k, self._get(k))\\n        return rccopy\\n\\n\\ndef rc_params(fail_on_error=False):\\n    \"\"\"Construct a `RcParams` instance from the default Matplotlib rc file.\"\"\"\\n    return rc_params_from_file(matplotlib_fname(), fail_on_error)\\n\\n\\n@functools.cache\\ndef _get_ssl_context():\\n    try:\\n        import certifi\\n    except ImportError:\\n        _log.debug(\"Could not import certifi.\")\\n        return None\\n    import ssl\\n    return ssl.create_default_context(cafile=certifi.where())\\n\\n\\n@contextlib.contextmanager\\ndef _open_file_or_url(fname):\\n    if (isinstance(fname, str)\\n            and fname.startswith((\\'http://\\', \\'https://\\', \\'ftp://\\', \\'file:\\'))):\\n        import urllib.request\\n        ssl_ctx = _get_ssl_context()\\n        if ssl_ctx is None:\\n            _log.debug(\\n                \"Could not get certifi ssl context, https may not work.\"\\n            )\\n        with urllib.request.urlopen(fname, context=ssl_ctx) as f:\\n            yield (line.decode(\\'utf-8\\') for line in f)\\n    else:\\n        fname = os.path.expanduser(fname)\\n        with open(fname, encoding=\\'utf-8\\') as f:\\n            yield f\\n\\n\\ndef _rc_params_in_file(fname, transform=lambda x: x, fail_on_error=False):\\n    \"\"\"\\n    Construct a `RcParams` instance from file *fname*.\\n\\n    Unlike `rc_params_from_file`, the configuration class only contains the\\n    parameters specified in the file (i.e. default values are not filled in).\\n\\n    Parameters\\n    ----------\\n    fname : path-like\\n        The loaded file.\\n    transform : callable, default: the identity function\\n        A function called on each individual line of the file to transform it,\\n        before further parsing.\\n    fail_on_error : bool, default: False\\n        Whether invalid entries should result in an exception or a warning.\\n    \"\"\"\\n    import matplotlib as mpl\\n    rc_temp = {}\\n    with _open_file_or_url(fname) as fd:\\n        try:\\n            for line_no, line in enumerate(fd, 1):\\n                line = transform(line)\\n                strippedline = cbook._strip_comment(line)\\n                if not strippedline:\\n                    continue\\n                tup = strippedline.split(\\':\\', 1)\\n                if len(tup) != 2:\\n                    _log.warning(\\'Missing colon in file %r, line %d (%r)\\',\\n                                 fname, line_no, line.rstrip(\\'\\\\n\\'))\\n                    continue\\n                key, val = tup\\n                key = key.strip()\\n                val = val.strip()\\n                if val.startswith(\\'\"\\') and val.endswith(\\'\"\\'):\\n                    val = val[1:-1]  # strip double quotes\\n                if key in rc_temp:\\n                    _log.warning(\\'Duplicate key in file %r, line %d (%r)\\',\\n                                 fname, line_no, line.rstrip(\\'\\\\n\\'))\\n                rc_temp[key] = (val, line, line_no)\\n        except UnicodeDecodeError:\\n            _log.warning(\\'Cannot decode configuration file %r as utf-8.\\',\\n                         fname)\\n            raise\\n\\n    config = RcParams()\\n\\n    for key, (val, line, line_no) in rc_temp.items():\\n        if key in rcsetup._validators:\\n            if fail_on_error:\\n                config[key] = val  # try to convert to proper type or raise\\n            else:\\n                try:\\n                    config[key] = val  # try to convert to proper type or skip\\n                except Exception as msg:\\n                    _log.warning(\\'Bad value in file %r, line %d (%r): %s\\',\\n                                 fname, line_no, line.rstrip(\\'\\\\n\\'), msg)\\n        elif key in _deprecated_ignore_map:\\n            version, alt_key = _deprecated_ignore_map[key]\\n            _api.warn_deprecated(\\n                version, name=key, alternative=alt_key, obj_type=\\'rcparam\\',\\n                addendum=\"Please update your matplotlibrc.\")\\n        else:\\n            # __version__ must be looked up as an attribute to trigger the\\n            # module-level __getattr__.\\n            version = (\\'main\\' if \\'.post\\' in mpl.__version__\\n                       else f\\'v{mpl.__version__}\\')\\n            _log.warning(\"\"\"\\nBad key %(key)s in file %(fname)s, line %(line_no)s (%(line)r)\\nYou probably need to get an updated matplotlibrc file from\\nhttps://github.com/matplotlib/matplotlib/blob/%(version)s/lib/matplotlib/mpl-data/matplotlibrc\\nor from the matplotlib source distribution\"\"\",\\n                         dict(key=key, fname=fname, line_no=line_no,\\n                              line=line.rstrip(\\'\\\\n\\'), version=version))\\n    return config\\n\\n\\ndef rc_params_from_file(fname, fail_on_error=False, use_default_template=True):\\n    \"\"\"\\n    Construct a `RcParams` from file *fname*.\\n\\n    Parameters\\n    ----------\\n    fname : str or path-like\\n        A file with Matplotlib rc settings.\\n    fail_on_error : bool\\n        If True, raise an error when the parser fails to convert a parameter.\\n    use_default_template : bool\\n        If True, initialize with default parameters before updating with those\\n        in the given file. If False, the configuration class only contains the\\n        parameters specified in the file. (Useful for updating dicts.)\\n    \"\"\"\\n    config_from_file = _rc_params_in_file(fname, fail_on_error=fail_on_error)\\n\\n    if not use_default_template:\\n        return config_from_file\\n\\n    with _api.suppress_matplotlib_deprecation_warning():\\n        config = RcParams({**rcParamsDefault, **config_from_file})\\n\\n    if \"\".join(config[\\'text.latex.preamble\\']):\\n        _log.info(\"\"\"\\n*****************************************************************\\nYou have the following UNSUPPORTED LaTeX preamble customizations:\\n%s\\nPlease do not ask for support with these customizations active.\\n*****************************************************************\\n\"\"\", \\'\\\\n\\'.join(config[\\'text.latex.preamble\\']))\\n    _log.debug(\\'loaded rc file %s\\', fname)\\n\\n    return config\\n\\n\\nrcParamsDefault = _rc_params_in_file(\\n    cbook._get_data_path(\"matplotlibrc\"),\\n    # Strip leading comment.\\n    transform=lambda line: line[1:] if line.startswith(\"#\") else line,\\n    fail_on_error=True)\\nrcParamsDefault._update_raw(rcsetup._hardcoded_defaults)\\nrcParamsDefault._ensure_has_backend()\\n\\nrcParams = RcParams()  # The global instance.\\nrcParams._update_raw(rcParamsDefault)\\nrcParams._update_raw(_rc_params_in_file(matplotlib_fname()))\\nrcParamsOrig = rcParams.copy()\\nwith _api.suppress_matplotlib_deprecation_warning():\\n    # This also checks that all rcParams are indeed listed in the template.\\n    # Assigning to rcsetup.defaultParams is left only for backcompat.\\n    defaultParams = rcsetup.defaultParams = {\\n        # We want to resolve deprecated rcParams, but not backend...\\n        key: [(rcsetup._auto_backend_sentinel if key == \"backend\" else\\n               rcParamsDefault[key]),\\n              validator]\\n        for key, validator in rcsetup._validators.items()}\\nif rcParams[\\'axes.formatter.use_locale\\']:\\n    locale.setlocale(locale.LC_ALL, \\'\\')\\n\\n\\ndef rc(group, **kwargs):\\n    \"\"\"\\n    Set the current `.rcParams`.  *group* is the grouping for the rc, e.g.,\\n    for ``lines.linewidth`` the group is ``lines``, for\\n    ``axes.facecolor``, the group is ``axes``, and so on.  Group may\\n    also be a list or tuple of group names, e.g., (*xtick*, *ytick*).\\n    *kwargs* is a dictionary attribute name/value pairs, e.g.,::\\n\\n      rc(\\'lines\\', linewidth=2, color=\\'r\\')\\n\\n    sets the current `.rcParams` and is equivalent to::\\n\\n      rcParams[\\'lines.linewidth\\'] = 2\\n      rcParams[\\'lines.color\\'] = \\'r\\'\\n\\n    The following aliases are available to save typing for interactive users:\\n\\n    =====   =================\\n    Alias   Property\\n    =====   =================\\n    \\'lw\\'    \\'linewidth\\'\\n    \\'ls\\'    \\'linestyle\\'\\n    \\'c\\'     \\'color\\'\\n    \\'fc\\'    \\'facecolor\\'\\n    \\'ec\\'    \\'edgecolor\\'\\n    \\'mew\\'   \\'markeredgewidth\\'\\n    \\'aa\\'    \\'antialiased\\'\\n    =====   =================\\n\\n    Thus you could abbreviate the above call as::\\n\\n          rc(\\'lines\\', lw=2, c=\\'r\\')\\n\\n    Note you can use python\\'s kwargs dictionary facility to store\\n    dictionaries of default parameters.  e.g., you can customize the\\n    font rc as follows::\\n\\n      font = {\\'family\\' : \\'monospace\\',\\n              \\'weight\\' : \\'bold\\',\\n              \\'size\\'   : \\'larger\\'}\\n      rc(\\'font\\', **font)  # pass in the font dict as kwargs\\n\\n    This enables you to easily switch between several configurations.  Use\\n    ``matplotlib.style.use(\\'default\\')`` or :func:`~matplotlib.rcdefaults` to\\n    restore the default `.rcParams` after changes.\\n\\n    Notes\\n    -----\\n    Similar functionality is available by using the normal dict interface, i.e.\\n    ``rcParams.update({\"lines.linewidth\": 2, ...})`` (but ``rcParams.update``\\n    does not support abbreviations or grouping).\\n    \"\"\"\\n\\n    aliases = {\\n        \\'lw\\':  \\'linewidth\\',\\n        \\'ls\\':  \\'linestyle\\',\\n        \\'c\\':   \\'color\\',\\n        \\'fc\\':  \\'facecolor\\',\\n        \\'ec\\':  \\'edgecolor\\',\\n        \\'mew\\': \\'markeredgewidth\\',\\n        \\'aa\\':  \\'antialiased\\',\\n        }\\n\\n    if isinstance(group, str):\\n        group = (group,)\\n    for g in group:\\n        for k, v in kwargs.items():\\n            name = aliases.get(k) or k\\n            key = f\\'{g}.{name}\\'\\n            try:\\n                rcParams[key] = v\\n            except KeyError as err:\\n                raise KeyError((\\'Unrecognized key \"%s\" for group \"%s\" and \\'\\n                                \\'name \"%s\"\\') % (key, g, name)) from err\\n\\n\\ndef rcdefaults():\\n    \"\"\"\\n    Restore the `.rcParams` from Matplotlib\\'s internal default style.\\n\\n    Style-blacklisted `.rcParams` (defined in\\n    ``matplotlib.style.core.STYLE_BLACKLIST``) are not updated.\\n\\n    See Also\\n    --------\\n    matplotlib.rc_file_defaults\\n        Restore the `.rcParams` from the rc file originally loaded by\\n        Matplotlib.\\n    matplotlib.style.use\\n        Use a specific style file.  Call ``style.use(\\'default\\')`` to restore\\n        the default style.\\n    \"\"\"\\n    # Deprecation warnings were already handled when creating rcParamsDefault,\\n    # no need to reemit them here.\\n    with _api.suppress_matplotlib_deprecation_warning():\\n        from .style.core import STYLE_BLACKLIST\\n        rcParams.clear()\\n        rcParams.update({k: v for k, v in rcParamsDefault.items()\\n                         if k not in STYLE_BLACKLIST})\\n\\n\\ndef rc_file_defaults():\\n    \"\"\"\\n    Restore the `.rcParams` from the original rc file loaded by Matplotlib.\\n\\n    Style-blacklisted `.rcParams` (defined in\\n    ``matplotlib.style.core.STYLE_BLACKLIST``) are not updated.\\n    \"\"\"\\n    # Deprecation warnings were already handled when creating rcParamsOrig, no\\n    # need to reemit them here.\\n    with _api.suppress_matplotlib_deprecation_warning():\\n        from .style.core import STYLE_BLACKLIST\\n        rcParams.update({k: rcParamsOrig[k] for k in rcParamsOrig\\n                         if k not in STYLE_BLACKLIST})\\n\\n\\ndef rc_file(fname, *, use_default_template=True):\\n    \"\"\"\\n    Update `.rcParams` from file.\\n\\n    Style-blacklisted `.rcParams` (defined in\\n    ``matplotlib.style.core.STYLE_BLACKLIST``) are not updated.\\n\\n    Parameters\\n    ----------\\n    fname : str or path-like\\n        A file with Matplotlib rc settings.\\n\\n    use_default_template : bool\\n        If True, initialize with default parameters before updating with those\\n        in the given file. If False, the current configuration persists\\n        and only the parameters specified in the file are updated.\\n    \"\"\"\\n    # Deprecation warnings were already handled in rc_params_from_file, no need\\n    # to reemit them here.\\n    with _api.suppress_matplotlib_deprecation_warning():\\n        from .style.core import STYLE_BLACKLIST\\n        rc_from_file = rc_params_from_file(\\n            fname, use_default_template=use_default_template)\\n        rcParams.update({k: rc_from_file[k] for k in rc_from_file\\n                         if k not in STYLE_BLACKLIST})\\n\\n\\n@contextlib.contextmanager\\ndef rc_context(rc=None, fname=None):\\n    \"\"\"\\n    Return a context manager for temporarily changing rcParams.\\n\\n    The :rc:`backend` will not be reset by the context manager.\\n\\n    rcParams changed both through the context manager invocation and\\n    in the body of the context will be reset on context exit.\\n\\n    Parameters\\n    ----------\\n    rc : dict\\n        The rcParams to temporarily set.\\n    fname : str or path-like\\n        A file with Matplotlib rc settings. If both *fname* and *rc* are given,\\n        settings from *rc* take precedence.\\n\\n    See Also\\n    --------\\n    :ref:`customizing-with-matplotlibrc-files`\\n\\n    Examples\\n    --------\\n    Passing explicit values via a dict::\\n\\n        with mpl.rc_context({\\'interactive\\': False}):\\n            fig, ax = plt.subplots()\\n            ax.plot(range(3), range(3))\\n            fig.savefig(\\'example.png\\')\\n            plt.close(fig)\\n\\n    Loading settings from a file::\\n\\n         with mpl.rc_context(fname=\\'print.rc\\'):\\n             plt.plot(x, y)  # uses \\'print.rc\\'\\n\\n    Setting in the context body::\\n\\n        with mpl.rc_context():\\n            # will be reset\\n            mpl.rcParams[\\'lines.linewidth\\'] = 5\\n            plt.plot(x, y)\\n\\n    \"\"\"\\n    orig = dict(rcParams.copy())\\n    del orig[\\'backend\\']\\n    try:\\n        if fname:\\n            rc_file(fname)\\n        if rc:\\n            rcParams.update(rc)\\n        yield\\n    finally:\\n        rcParams._update_raw(orig)  # Revert to the original rcs.\\n\\n\\ndef use(backend, *, force=True):\\n    \"\"\"\\n    Select the backend used for rendering and GUI integration.\\n\\n    If pyplot is already imported, `~matplotlib.pyplot.switch_backend` is used\\n    and if the new backend is different than the current backend, all Figures\\n    will be closed.\\n\\n    Parameters\\n    ----------\\n    backend : str\\n        The backend to switch to.  This can either be one of the standard\\n        backend names, which are case-insensitive:\\n\\n        - interactive backends:\\n          GTK3Agg, GTK3Cairo, GTK4Agg, GTK4Cairo, MacOSX, nbAgg, notebook, QtAgg,\\n          QtCairo, TkAgg, TkCairo, WebAgg, WX, WXAgg, WXCairo, Qt5Agg, Qt5Cairo\\n\\n        - non-interactive backends:\\n          agg, cairo, pdf, pgf, ps, svg, template\\n\\n        or a string of the form: ``module://my.module.name``.\\n\\n        notebook is a synonym for nbAgg.\\n\\n        Switching to an interactive backend is not possible if an unrelated\\n        event loop has already been started (e.g., switching to GTK3Agg if a\\n        TkAgg window has already been opened).  Switching to a non-interactive\\n        backend is always possible.\\n\\n    force : bool, default: True\\n        If True (the default), raise an `ImportError` if the backend cannot be\\n        set up (either because it fails to import, or because an incompatible\\n        GUI interactive framework is already running); if False, silently\\n        ignore the failure.\\n\\n    See Also\\n    --------\\n    :ref:`backends`\\n    matplotlib.get_backend\\n    matplotlib.pyplot.switch_backend\\n\\n    \"\"\"\\n    name = rcsetup.validate_backend(backend)\\n    # don\\'t (prematurely) resolve the \"auto\" backend setting\\n    if rcParams._get_backend_or_none() == name:\\n        # Nothing to do if the requested backend is already set\\n        pass\\n    else:\\n        # if pyplot is not already imported, do not import it.  Doing\\n        # so may trigger a `plt.switch_backend` to the _default_ backend\\n        # before we get a chance to change to the one the user just requested\\n        plt = sys.modules.get(\\'matplotlib.pyplot\\')\\n        # if pyplot is imported, then try to change backends\\n        if plt is not None:\\n            try:\\n                # we need this import check here to re-raise if the\\n                # user does not have the libraries to support their\\n                # chosen backend installed.\\n                plt.switch_backend(name)\\n            except ImportError:\\n                if force:\\n                    raise\\n        # if we have not imported pyplot, then we can set the rcParam\\n        # value which will be respected when the user finally imports\\n        # pyplot\\n        else:\\n            rcParams[\\'backend\\'] = backend\\n    # if the user has asked for a given backend, do not helpfully\\n    # fallback\\n    rcParams[\\'backend_fallback\\'] = False\\n\\n\\nif os.environ.get(\\'MPLBACKEND\\'):\\n    rcParams[\\'backend\\'] = os.environ.get(\\'MPLBACKEND\\')\\n\\n\\ndef get_backend(*, auto_select=True):\\n    \"\"\"\\n    Return the name of the current backend.\\n\\n    Parameters\\n    ----------\\n    auto_select : bool, default: True\\n        Whether to trigger backend resolution if no backend has been\\n        selected so far. If True, this ensures that a valid backend\\n        is returned. If False, this returns None if no backend has been\\n        selected so far.\\n\\n        .. versionadded:: 3.10\\n\\n        .. admonition:: Provisional\\n\\n           The *auto_select* flag is provisional. It may be changed or removed\\n           without prior warning.\\n\\n    See Also\\n    --------\\n    matplotlib.use\\n    \"\"\"\\n    if auto_select:\\n        return rcParams[\\'backend\\']\\n    else:\\n        backend = rcParams._get(\\'backend\\')\\n        if backend is rcsetup._auto_backend_sentinel:\\n            return None\\n        else:\\n            return backend\\n\\n\\ndef interactive(b):\\n    \"\"\"\\n    Set whether to redraw after every plotting command (e.g. `.pyplot.xlabel`).\\n    \"\"\"\\n    rcParams[\\'interactive\\'] = b\\n\\n\\ndef is_interactive():\\n    \"\"\"\\n    Return whether to redraw after every plotting command.\\n\\n    .. note::\\n\\n        This function is only intended for use in backends. End users should\\n        use `.pyplot.isinteractive` instead.\\n    \"\"\"\\n    return rcParams[\\'interactive\\']\\n\\n\\ndef _val_or_rc(val, rc_name):\\n    \"\"\"\\n    If *val* is None, return ``mpl.rcParams[rc_name]``, otherwise return val.\\n    \"\"\"\\n    return val if val is not None else rcParams[rc_name]\\n\\n\\ndef _init_tests():\\n    # The version of FreeType to install locally for running the tests. This must match\\n    # the value in `meson.build`.\\n    LOCAL_FREETYPE_VERSION = \\'2.6.1\\'\\n\\n    from matplotlib import ft2font\\n    if (ft2font.__freetype_version__ != LOCAL_FREETYPE_VERSION or\\n            ft2font.__freetype_build_type__ != \\'local\\'):\\n        _log.warning(\\n            \"Matplotlib is not built with the correct FreeType version to run tests.  \"\\n            \"Rebuild without setting system-freetype=true in Meson setup options.  \"\\n            \"Expect many image comparison failures below.  \"\\n            \"Expected freetype version %s.  \"\\n            \"Found freetype version %s.  \"\\n            \"Freetype build type is %slocal.\",\\n            LOCAL_FREETYPE_VERSION,\\n            ft2font.__freetype_version__,\\n            \"\" if ft2font.__freetype_build_type__ == \\'local\\' else \"not \")\\n\\n\\ndef _replacer(data, value):\\n    \"\"\"\\n    Either returns ``data[value]`` or passes ``data`` back, converts either to\\n    a sequence.\\n    \"\"\"\\n    try:\\n        # if key isn\\'t a string don\\'t bother\\n        if isinstance(value, str):\\n            # try to use __getitem__\\n            value = data[value]\\n    except Exception:\\n        # key does not exist, silently fall back to key\\n        pass\\n    return cbook.sanitize_sequence(value)\\n\\n\\ndef _label_from_arg(y, default_name):\\n    try:\\n        return y.name\\n    except AttributeError:\\n        if isinstance(default_name, str):\\n            return default_name\\n    return None\\n\\n\\ndef _add_data_doc(docstring, replace_names):\\n    \"\"\"\\n    Add documentation for a *data* field to the given docstring.\\n\\n    Parameters\\n    ----------\\n    docstring : str\\n        The input docstring.\\n    replace_names : list of str or None\\n        The list of parameter names which arguments should be replaced by\\n        ``data[name]`` (if ``data[name]`` does not throw an exception).  If\\n        None, replacement is attempted for all arguments.\\n\\n    Returns\\n    -------\\n    str\\n        The augmented docstring.\\n    \"\"\"\\n    if (docstring is None\\n            or replace_names is not None and len(replace_names) == 0):\\n        return docstring\\n    docstring = inspect.cleandoc(docstring)\\n\\n    data_doc = (\"\"\"\\\\\\n    If given, all parameters also accept a string ``s``, which is\\n    interpreted as ``data[s]`` if ``s`` is a key in ``data``.\"\"\"\\n                if replace_names is None else f\"\"\"\\\\\\n    If given, the following parameters also accept a string ``s``, which is\\n    interpreted as ``data[s]`` if ``s`` is a key in ``data``:\\n\\n    {\\', \\'.join(map(\\'*{}*\\'.format, replace_names))}\"\"\")\\n    # using string replacement instead of formatting has the advantages\\n    # 1) simpler indent handling\\n    # 2) prevent problems with formatting characters \\'{\\', \\'%\\' in the docstring\\n    if _log.level <= logging.DEBUG:\\n        # test_data_parameter_replacement() tests against these log messages\\n        # make sure to keep message and test in sync\\n        if \"data : indexable object, optional\" not in docstring:\\n            _log.debug(\"data parameter docstring error: no data parameter\")\\n        if \\'DATA_PARAMETER_PLACEHOLDER\\' not in docstring:\\n            _log.debug(\"data parameter docstring error: missing placeholder\")\\n    return docstring.replace(\\'    DATA_PARAMETER_PLACEHOLDER\\', data_doc)\\n\\n\\ndef _preprocess_data(func=None, *, replace_names=None, label_namer=None):\\n    \"\"\"\\n    A decorator to add a \\'data\\' kwarg to a function.\\n\\n    When applied::\\n\\n        @_preprocess_data()\\n        def func(ax, *args, **kwargs): ...\\n\\n    the signature is modified to ``decorated(ax, *args, data=None, **kwargs)``\\n    with the following behavior:\\n\\n    - if called with ``data=None``, forward the other arguments to ``func``;\\n    - otherwise, *data* must be a mapping; for any argument passed in as a\\n      string ``name``, replace the argument by ``data[name]`` (if this does not\\n      throw an exception), then forward the arguments to ``func``.\\n\\n    In either case, any argument that is a `MappingView` is also converted to a\\n    list.\\n\\n    Parameters\\n    ----------\\n    replace_names : list of str or None, default: None\\n        The list of parameter names for which lookup into *data* should be\\n        attempted. If None, replacement is attempted for all arguments.\\n    label_namer : str, default: None\\n        If set e.g. to \"namer\" (which must be a kwarg in the function\\'s\\n        signature -- not as ``**kwargs``), if the *namer* argument passed in is\\n        a (string) key of *data* and no *label* kwarg is passed, then use the\\n        (string) value of the *namer* as *label*. ::\\n\\n            @_preprocess_data(label_namer=\"foo\")\\n            def func(foo, label=None): ...\\n\\n            func(\"key\", data={\"key\": value})\\n            # is equivalent to\\n            func.__wrapped__(value, label=\"key\")\\n    \"\"\"\\n\\n    if func is None:  # Return the actual decorator.\\n        return functools.partial(\\n            _preprocess_data,\\n            replace_names=replace_names, label_namer=label_namer)\\n\\n    sig = inspect.signature(func)\\n    varargs_name = None\\n    varkwargs_name = None\\n    arg_names = []\\n    params = list(sig.parameters.values())\\n    for p in params:\\n        if p.kind is Parameter.VAR_POSITIONAL:\\n            varargs_name = p.name\\n        elif p.kind is Parameter.VAR_KEYWORD:\\n            varkwargs_name = p.name\\n        else:\\n            arg_names.append(p.name)\\n    data_param = Parameter(\"data\", Parameter.KEYWORD_ONLY, default=None)\\n    if varkwargs_name:\\n        params.insert(-1, data_param)\\n    else:\\n        params.append(data_param)\\n    new_sig = sig.replace(parameters=params)\\n    arg_names = arg_names[1:]  # remove the first \"ax\" / self arg\\n\\n    assert {*arg_names}.issuperset(replace_names or []) or varkwargs_name, (\\n        \"Matplotlib internal error: invalid replace_names \"\\n        f\"({replace_names!r}) for {func.__name__!r}\")\\n    assert label_namer is None or label_namer in arg_names, (\\n        \"Matplotlib internal error: invalid label_namer \"\\n        f\"({label_namer!r}) for {func.__name__!r}\")\\n\\n    @functools.wraps(func)\\n    def inner(ax, *args, data=None, **kwargs):\\n        if data is None:\\n            return func(\\n                ax,\\n                *map(cbook.sanitize_sequence, args),\\n                **{k: cbook.sanitize_sequence(v) for k, v in kwargs.items()})\\n\\n        bound = new_sig.bind(ax, *args, **kwargs)\\n        auto_label = (bound.arguments.get(label_namer)\\n                      or bound.kwargs.get(label_namer))\\n\\n        for k, v in bound.arguments.items():\\n            if k == varkwargs_name:\\n                for k1, v1 in v.items():\\n                    if replace_names is None or k1 in replace_names:\\n                        v[k1] = _replacer(data, v1)\\n            elif k == varargs_name:\\n                if replace_names is None:\\n                    bound.arguments[k] = tuple(_replacer(data, v1) for v1 in v)\\n            else:\\n                if replace_names is None or k in replace_names:\\n                    bound.arguments[k] = _replacer(data, v)\\n\\n        new_args = bound.args\\n        new_kwargs = bound.kwargs\\n\\n        args_and_kwargs = {**bound.arguments, **bound.kwargs}\\n        if label_namer and \"label\" not in args_and_kwargs:\\n            new_kwargs[\"label\"] = _label_from_arg(\\n                args_and_kwargs.get(label_namer), auto_label)\\n\\n        return func(*new_args, **new_kwargs)\\n\\n    inner.__doc__ = _add_data_doc(inner.__doc__, replace_names)\\n    inner.__signature__ = new_sig\\n    return inner\\n\\n\\n_log.debug(\\'interactive is %s\\', is_interactive())\\n_log.debug(\\'platform is %s\\', sys.platform)\\n\\n\\n@_api.deprecated(\"3.10\", alternative=\"matplotlib.cbook.sanitize_sequence\")\\ndef sanitize_sequence(data):\\n    return cbook.sanitize_sequence(data)\\n\\n\\n@_api.deprecated(\"3.10\", alternative=\"matplotlib.rcsetup.validate_backend\")\\ndef validate_backend(s):\\n    return rcsetup.validate_backend(s)\\n\\n\\n# workaround: we must defer colormaps import to after loading rcParams, because\\n# colormap creation depends on rcParams\\nfrom matplotlib.cm import _colormaps as colormaps  # noqa: E402\\nfrom matplotlib.cm import _multivar_colormaps as multivar_colormaps  # noqa: E402\\nfrom matplotlib.cm import _bivar_colormaps as bivar_colormaps  # noqa: E402\\nfrom matplotlib.colors import _color_sequences as color_sequences  # noqa: E402\\n', 'caller': 'default_function'}, {'name': 'pyplot', 'path': 'matplotlib.pyplot', 'type': 'module', 'text': '# Note: The first part of this file can be modified in place, but the latter\\n# part is autogenerated by the boilerplate.py script.\\n\\n\"\"\"\\n`matplotlib.pyplot` is a state-based interface to matplotlib. It provides\\nan implicit,  MATLAB-like, way of plotting.  It also opens figures on your\\nscreen, and acts as the figure GUI manager.\\n\\npyplot is mainly intended for interactive plots and simple cases of\\nprogrammatic plot generation::\\n\\n    import numpy as np\\n    import matplotlib.pyplot as plt\\n\\n    x = np.arange(0, 5, 0.1)\\n    y = np.sin(x)\\n    plt.plot(x, y)\\n    plt.show()\\n\\nThe explicit object-oriented API is recommended for complex plots, though\\npyplot is still usually used to create the figure and often the Axes in the\\nfigure. See `.pyplot.figure`, `.pyplot.subplots`, and\\n`.pyplot.subplot_mosaic` to create figures, and\\n:doc:`Axes API </api/axes_api>` for the plotting methods on an Axes::\\n\\n    import numpy as np\\n    import matplotlib.pyplot as plt\\n\\n    x = np.arange(0, 5, 0.1)\\n    y = np.sin(x)\\n    fig, ax = plt.subplots()\\n    ax.plot(x, y)\\n    plt.show()\\n\\n\\nSee :ref:`api_interfaces` for an explanation of the tradeoffs between the\\nimplicit and explicit interfaces.\\n\"\"\"\\n\\n# fmt: off\\n\\nfrom __future__ import annotations\\n\\nfrom contextlib import AbstractContextManager, ExitStack\\nfrom enum import Enum\\nimport functools\\nimport importlib\\nimport inspect\\nimport logging\\nimport sys\\nimport threading\\nimport time\\nfrom typing import TYPE_CHECKING, cast, overload\\n\\nfrom cycler import cycler  # noqa: F401\\nimport matplotlib\\nimport matplotlib.colorbar\\nimport matplotlib.image\\nfrom matplotlib import _api\\n# Re-exported (import x as x) for typing.\\nfrom matplotlib import get_backend as get_backend, rcParams as rcParams\\nfrom matplotlib import cm as cm  # noqa: F401\\nfrom matplotlib import style as style  # noqa: F401\\nfrom matplotlib import _pylab_helpers\\nfrom matplotlib import interactive  # noqa: F401\\nfrom matplotlib import cbook\\nfrom matplotlib import _docstring\\nfrom matplotlib.backend_bases import (\\n    FigureCanvasBase, FigureManagerBase, MouseButton)\\nfrom matplotlib.figure import Figure, FigureBase, figaspect\\nfrom matplotlib.gridspec import GridSpec, SubplotSpec\\nfrom matplotlib import rcsetup, rcParamsDefault, rcParamsOrig\\nfrom matplotlib.artist import Artist\\nfrom matplotlib.axes import Axes\\nfrom matplotlib.axes import Subplot  # noqa: F401\\nfrom matplotlib.backends import BackendFilter, backend_registry\\nfrom matplotlib.projections import PolarAxes\\nfrom matplotlib.colorizer import _ColorizerInterface, ColorizingArtist, Colorizer\\nfrom matplotlib import mlab  # for detrend_none, window_hanning\\nfrom matplotlib.scale import get_scale_names  # noqa: F401\\n\\nfrom matplotlib.cm import _colormaps\\nfrom matplotlib.colors import _color_sequences, Colormap\\n\\nimport numpy as np\\n\\nif TYPE_CHECKING:\\n    from collections.abc import Callable, Hashable, Iterable, Sequence\\n    import datetime\\n    import pathlib\\n    import os\\n    from typing import Any, BinaryIO, Literal, TypeVar\\n    from typing_extensions import ParamSpec\\n\\n    import PIL.Image\\n    from numpy.typing import ArrayLike\\n\\n    import matplotlib.axes\\n    import matplotlib.artist\\n    import matplotlib.backend_bases\\n    from matplotlib.axis import Tick\\n    from matplotlib.axes._base import _AxesBase\\n    from matplotlib.backend_bases import Event\\n    from matplotlib.cm import ScalarMappable\\n    from matplotlib.contour import ContourSet, QuadContourSet\\n    from matplotlib.collections import (\\n        Collection,\\n        FillBetweenPolyCollection,\\n        LineCollection,\\n        PolyCollection,\\n        PathCollection,\\n        EventCollection,\\n        QuadMesh,\\n    )\\n    from matplotlib.colorbar import Colorbar\\n    from matplotlib.container import (\\n        BarContainer,\\n        ErrorbarContainer,\\n        StemContainer,\\n    )\\n    from matplotlib.figure import SubFigure\\n    from matplotlib.legend import Legend\\n    from matplotlib.mlab import GaussianKDE\\n    from matplotlib.image import AxesImage, FigureImage\\n    from matplotlib.patches import FancyArrow, StepPatch, Wedge\\n    from matplotlib.quiver import Barbs, Quiver, QuiverKey\\n    from matplotlib.scale import ScaleBase\\n    from matplotlib.typing import (\\n        ColorType,\\n        CoordsType,\\n        HashableList,\\n        LineStyleType,\\n        MarkerType,\\n    )\\n    from matplotlib.widgets import SubplotTool\\n\\n    _P = ParamSpec(\\'_P\\')\\n    _R = TypeVar(\\'_R\\')\\n    _T = TypeVar(\\'_T\\')\\n\\n\\n# We may not need the following imports here:\\nfrom matplotlib.colors import Normalize\\nfrom matplotlib.lines import Line2D, AxLine\\nfrom matplotlib.text import Text, Annotation\\nfrom matplotlib.patches import Arrow, Circle, Rectangle  # noqa: F401\\nfrom matplotlib.patches import Polygon\\nfrom matplotlib.widgets import Button, Slider, Widget  # noqa: F401\\n\\nfrom .ticker import (  # noqa: F401\\n    TickHelper, Formatter, FixedFormatter, NullFormatter, FuncFormatter,\\n    FormatStrFormatter, ScalarFormatter, LogFormatter, LogFormatterExponent,\\n    LogFormatterMathtext, Locator, IndexLocator, FixedLocator, NullLocator,\\n    LinearLocator, LogLocator, AutoLocator, MultipleLocator, MaxNLocator)\\n\\n_log = logging.getLogger(__name__)\\n\\n\\n# Explicit rename instead of import-as for typing\\'s sake.\\ncolormaps = _colormaps\\ncolor_sequences = _color_sequences\\n\\n\\n@overload\\ndef _copy_docstring_and_deprecators(\\n    method: Any,\\n    func: Literal[None] = None\\n) -> Callable[[Callable[_P, _R]], Callable[_P, _R]]: ...\\n\\n\\n@overload\\ndef _copy_docstring_and_deprecators(\\n    method: Any, func: Callable[_P, _R]) -> Callable[_P, _R]: ...\\n\\n\\ndef _copy_docstring_and_deprecators(\\n    method: Any,\\n    func: Callable[_P, _R] | None = None\\n) -> Callable[[Callable[_P, _R]], Callable[_P, _R]] | Callable[_P, _R]:\\n    if func is None:\\n        return cast(\\'Callable[[Callable[_P, _R]], Callable[_P, _R]]\\',\\n                    functools.partial(_copy_docstring_and_deprecators, method))\\n    decorators: list[Callable[[Callable[_P, _R]], Callable[_P, _R]]] = [\\n        _docstring.copy(method)\\n    ]\\n    # Check whether the definition of *method* includes @_api.rename_parameter\\n    # or @_api.make_keyword_only decorators; if so, propagate them to the\\n    # pyplot wrapper as well.\\n    while hasattr(method, \"__wrapped__\"):\\n        potential_decorator = _api.deprecation.DECORATORS.get(method)\\n        if potential_decorator:\\n            decorators.append(potential_decorator)\\n        method = method.__wrapped__\\n    for decorator in decorators[::-1]:\\n        func = decorator(func)\\n    _add_pyplot_note(func, method)\\n    return func\\n\\n\\n_NO_PYPLOT_NOTE = [\\n    \\'FigureBase._gci\\',  # wrapped_func is private\\n    \\'_AxesBase._sci\\',  # wrapped_func is private\\n    \\'Artist.findobj\\',  # not a standard pyplot wrapper because it does not operate\\n                       # on the current Figure / Axes. Explanation of relation would\\n                       # be more complex and is not too important.\\n]\\n\\n\\ndef _add_pyplot_note(func, wrapped_func):\\n    \"\"\"\\n    Add a note to the docstring of *func* that it is a pyplot wrapper.\\n\\n    The note is added to the \"Notes\" section of the docstring. If that does\\n    not exist, a \"Notes\" section is created. In numpydoc, the \"Notes\"\\n    section is the third last possible section, only potentially followed by\\n    \"References\" and \"Examples\".\\n    \"\"\"\\n    if not func.__doc__:\\n        return  # nothing to do\\n\\n    qualname = wrapped_func.__qualname__\\n    if qualname in _NO_PYPLOT_NOTE:\\n        return\\n\\n    wrapped_func_is_method = True\\n    if \".\" not in qualname:\\n        # method qualnames are prefixed by the class and \".\", e.g. \"Axes.plot\"\\n        wrapped_func_is_method = False\\n        link = f\"{wrapped_func.__module__}.{qualname}\"\\n    elif qualname.startswith(\"Axes.\"):  # e.g. \"Axes.plot\"\\n        link = \".axes.\" + qualname\\n    elif qualname.startswith(\"_AxesBase.\"):  # e.g. \"_AxesBase.set_xlabel\"\\n        link = \".axes.Axes\" + qualname[9:]\\n    elif qualname.startswith(\"Figure.\"):  # e.g. \"Figure.figimage\"\\n        link = \".\" + qualname\\n    elif qualname.startswith(\"FigureBase.\"):  # e.g. \"FigureBase.gca\"\\n        link = \".Figure\" + qualname[10:]\\n    elif qualname.startswith(\"FigureCanvasBase.\"):  # \"FigureBaseCanvas.mpl_connect\"\\n        link = \".\" + qualname\\n    else:\\n        raise RuntimeError(f\"Wrapped method from unexpected class: {qualname}\")\\n\\n    if wrapped_func_is_method:\\n        message = f\"This is the :ref:`pyplot wrapper <pyplot_interface>` for `{link}`.\"\\n    else:\\n        message = f\"This is equivalent to `{link}`.\"\\n\\n    # Find the correct insert position:\\n    # - either we already have a \"Notes\" section into which we can insert\\n    # - or we create one before the next present section. Note that in numpydoc, the\\n    #   \"Notes\" section is the third last possible section, only potentially followed\\n    #   by \"References\" and \"Examples\".\\n    # - or we append a new \"Notes\" section at the end.\\n    doc = inspect.cleandoc(func.__doc__)\\n    if \"\\\\nNotes\\\\n-----\" in doc:\\n        before, after = doc.split(\"\\\\nNotes\\\\n-----\", 1)\\n    elif (index := doc.find(\"\\\\nReferences\\\\n----------\")) != -1:\\n        before, after = doc[:index], doc[index:]\\n    elif (index := doc.find(\"\\\\nExamples\\\\n--------\")) != -1:\\n        before, after = doc[:index], doc[index:]\\n    else:\\n        # No \"Notes\", \"References\", or \"Examples\" --> append to the end.\\n        before = doc + \"\\\\n\"\\n        after = \"\"\\n\\n    func.__doc__ = f\"{before}\\\\nNotes\\\\n-----\\\\n\\\\n.. note::\\\\n\\\\n    {message}\\\\n{after}\"\\n\\n\\n## Global ##\\n\\n\\n# The state controlled by {,un}install_repl_displayhook().\\n_ReplDisplayHook = Enum(\"_ReplDisplayHook\", [\"NONE\", \"PLAIN\", \"IPYTHON\"])\\n_REPL_DISPLAYHOOK = _ReplDisplayHook.NONE\\n\\n\\ndef _draw_all_if_interactive() -> None:\\n    if matplotlib.is_interactive():\\n        draw_all()\\n\\n\\ndef install_repl_displayhook() -> None:\\n    \"\"\"\\n    Connect to the display hook of the current shell.\\n\\n    The display hook gets called when the read-evaluate-print-loop (REPL) of\\n    the shell has finished the execution of a command. We use this callback\\n    to be able to automatically update a figure in interactive mode.\\n\\n    This works both with IPython and with vanilla python shells.\\n    \"\"\"\\n    global _REPL_DISPLAYHOOK\\n\\n    if _REPL_DISPLAYHOOK is _ReplDisplayHook.IPYTHON:\\n        return\\n\\n    # See if we have IPython hooks around, if so use them.\\n    # Use ``sys.modules.get(name)`` rather than ``name in sys.modules`` as\\n    # entries can also have been explicitly set to None.\\n    mod_ipython = sys.modules.get(\"IPython\")\\n    if not mod_ipython:\\n        _REPL_DISPLAYHOOK = _ReplDisplayHook.PLAIN\\n        return\\n    ip = mod_ipython.get_ipython()\\n    if not ip:\\n        _REPL_DISPLAYHOOK = _ReplDisplayHook.PLAIN\\n        return\\n\\n    ip.events.register(\"post_execute\", _draw_all_if_interactive)\\n    _REPL_DISPLAYHOOK = _ReplDisplayHook.IPYTHON\\n\\n    if mod_ipython.version_info[:2] < (8, 24):\\n        # Use of backend2gui is not needed for IPython >= 8.24 as that functionality\\n        # has been moved to Matplotlib.\\n        # This code can be removed when Python 3.12, the latest version supported by\\n        # IPython < 8.24, reaches end-of-life in late 2028.\\n        from IPython.core.pylabtools import backend2gui\\n        ipython_gui_name = backend2gui.get(get_backend())\\n    else:\\n        _, ipython_gui_name = backend_registry.resolve_backend(get_backend())\\n    # trigger IPython\\'s eventloop integration, if available\\n    if ipython_gui_name:\\n        ip.enable_gui(ipython_gui_name)\\n\\n\\ndef uninstall_repl_displayhook() -> None:\\n    \"\"\"Disconnect from the display hook of the current shell.\"\"\"\\n    global _REPL_DISPLAYHOOK\\n    if _REPL_DISPLAYHOOK is _ReplDisplayHook.IPYTHON:\\n        from IPython import get_ipython\\n        ip = get_ipython()\\n        ip.events.unregister(\"post_execute\", _draw_all_if_interactive)\\n    _REPL_DISPLAYHOOK = _ReplDisplayHook.NONE\\n\\n\\ndraw_all = _pylab_helpers.Gcf.draw_all\\n\\n\\n# Ensure this appears in the pyplot docs.\\n@_copy_docstring_and_deprecators(matplotlib.set_loglevel)\\ndef set_loglevel(*args, **kwargs) -> None:\\n    return matplotlib.set_loglevel(*args, **kwargs)\\n\\n\\n@_copy_docstring_and_deprecators(Artist.findobj)\\ndef findobj(\\n    o: Artist | None = None,\\n    match: Callable[[Artist], bool] | type[Artist] | None = None,\\n    include_self: bool = True\\n) -> list[Artist]:\\n    if o is None:\\n        o = gcf()\\n    return o.findobj(match, include_self=include_self)\\n\\n\\n_backend_mod: type[matplotlib.backend_bases._Backend] | None = None\\n\\n\\ndef _get_backend_mod() -> type[matplotlib.backend_bases._Backend]:\\n    \"\"\"\\n    Ensure that a backend is selected and return it.\\n\\n    This is currently private, but may be made public in the future.\\n    \"\"\"\\n    if _backend_mod is None:\\n        # Use rcParams._get(\"backend\") to avoid going through the fallback\\n        # logic (which will (re)import pyplot and then call switch_backend if\\n        # we need to resolve the auto sentinel)\\n        switch_backend(rcParams._get(\"backend\"))\\n    return cast(type[matplotlib.backend_bases._Backend], _backend_mod)\\n\\n\\ndef switch_backend(newbackend: str) -> None:\\n    \"\"\"\\n    Set the pyplot backend.\\n\\n    Switching to an interactive backend is possible only if no event loop for\\n    another interactive backend has started.  Switching to and from\\n    non-interactive backends is always possible.\\n\\n    If the new backend is different than the current backend then all open\\n    Figures will be closed via ``plt.close(\\'all\\')``.\\n\\n    Parameters\\n    ----------\\n    newbackend : str\\n        The case-insensitive name of the backend to use.\\n\\n    \"\"\"\\n    global _backend_mod\\n    # make sure the init is pulled up so we can assign to it later\\n    import matplotlib.backends\\n\\n    if newbackend is rcsetup._auto_backend_sentinel:\\n        current_framework = cbook._get_running_interactive_framework()\\n\\n        if (current_framework and\\n                (backend := backend_registry.backend_for_gui_framework(\\n                    current_framework))):\\n            candidates = [backend]\\n        else:\\n            candidates = []\\n        candidates += [\\n            \"macosx\", \"qtagg\", \"gtk4agg\", \"gtk3agg\", \"tkagg\", \"wxagg\"]\\n\\n        # Don\\'t try to fallback on the cairo-based backends as they each have\\n        # an additional dependency (pycairo) over the agg-based backend, and\\n        # are of worse quality.\\n        for candidate in candidates:\\n            try:\\n                switch_backend(candidate)\\n            except ImportError:\\n                continue\\n            else:\\n                rcParamsOrig[\\'backend\\'] = candidate\\n                return\\n        else:\\n            # Switching to Agg should always succeed; if it doesn\\'t, let the\\n            # exception propagate out.\\n            switch_backend(\"agg\")\\n            rcParamsOrig[\"backend\"] = \"agg\"\\n            return\\n    old_backend = rcParams._get(\\'backend\\')  # get without triggering backend resolution\\n\\n    module = backend_registry.load_backend_module(newbackend)\\n    canvas_class = module.FigureCanvas\\n\\n    required_framework = canvas_class.required_interactive_framework\\n    if required_framework is not None:\\n        current_framework = cbook._get_running_interactive_framework()\\n        if (current_framework and required_framework\\n                and current_framework != required_framework):\\n            raise ImportError(\\n                \"Cannot load backend {!r} which requires the {!r} interactive \"\\n                \"framework, as {!r} is currently running\".format(\\n                    newbackend, required_framework, current_framework))\\n\\n    # Load the new_figure_manager() and show() functions from the backend.\\n\\n    # Classically, backends can directly export these functions.  This should\\n    # keep working for backcompat.\\n    new_figure_manager = getattr(module, \"new_figure_manager\", None)\\n    show = getattr(module, \"show\", None)\\n\\n    # In that classical approach, backends are implemented as modules, but\\n    # \"inherit\" default method implementations from backend_bases._Backend.\\n    # This is achieved by creating a \"class\" that inherits from\\n    # backend_bases._Backend and whose body is filled with the module globals.\\n    class backend_mod(matplotlib.backend_bases._Backend):\\n        locals().update(vars(module))\\n\\n    # However, the newer approach for defining new_figure_manager and\\n    # show is to derive them from canvas methods.  In that case, also\\n    # update backend_mod accordingly; also, per-backend customization of\\n    # draw_if_interactive is disabled.\\n    if new_figure_manager is None:\\n\\n        def new_figure_manager_given_figure(num, figure):\\n            return canvas_class.new_manager(figure, num)\\n\\n        def new_figure_manager(num, *args, FigureClass=Figure, **kwargs):\\n            fig = FigureClass(*args, **kwargs)\\n            return new_figure_manager_given_figure(num, fig)\\n\\n        def draw_if_interactive() -> None:\\n            if matplotlib.is_interactive():\\n                manager = _pylab_helpers.Gcf.get_active()\\n                if manager:\\n                    manager.canvas.draw_idle()\\n\\n        backend_mod.new_figure_manager_given_figure = (  # type: ignore[method-assign]\\n            new_figure_manager_given_figure)\\n        backend_mod.new_figure_manager = (  # type: ignore[method-assign]\\n            new_figure_manager)\\n        backend_mod.draw_if_interactive = (  # type: ignore[method-assign]\\n            draw_if_interactive)\\n\\n    # If the manager explicitly overrides pyplot_show, use it even if a global\\n    # show is already present, as the latter may be here for backcompat.\\n    manager_class = getattr(canvas_class, \"manager_class\", None)\\n    # We can\\'t compare directly manager_class.pyplot_show and FMB.pyplot_show because\\n    # pyplot_show is a classmethod so the above constructs are bound classmethods, and\\n    # thus always different (being bound to different classes).  We also have to use\\n    # getattr_static instead of vars as manager_class could have no __dict__.\\n    manager_pyplot_show = inspect.getattr_static(manager_class, \"pyplot_show\", None)\\n    base_pyplot_show = inspect.getattr_static(FigureManagerBase, \"pyplot_show\", None)\\n    if (show is None\\n            or (manager_pyplot_show is not None\\n                and manager_pyplot_show != base_pyplot_show)):\\n        if not manager_pyplot_show:\\n            raise ValueError(\\n                f\"Backend {newbackend} defines neither FigureCanvas.manager_class nor \"\\n                f\"a toplevel show function\")\\n        _pyplot_show = cast(\\'Any\\', manager_class).pyplot_show\\n        backend_mod.show = _pyplot_show  # type: ignore[method-assign]\\n\\n    _log.debug(\"Loaded backend %s version %s.\",\\n               newbackend, backend_mod.backend_version)\\n\\n    if newbackend in (\"ipympl\", \"widget\"):\\n        # ipympl < 0.9.4 expects rcParams[\"backend\"] to be the fully-qualified backend\\n        # name \"module://ipympl.backend_nbagg\" not short names \"ipympl\" or \"widget\".\\n        import importlib.metadata as im\\n        from matplotlib import _parse_to_version_info  # type: ignore[attr-defined]\\n        try:\\n            module_version = im.version(\"ipympl\")\\n            if _parse_to_version_info(module_version) < (0, 9, 4):\\n                newbackend = \"module://ipympl.backend_nbagg\"\\n        except im.PackageNotFoundError:\\n            pass\\n\\n    rcParams[\\'backend\\'] = rcParamsDefault[\\'backend\\'] = newbackend\\n    _backend_mod = backend_mod\\n    for func_name in [\"new_figure_manager\", \"draw_if_interactive\", \"show\"]:\\n        globals()[func_name].__signature__ = inspect.signature(\\n            getattr(backend_mod, func_name))\\n\\n    # Need to keep a global reference to the backend for compatibility reasons.\\n    # See https://github.com/matplotlib/matplotlib/issues/6092\\n    matplotlib.backends.backend = newbackend  # type: ignore[attr-defined]\\n\\n    # Make sure the repl display hook is installed in case we become interactive.\\n    install_repl_displayhook()\\n\\n\\ndef _warn_if_gui_out_of_main_thread() -> None:\\n    warn = False\\n    canvas_class = cast(type[FigureCanvasBase], _get_backend_mod().FigureCanvas)\\n    if canvas_class.required_interactive_framework:\\n        if hasattr(threading, \\'get_native_id\\'):\\n            # This compares native thread ids because even if Python-level\\n            # Thread objects match, the underlying OS thread (which is what\\n            # really matters) may be different on Python implementations with\\n            # green threads.\\n            if threading.get_native_id() != threading.main_thread().native_id:\\n                warn = True\\n        else:\\n            # Fall back to Python-level Thread if native IDs are unavailable,\\n            # mainly for PyPy.\\n            if threading.current_thread() is not threading.main_thread():\\n                warn = True\\n    if warn:\\n        _api.warn_external(\\n            \"Starting a Matplotlib GUI outside of the main thread will likely \"\\n            \"fail.\")\\n\\n\\n# This function\\'s signature is rewritten upon backend-load by switch_backend.\\ndef new_figure_manager(*args, **kwargs):\\n    \"\"\"Create a new figure manager instance.\"\"\"\\n    _warn_if_gui_out_of_main_thread()\\n    return _get_backend_mod().new_figure_manager(*args, **kwargs)\\n\\n\\n# This function\\'s signature is rewritten upon backend-load by switch_backend.\\ndef draw_if_interactive(*args, **kwargs):\\n    \"\"\"\\n    Redraw the current figure if in interactive mode.\\n\\n    .. warning::\\n\\n        End users will typically not have to call this function because the\\n        the interactive mode takes care of this.\\n    \"\"\"\\n    return _get_backend_mod().draw_if_interactive(*args, **kwargs)\\n\\n\\n# This function\\'s signature is rewritten upon backend-load by switch_backend.\\ndef show(*args, **kwargs) -> None:\\n    \"\"\"\\n    Display all open figures.\\n\\n    Parameters\\n    ----------\\n    block : bool, optional\\n        Whether to wait for all figures to be closed before returning.\\n\\n        If `True` block and run the GUI main loop until all figure windows\\n        are closed.\\n\\n        If `False` ensure that all figure windows are displayed and return\\n        immediately.  In this case, you are responsible for ensuring\\n        that the event loop is running to have responsive figures.\\n\\n        Defaults to True in non-interactive mode and to False in interactive\\n        mode (see `.pyplot.isinteractive`).\\n\\n    See Also\\n    --------\\n    ion : Enable interactive mode, which shows / updates the figure after\\n          every plotting command, so that calling ``show()`` is not necessary.\\n    ioff : Disable interactive mode.\\n    savefig : Save the figure to an image file instead of showing it on screen.\\n\\n    Notes\\n    -----\\n    **Saving figures to file and showing a window at the same time**\\n\\n    If you want an image file as well as a user interface window, use\\n    `.pyplot.savefig` before `.pyplot.show`. At the end of (a blocking)\\n    ``show()`` the figure is closed and thus unregistered from pyplot. Calling\\n    `.pyplot.savefig` afterwards would save a new and thus empty figure. This\\n    limitation of command order does not apply if the show is non-blocking or\\n    if you keep a reference to the figure and use `.Figure.savefig`.\\n\\n    **Auto-show in jupyter notebooks**\\n\\n    The jupyter backends (activated via ``%matplotlib inline``,\\n    ``%matplotlib notebook``, or ``%matplotlib widget``), call ``show()`` at\\n    the end of every cell by default. Thus, you usually don\\'t have to call it\\n    explicitly there.\\n    \"\"\"\\n    _warn_if_gui_out_of_main_thread()\\n    return _get_backend_mod().show(*args, **kwargs)\\n\\n\\ndef isinteractive() -> bool:\\n    \"\"\"\\n    Return whether plots are updated after every plotting command.\\n\\n    The interactive mode is mainly useful if you build plots from the command\\n    line and want to see the effect of each command while you are building the\\n    figure.\\n\\n    In interactive mode:\\n\\n    - newly created figures will be shown immediately;\\n    - figures will automatically redraw on change;\\n    - `.pyplot.show` will not block by default.\\n\\n    In non-interactive mode:\\n\\n    - newly created figures and changes to figures will not be reflected until\\n      explicitly asked to be;\\n    - `.pyplot.show` will block by default.\\n\\n    See Also\\n    --------\\n    ion : Enable interactive mode.\\n    ioff : Disable interactive mode.\\n    show : Show all figures (and maybe block).\\n    pause : Show all figures, and block for a time.\\n    \"\"\"\\n    return matplotlib.is_interactive()\\n\\n\\n# Note: The return type of ioff being AbstractContextManager\\n# instead of ExitStack is deliberate.\\n# See https://github.com/matplotlib/matplotlib/issues/27659\\n# and https://github.com/matplotlib/matplotlib/pull/27667 for more info.\\ndef ioff() -> AbstractContextManager:\\n    \"\"\"\\n    Disable interactive mode.\\n\\n    See `.pyplot.isinteractive` for more details.\\n\\n    See Also\\n    --------\\n    ion : Enable interactive mode.\\n    isinteractive : Whether interactive mode is enabled.\\n    show : Show all figures (and maybe block).\\n    pause : Show all figures, and block for a time.\\n\\n    Notes\\n    -----\\n    For a temporary change, this can be used as a context manager::\\n\\n        # if interactive mode is on\\n        # then figures will be shown on creation\\n        plt.ion()\\n        # This figure will be shown immediately\\n        fig = plt.figure()\\n\\n        with plt.ioff():\\n            # interactive mode will be off\\n            # figures will not automatically be shown\\n            fig2 = plt.figure()\\n            # ...\\n\\n    To enable optional usage as a context manager, this function returns a\\n    context manager object, which is not intended to be stored or\\n    accessed by the user.\\n    \"\"\"\\n    stack = ExitStack()\\n    stack.callback(ion if isinteractive() else ioff)\\n    matplotlib.interactive(False)\\n    uninstall_repl_displayhook()\\n    return stack\\n\\n\\n# Note: The return type of ion being AbstractContextManager\\n# instead of ExitStack is deliberate.\\n# See https://github.com/matplotlib/matplotlib/issues/27659\\n# and https://github.com/matplotlib/matplotlib/pull/27667 for more info.\\ndef ion() -> AbstractContextManager:\\n    \"\"\"\\n    Enable interactive mode.\\n\\n    See `.pyplot.isinteractive` for more details.\\n\\n    See Also\\n    --------\\n    ioff : Disable interactive mode.\\n    isinteractive : Whether interactive mode is enabled.\\n    show : Show all figures (and maybe block).\\n    pause : Show all figures, and block for a time.\\n\\n    Notes\\n    -----\\n    For a temporary change, this can be used as a context manager::\\n\\n        # if interactive mode is off\\n        # then figures will not be shown on creation\\n        plt.ioff()\\n        # This figure will not be shown immediately\\n        fig = plt.figure()\\n\\n        with plt.ion():\\n            # interactive mode will be on\\n            # figures will automatically be shown\\n            fig2 = plt.figure()\\n            # ...\\n\\n    To enable optional usage as a context manager, this function returns a\\n    context manager object, which is not intended to be stored or\\n    accessed by the user.\\n    \"\"\"\\n    stack = ExitStack()\\n    stack.callback(ion if isinteractive() else ioff)\\n    matplotlib.interactive(True)\\n    install_repl_displayhook()\\n    return stack\\n\\n\\ndef pause(interval: float) -> None:\\n    \"\"\"\\n    Run the GUI event loop for *interval* seconds.\\n\\n    If there is an active figure, it will be updated and displayed before the\\n    pause, and the GUI event loop (if any) will run during the pause.\\n\\n    This can be used for crude animation.  For more complex animation use\\n    :mod:`matplotlib.animation`.\\n\\n    If there is no active figure, sleep for *interval* seconds instead.\\n\\n    See Also\\n    --------\\n    matplotlib.animation : Proper animations\\n    show : Show all figures and optional block until all figures are closed.\\n    \"\"\"\\n    manager = _pylab_helpers.Gcf.get_active()\\n    if manager is not None:\\n        canvas = manager.canvas\\n        if canvas.figure.stale:\\n            canvas.draw_idle()\\n        show(block=False)\\n        canvas.start_event_loop(interval)\\n    else:\\n        time.sleep(interval)\\n\\n\\n@_copy_docstring_and_deprecators(matplotlib.rc)\\ndef rc(group: str, **kwargs) -> None:\\n    matplotlib.rc(group, **kwargs)\\n\\n\\n@_copy_docstring_and_deprecators(matplotlib.rc_context)\\ndef rc_context(\\n    rc: dict[str, Any] | None = None,\\n    fname: str | pathlib.Path | os.PathLike | None = None,\\n) -> AbstractContextManager[None]:\\n    return matplotlib.rc_context(rc, fname)\\n\\n\\n@_copy_docstring_and_deprecators(matplotlib.rcdefaults)\\ndef rcdefaults() -> None:\\n    matplotlib.rcdefaults()\\n    if matplotlib.is_interactive():\\n        draw_all()\\n\\n\\n# getp/get/setp are explicitly reexported so that they show up in pyplot docs.\\n\\n\\n@_copy_docstring_and_deprecators(matplotlib.artist.getp)\\ndef getp(obj, *args, **kwargs):\\n    return matplotlib.artist.getp(obj, *args, **kwargs)\\n\\n\\n@_copy_docstring_and_deprecators(matplotlib.artist.get)\\ndef get(obj, *args, **kwargs):\\n    return matplotlib.artist.get(obj, *args, **kwargs)\\n\\n\\n@_copy_docstring_and_deprecators(matplotlib.artist.setp)\\ndef setp(obj, *args, **kwargs):\\n    return matplotlib.artist.setp(obj, *args, **kwargs)\\n\\n\\ndef xkcd(\\n    scale: float = 1, length: float = 100, randomness: float = 2\\n) -> ExitStack:\\n    \"\"\"\\n    Turn on `xkcd <https://xkcd.com/>`_ sketch-style drawing mode.\\n\\n    This will only have an effect on things drawn after this function is called.\\n\\n    For best results, install the `xkcd script <https://github.com/ipython/xkcd-font/>`_\\n    font; xkcd fonts are not packaged with Matplotlib.\\n\\n    Parameters\\n    ----------\\n    scale : float, optional\\n        The amplitude of the wiggle perpendicular to the source line.\\n    length : float, optional\\n        The length of the wiggle along the line.\\n    randomness : float, optional\\n        The scale factor by which the length is shrunken or expanded.\\n\\n    Notes\\n    -----\\n    This function works by a number of rcParams, so it will probably\\n    override others you have set before.\\n\\n    If you want the effects of this function to be temporary, it can\\n    be used as a context manager, for example::\\n\\n        with plt.xkcd():\\n            # This figure will be in XKCD-style\\n            fig1 = plt.figure()\\n            # ...\\n\\n        # This figure will be in regular style\\n        fig2 = plt.figure()\\n    \"\"\"\\n    # This cannot be implemented in terms of contextmanager() or rc_context()\\n    # because this needs to work as a non-contextmanager too.\\n\\n    if rcParams[\\'text.usetex\\']:\\n        raise RuntimeError(\\n            \"xkcd mode is not compatible with text.usetex = True\")\\n\\n    stack = ExitStack()\\n    stack.callback(rcParams._update_raw, rcParams.copy())  # type: ignore[arg-type]\\n\\n    from matplotlib import patheffects\\n    rcParams.update({\\n        \\'font.family\\': [\\'xkcd\\', \\'xkcd Script\\', \\'Comic Neue\\', \\'Comic Sans MS\\'],\\n        \\'font.size\\': 14.0,\\n        \\'path.sketch\\': (scale, length, randomness),\\n        \\'path.effects\\': [\\n            patheffects.withStroke(linewidth=4, foreground=\"w\")],\\n        \\'axes.linewidth\\': 1.5,\\n        \\'lines.linewidth\\': 2.0,\\n        \\'figure.facecolor\\': \\'white\\',\\n        \\'grid.linewidth\\': 0.0,\\n        \\'axes.grid\\': False,\\n        \\'axes.unicode_minus\\': False,\\n        \\'axes.edgecolor\\': \\'black\\',\\n        \\'xtick.major.size\\': 8,\\n        \\'xtick.major.width\\': 3,\\n        \\'ytick.major.size\\': 8,\\n        \\'ytick.major.width\\': 3,\\n    })\\n\\n    return stack\\n\\n\\n## Figures ##\\n\\ndef figure(\\n    # autoincrement if None, else integer from 1-N\\n    num: int | str | Figure | SubFigure | None = None,\\n    # defaults to rc figure.figsize\\n    figsize: tuple[float, float] | None = None,\\n    # defaults to rc figure.dpi\\n    dpi: float | None = None,\\n    *,\\n    # defaults to rc figure.facecolor\\n    facecolor: ColorType | None = None,\\n    # defaults to rc figure.edgecolor\\n    edgecolor: ColorType | None = None,\\n    frameon: bool = True,\\n    FigureClass: type[Figure] = Figure,\\n    clear: bool = False,\\n    **kwargs\\n) -> Figure:\\n    \"\"\"\\n    Create a new figure, or activate an existing figure.\\n\\n    Parameters\\n    ----------\\n    num : int or str or `.Figure` or `.SubFigure`, optional\\n        A unique identifier for the figure.\\n\\n        If a figure with that identifier already exists, this figure is made\\n        active and returned. An integer refers to the ``Figure.number``\\n        attribute, a string refers to the figure label.\\n\\n        If there is no figure with the identifier or *num* is not given, a new\\n        figure is created, made active and returned.  If *num* is an int, it\\n        will be used for the ``Figure.number`` attribute, otherwise, an\\n        auto-generated integer value is used (starting at 1 and incremented\\n        for each new figure). If *num* is a string, the figure label and the\\n        window title is set to this value.  If num is a ``SubFigure``, its\\n        parent ``Figure`` is activated.\\n\\n    figsize : (float, float), default: :rc:`figure.figsize`\\n        Width, height in inches.\\n\\n    dpi : float, default: :rc:`figure.dpi`\\n        The resolution of the figure in dots-per-inch.\\n\\n    facecolor : :mpltype:`color`, default: :rc:`figure.facecolor`\\n        The background color.\\n\\n    edgecolor : :mpltype:`color`, default: :rc:`figure.edgecolor`\\n        The border color.\\n\\n    frameon : bool, default: True\\n        If False, suppress drawing the figure frame.\\n\\n    FigureClass : subclass of `~matplotlib.figure.Figure`\\n        If set, an instance of this subclass will be created, rather than a\\n        plain `.Figure`.\\n\\n    clear : bool, default: False\\n        If True and the figure already exists, then it is cleared.\\n\\n    layout : {\\'constrained\\', \\'compressed\\', \\'tight\\', \\'none\\', `.LayoutEngine`, None}, \\\\\\ndefault: None\\n        The layout mechanism for positioning of plot elements to avoid\\n        overlapping Axes decorations (labels, ticks, etc). Note that layout\\n        managers can measurably slow down figure display.\\n\\n        - \\'constrained\\': The constrained layout solver adjusts Axes sizes\\n          to avoid overlapping Axes decorations.  Can handle complex plot\\n          layouts and colorbars, and is thus recommended.\\n\\n          See :ref:`constrainedlayout_guide`\\n          for examples.\\n\\n        - \\'compressed\\': uses the same algorithm as \\'constrained\\', but\\n          removes extra space between fixed-aspect-ratio Axes.  Best for\\n          simple grids of Axes.\\n\\n        - \\'tight\\': Use the tight layout mechanism. This is a relatively\\n          simple algorithm that adjusts the subplot parameters so that\\n          decorations do not overlap. See `.Figure.set_tight_layout` for\\n          further details.\\n\\n        - \\'none\\': Do not use a layout engine.\\n\\n        - A `.LayoutEngine` instance. Builtin layout classes are\\n          `.ConstrainedLayoutEngine` and `.TightLayoutEngine`, more easily\\n          accessible by \\'constrained\\' and \\'tight\\'.  Passing an instance\\n          allows third parties to provide their own layout engine.\\n\\n        If not given, fall back to using the parameters *tight_layout* and\\n        *constrained_layout*, including their config defaults\\n        :rc:`figure.autolayout` and :rc:`figure.constrained_layout.use`.\\n\\n    **kwargs\\n        Additional keyword arguments are passed to the `.Figure` constructor.\\n\\n    Returns\\n    -------\\n    `~matplotlib.figure.Figure`\\n\\n    Notes\\n    -----\\n    A newly created figure is passed to the `~.FigureCanvasBase.new_manager`\\n    method or the `new_figure_manager` function provided by the current\\n    backend, which install a canvas and a manager on the figure.\\n\\n    Once this is done, :rc:`figure.hooks` are called, one at a time, on the\\n    figure; these hooks allow arbitrary customization of the figure (e.g.,\\n    attaching callbacks) or of associated elements (e.g., modifying the\\n    toolbar).  See :doc:`/gallery/user_interfaces/mplcvd` for an example of\\n    toolbar customization.\\n\\n    If you are creating many figures, make sure you explicitly call\\n    `.pyplot.close` on the figures you are not using, because this will\\n    enable pyplot to properly clean up the memory.\\n\\n    `~matplotlib.rcParams` defines the default values, which can be modified\\n    in the matplotlibrc file.\\n    \"\"\"\\n    allnums = get_fignums()\\n\\n    if isinstance(num, FigureBase):\\n        # type narrowed to `Figure | SubFigure` by combination of input and isinstance\\n        root_fig = num.get_figure(root=True)\\n        if root_fig.canvas.manager is None:\\n            raise ValueError(\"The passed figure is not managed by pyplot\")\\n        elif any([figsize, dpi, facecolor, edgecolor, not frameon,\\n                  kwargs]) and root_fig.canvas.manager.num in allnums:\\n            _api.warn_external(\\n                \"Ignoring specified arguments in this call because figure \"\\n                f\"with num: {root_fig.canvas.manager.num} already exists\")\\n        _pylab_helpers.Gcf.set_active(root_fig.canvas.manager)\\n        return root_fig\\n\\n    next_num = max(allnums) + 1 if allnums else 1\\n    fig_label = \\'\\'\\n    if num is None:\\n        num = next_num\\n    else:\\n        if any([figsize, dpi, facecolor, edgecolor, not frameon,\\n                kwargs]) and num in allnums:\\n            _api.warn_external(\\n                \"Ignoring specified arguments in this call \"\\n                f\"because figure with num: {num} already exists\")\\n        if isinstance(num, str):\\n            fig_label = num\\n            all_labels = get_figlabels()\\n            if fig_label not in all_labels:\\n                if fig_label == \\'all\\':\\n                    _api.warn_external(\"close(\\'all\\') closes all existing figures.\")\\n                num = next_num\\n            else:\\n                inum = all_labels.index(fig_label)\\n                num = allnums[inum]\\n        else:\\n            num = int(num)  # crude validation of num argument\\n\\n    # Type of \"num\" has narrowed to int, but mypy can\\'t quite see it\\n    manager = _pylab_helpers.Gcf.get_fig_manager(num)  # type: ignore[arg-type]\\n    if manager is None:\\n        max_open_warning = rcParams[\\'figure.max_open_warning\\']\\n        if len(allnums) == max_open_warning >= 1:\\n            _api.warn_external(\\n                f\"More than {max_open_warning} figures have been opened. \"\\n                f\"Figures created through the pyplot interface \"\\n                f\"(`matplotlib.pyplot.figure`) are retained until explicitly \"\\n                f\"closed and may consume too much memory. (To control this \"\\n                f\"warning, see the rcParam `figure.max_open_warning`). \"\\n                f\"Consider using `matplotlib.pyplot.close()`.\",\\n                RuntimeWarning)\\n\\n        manager = new_figure_manager(\\n            num, figsize=figsize, dpi=dpi,\\n            facecolor=facecolor, edgecolor=edgecolor, frameon=frameon,\\n            FigureClass=FigureClass, **kwargs)\\n        fig = manager.canvas.figure\\n        if fig_label:\\n            fig.set_label(fig_label)\\n\\n        for hookspecs in rcParams[\"figure.hooks\"]:\\n            module_name, dotted_name = hookspecs.split(\":\")\\n            obj: Any = importlib.import_module(module_name)\\n            for part in dotted_name.split(\".\"):\\n                obj = getattr(obj, part)\\n            obj(fig)\\n\\n        _pylab_helpers.Gcf._set_new_active_manager(manager)\\n\\n        # make sure backends (inline) that we don\\'t ship that expect this\\n        # to be called in plotting commands to make the figure call show\\n        # still work.  There is probably a better way to do this in the\\n        # FigureManager base class.\\n        draw_if_interactive()\\n\\n        if _REPL_DISPLAYHOOK is _ReplDisplayHook.PLAIN:\\n            fig.stale_callback = _auto_draw_if_interactive\\n\\n    if clear:\\n        manager.canvas.figure.clear()\\n\\n    return manager.canvas.figure\\n\\n\\ndef _auto_draw_if_interactive(fig, val):\\n    \"\"\"\\n    An internal helper function for making sure that auto-redrawing\\n    works as intended in the plain python repl.\\n\\n    Parameters\\n    ----------\\n    fig : Figure\\n        A figure object which is assumed to be associated with a canvas\\n    \"\"\"\\n    if (val and matplotlib.is_interactive()\\n            and not fig.canvas.is_saving()\\n            and not fig.canvas._is_idle_drawing):\\n        # Some artists can mark themselves as stale in the middle of drawing\\n        # (e.g. axes position & tick labels being computed at draw time), but\\n        # this shouldn\\'t trigger a redraw because the current redraw will\\n        # already take them into account.\\n        with fig.canvas._idle_draw_cntx():\\n            fig.canvas.draw_idle()\\n\\n\\ndef gcf() -> Figure:\\n    \"\"\"\\n    Get the current figure.\\n\\n    If there is currently no figure on the pyplot figure stack, a new one is\\n    created using `~.pyplot.figure()`.  (To test whether there is currently a\\n    figure on the pyplot figure stack, check whether `~.pyplot.get_fignums()`\\n    is empty.)\\n    \"\"\"\\n    manager = _pylab_helpers.Gcf.get_active()\\n    if manager is not None:\\n        return manager.canvas.figure\\n    else:\\n        return figure()\\n\\n\\ndef fignum_exists(num: int | str) -> bool:\\n    \"\"\"\\n    Return whether the figure with the given id exists.\\n\\n    Parameters\\n    ----------\\n    num : int or str\\n        A figure identifier.\\n\\n    Returns\\n    -------\\n    bool\\n        Whether or not a figure with id *num* exists.\\n    \"\"\"\\n    return (\\n        _pylab_helpers.Gcf.has_fignum(num)\\n        if isinstance(num, int)\\n        else num in get_figlabels()\\n    )\\n\\n\\ndef get_fignums() -> list[int]:\\n    \"\"\"Return a list of existing figure numbers.\"\"\"\\n    return sorted(_pylab_helpers.Gcf.figs)\\n\\n\\ndef get_figlabels() -> list[Any]:\\n    \"\"\"Return a list of existing figure labels.\"\"\"\\n    managers = _pylab_helpers.Gcf.get_all_fig_managers()\\n    managers.sort(key=lambda m: m.num)\\n    return [m.canvas.figure.get_label() for m in managers]\\n\\n\\ndef get_current_fig_manager() -> FigureManagerBase | None:\\n    \"\"\"\\n    Return the figure manager of the current figure.\\n\\n    The figure manager is a container for the actual backend-depended window\\n    that displays the figure on screen.\\n\\n    If no current figure exists, a new one is created, and its figure\\n    manager is returned.\\n\\n    Returns\\n    -------\\n    `.FigureManagerBase` or backend-dependent subclass thereof\\n    \"\"\"\\n    return gcf().canvas.manager\\n\\n\\n@_copy_docstring_and_deprecators(FigureCanvasBase.mpl_connect)\\ndef connect(s: str, func: Callable[[Event], Any]) -> int:\\n    return gcf().canvas.mpl_connect(s, func)\\n\\n\\n@_copy_docstring_and_deprecators(FigureCanvasBase.mpl_disconnect)\\ndef disconnect(cid: int) -> None:\\n    gcf().canvas.mpl_disconnect(cid)\\n\\n\\ndef close(fig: None | int | str | Figure | Literal[\"all\"] = None) -> None:\\n    \"\"\"\\n    Close a figure window.\\n\\n    Parameters\\n    ----------\\n    fig : None or int or str or `.Figure`\\n        The figure to close. There are a number of ways to specify this:\\n\\n        - *None*: the current figure\\n        - `.Figure`: the given `.Figure` instance\\n        - ``int``: a figure number\\n        - ``str``: a figure name\\n        - \\'all\\': all figures\\n\\n    \"\"\"\\n    if fig is None:\\n        manager = _pylab_helpers.Gcf.get_active()\\n        if manager is None:\\n            return\\n        else:\\n            _pylab_helpers.Gcf.destroy(manager)\\n    elif fig == \\'all\\':\\n        _pylab_helpers.Gcf.destroy_all()\\n    elif isinstance(fig, int):\\n        _pylab_helpers.Gcf.destroy(fig)\\n    elif hasattr(fig, \\'int\\'):\\n        # if we are dealing with a type UUID, we\\n        # can use its integer representation\\n        _pylab_helpers.Gcf.destroy(fig.int)\\n    elif isinstance(fig, str):\\n        all_labels = get_figlabels()\\n        if fig in all_labels:\\n            num = get_fignums()[all_labels.index(fig)]\\n            _pylab_helpers.Gcf.destroy(num)\\n    elif isinstance(fig, Figure):\\n        _pylab_helpers.Gcf.destroy_fig(fig)\\n    else:\\n        raise TypeError(\"close() argument must be a Figure, an int, a string, \"\\n                        \"or None, not %s\" % type(fig))\\n\\n\\ndef clf() -> None:\\n    \"\"\"Clear the current figure.\"\"\"\\n    gcf().clear()\\n\\n\\ndef draw() -> None:\\n    \"\"\"\\n    Redraw the current figure.\\n\\n    This is used to update a figure that has been altered, but not\\n    automatically re-drawn.  If interactive mode is on (via `.ion()`), this\\n    should be only rarely needed, but there may be ways to modify the state of\\n    a figure without marking it as \"stale\".  Please report these cases as bugs.\\n\\n    This is equivalent to calling ``fig.canvas.draw_idle()``, where ``fig`` is\\n    the current figure.\\n\\n    See Also\\n    --------\\n    .FigureCanvasBase.draw_idle\\n    .FigureCanvasBase.draw\\n    \"\"\"\\n    gcf().canvas.draw_idle()\\n\\n\\n@_copy_docstring_and_deprecators(Figure.savefig)\\ndef savefig(*args, **kwargs) -> None:\\n    fig = gcf()\\n    # savefig default implementation has no return, so mypy is unhappy\\n    # presumably this is here because subclasses can return?\\n    res = fig.savefig(*args, **kwargs)  # type: ignore[func-returns-value]\\n    fig.canvas.draw_idle()  # Need this if \\'transparent=True\\', to reset colors.\\n    return res\\n\\n\\n## Putting things in figures ##\\n\\n\\ndef figlegend(*args, **kwargs) -> Legend:\\n    return gcf().legend(*args, **kwargs)\\nif Figure.legend.__doc__:\\n    figlegend.__doc__ = Figure.legend.__doc__ \\\\\\n        .replace(\" legend(\", \" figlegend(\") \\\\\\n        .replace(\"fig.legend(\", \"plt.figlegend(\") \\\\\\n        .replace(\"ax.plot(\", \"plt.plot(\")\\n\\n\\n## Axes ##\\n\\n@_docstring.interpd\\ndef axes(\\n    arg: None | tuple[float, float, float, float] = None,\\n    **kwargs\\n) -> matplotlib.axes.Axes:\\n    \"\"\"\\n    Add an Axes to the current figure and make it the current Axes.\\n\\n    Call signatures::\\n\\n        plt.axes()\\n        plt.axes(rect, projection=None, polar=False, **kwargs)\\n        plt.axes(ax)\\n\\n    Parameters\\n    ----------\\n    arg : None or 4-tuple\\n        The exact behavior of this function depends on the type:\\n\\n        - *None*: A new full window Axes is added using\\n          ``subplot(**kwargs)``.\\n        - 4-tuple of floats *rect* = ``(left, bottom, width, height)``.\\n          A new Axes is added with dimensions *rect* in normalized\\n          (0, 1) units using `~.Figure.add_axes` on the current figure.\\n\\n    projection : {None, \\'aitoff\\', \\'hammer\\', \\'lambert\\', \\'mollweide\\', \\\\\\n\\'polar\\', \\'rectilinear\\', str}, optional\\n        The projection type of the `~.axes.Axes`. *str* is the name of\\n        a custom projection, see `~matplotlib.projections`. The default\\n        None results in a \\'rectilinear\\' projection.\\n\\n    polar : bool, default: False\\n        If True, equivalent to projection=\\'polar\\'.\\n\\n    sharex, sharey : `~matplotlib.axes.Axes`, optional\\n        Share the x or y `~matplotlib.axis` with sharex and/or sharey.\\n        The axis will have the same limits, ticks, and scale as the axis\\n        of the shared Axes.\\n\\n    label : str\\n        A label for the returned Axes.\\n\\n    Returns\\n    -------\\n    `~.axes.Axes`, or a subclass of `~.axes.Axes`\\n        The returned Axes class depends on the projection used. It is\\n        `~.axes.Axes` if rectilinear projection is used and\\n        `.projections.polar.PolarAxes` if polar projection is used.\\n\\n    Other Parameters\\n    ----------------\\n    **kwargs\\n        This method also takes the keyword arguments for\\n        the returned Axes class. The keyword arguments for the\\n        rectilinear Axes class `~.axes.Axes` can be found in\\n        the following table but there might also be other keyword\\n        arguments if another projection is used, see the actual Axes\\n        class.\\n\\n        %(Axes:kwdoc)s\\n\\n    See Also\\n    --------\\n    .Figure.add_axes\\n    .pyplot.subplot\\n    .Figure.add_subplot\\n    .Figure.subplots\\n    .pyplot.subplots\\n\\n    Examples\\n    --------\\n    ::\\n\\n        # Creating a new full window Axes\\n        plt.axes()\\n\\n        # Creating a new Axes with specified dimensions and a grey background\\n        plt.axes((left, bottom, width, height), facecolor=\\'grey\\')\\n    \"\"\"\\n    fig = gcf()\\n    pos = kwargs.pop(\\'position\\', None)\\n    if arg is None:\\n        if pos is None:\\n            return fig.add_subplot(**kwargs)\\n        else:\\n            return fig.add_axes(pos, **kwargs)\\n    else:\\n        return fig.add_axes(arg, **kwargs)\\n\\n\\ndef delaxes(ax: matplotlib.axes.Axes | None = None) -> None:\\n    \"\"\"\\n    Remove an `~.axes.Axes` (defaulting to the current Axes) from its figure.\\n    \"\"\"\\n    if ax is None:\\n        ax = gca()\\n    ax.remove()\\n\\n\\ndef sca(ax: Axes) -> None:\\n    \"\"\"\\n    Set the current Axes to *ax* and the current Figure to the parent of *ax*.\\n    \"\"\"\\n    # Mypy sees ax.figure as potentially None,\\n    # but if you are calling this, it won\\'t be None\\n    # Additionally the slight difference between `Figure` and `FigureBase` mypy catches\\n    fig = ax.get_figure(root=False)\\n    figure(fig)  # type: ignore[arg-type]\\n    fig.sca(ax)  # type: ignore[union-attr]\\n\\n\\ndef cla() -> None:\\n    \"\"\"Clear the current Axes.\"\"\"\\n    # Not generated via boilerplate.py to allow a different docstring.\\n    return gca().cla()\\n\\n\\n## More ways of creating Axes ##\\n\\n@_docstring.interpd\\ndef subplot(*args, **kwargs) -> Axes:\\n    \"\"\"\\n    Add an Axes to the current figure or retrieve an existing Axes.\\n\\n    This is a wrapper of `.Figure.add_subplot` which provides additional\\n    behavior when working with the implicit API (see the notes section).\\n\\n    Call signatures::\\n\\n       subplot(nrows, ncols, index, **kwargs)\\n       subplot(pos, **kwargs)\\n       subplot(**kwargs)\\n       subplot(ax)\\n\\n    Parameters\\n    ----------\\n    *args : int, (int, int, *index*), or `.SubplotSpec`, default: (1, 1, 1)\\n        The position of the subplot described by one of\\n\\n        - Three integers (*nrows*, *ncols*, *index*). The subplot will take the\\n          *index* position on a grid with *nrows* rows and *ncols* columns.\\n          *index* starts at 1 in the upper left corner and increases to the\\n          right. *index* can also be a two-tuple specifying the (*first*,\\n          *last*) indices (1-based, and including *last*) of the subplot, e.g.,\\n          ``fig.add_subplot(3, 1, (1, 2))`` makes a subplot that spans the\\n          upper 2/3 of the figure.\\n        - A 3-digit integer. The digits are interpreted as if given separately\\n          as three single-digit integers, i.e. ``fig.add_subplot(235)`` is the\\n          same as ``fig.add_subplot(2, 3, 5)``. Note that this can only be used\\n          if there are no more than 9 subplots.\\n        - A `.SubplotSpec`.\\n\\n    projection : {None, \\'aitoff\\', \\'hammer\\', \\'lambert\\', \\'mollweide\\', \\\\\\n\\'polar\\', \\'rectilinear\\', str}, optional\\n        The projection type of the subplot (`~.axes.Axes`). *str* is the name\\n        of a custom projection, see `~matplotlib.projections`. The default\\n        None results in a \\'rectilinear\\' projection.\\n\\n    polar : bool, default: False\\n        If True, equivalent to projection=\\'polar\\'.\\n\\n    sharex, sharey : `~matplotlib.axes.Axes`, optional\\n        Share the x or y `~matplotlib.axis` with sharex and/or sharey. The\\n        axis will have the same limits, ticks, and scale as the axis of the\\n        shared Axes.\\n\\n    label : str\\n        A label for the returned Axes.\\n\\n    Returns\\n    -------\\n    `~.axes.Axes`\\n\\n        The Axes of the subplot. The returned Axes can actually be an instance\\n        of a subclass, such as `.projections.polar.PolarAxes` for polar\\n        projections.\\n\\n    Other Parameters\\n    ----------------\\n    **kwargs\\n        This method also takes the keyword arguments for the returned Axes\\n        base class; except for the *figure* argument. The keyword arguments\\n        for the rectilinear base class `~.axes.Axes` can be found in\\n        the following table but there might also be other keyword\\n        arguments if another projection is used.\\n\\n        %(Axes:kwdoc)s\\n\\n    Notes\\n    -----\\n    Creating a new Axes will delete any preexisting Axes that\\n    overlaps with it beyond sharing a boundary::\\n\\n        import matplotlib.pyplot as plt\\n        # plot a line, implicitly creating a subplot(111)\\n        plt.plot([1, 2, 3])\\n        # now create a subplot which represents the top plot of a grid\\n        # with 2 rows and 1 column. Since this subplot will overlap the\\n        # first, the plot (and its Axes) previously created, will be removed\\n        plt.subplot(211)\\n\\n    If you do not want this behavior, use the `.Figure.add_subplot` method\\n    or the `.pyplot.axes` function instead.\\n\\n    If no *kwargs* are passed and there exists an Axes in the location\\n    specified by *args* then that Axes will be returned rather than a new\\n    Axes being created.\\n\\n    If *kwargs* are passed and there exists an Axes in the location\\n    specified by *args*, the projection type is the same, and the\\n    *kwargs* match with the existing Axes, then the existing Axes is\\n    returned.  Otherwise a new Axes is created with the specified\\n    parameters.  We save a reference to the *kwargs* which we use\\n    for this comparison.  If any of the values in *kwargs* are\\n    mutable we will not detect the case where they are mutated.\\n    In these cases we suggest using `.Figure.add_subplot` and the\\n    explicit Axes API rather than the implicit pyplot API.\\n\\n    See Also\\n    --------\\n    .Figure.add_subplot\\n    .pyplot.subplots\\n    .pyplot.axes\\n    .Figure.subplots\\n\\n    Examples\\n    --------\\n    ::\\n\\n        plt.subplot(221)\\n\\n        # equivalent but more general\\n        ax1 = plt.subplot(2, 2, 1)\\n\\n        # add a subplot with no frame\\n        ax2 = plt.subplot(222, frameon=False)\\n\\n        # add a polar subplot\\n        plt.subplot(223, projection=\\'polar\\')\\n\\n        # add a red subplot that shares the x-axis with ax1\\n        plt.subplot(224, sharex=ax1, facecolor=\\'red\\')\\n\\n        # delete ax2 from the figure\\n        plt.delaxes(ax2)\\n\\n        # add ax2 to the figure again\\n        plt.subplot(ax2)\\n\\n        # make the first Axes \"current\" again\\n        plt.subplot(221)\\n\\n    \"\"\"\\n    # Here we will only normalize `polar=True` vs `projection=\\'polar\\'` and let\\n    # downstream code deal with the rest.\\n    unset = object()\\n    projection = kwargs.get(\\'projection\\', unset)\\n    polar = kwargs.pop(\\'polar\\', unset)\\n    if polar is not unset and polar:\\n        # if we got mixed messages from the user, raise\\n        if projection is not unset and projection != \\'polar\\':\\n            raise ValueError(\\n                f\"polar={polar}, yet projection={projection!r}. \"\\n                \"Only one of these arguments should be supplied.\"\\n            )\\n        kwargs[\\'projection\\'] = projection = \\'polar\\'\\n\\n    # if subplot called without arguments, create subplot(1, 1, 1)\\n    if len(args) == 0:\\n        args = (1, 1, 1)\\n\\n    # This check was added because it is very easy to type subplot(1, 2, False)\\n    # when subplots(1, 2, False) was intended (sharex=False, that is). In most\\n    # cases, no error will ever occur, but mysterious behavior can result\\n    # because what was intended to be the sharex argument is instead treated as\\n    # a subplot index for subplot()\\n    if len(args) >= 3 and isinstance(args[2], bool):\\n        _api.warn_external(\"The subplot index argument to subplot() appears \"\\n                           \"to be a boolean. Did you intend to use \"\\n                           \"subplots()?\")\\n    # Check for nrows and ncols, which are not valid subplot args:\\n    if \\'nrows\\' in kwargs or \\'ncols\\' in kwargs:\\n        raise TypeError(\"subplot() got an unexpected keyword argument \\'ncols\\' \"\\n                        \"and/or \\'nrows\\'.  Did you intend to call subplots()?\")\\n\\n    fig = gcf()\\n\\n    # First, search for an existing subplot with a matching spec.\\n    key = SubplotSpec._from_subplot_args(fig, args)\\n\\n    for ax in fig.axes:\\n        # If we found an Axes at the position, we can reuse it if the user passed no\\n        # kwargs or if the Axes class and kwargs are identical.\\n        if (ax.get_subplotspec() == key\\n            and (kwargs == {}\\n                 or (ax._projection_init\\n                     == fig._process_projection_requirements(**kwargs)))):\\n            break\\n    else:\\n        # we have exhausted the known Axes and none match, make a new one!\\n        ax = fig.add_subplot(*args, **kwargs)\\n\\n    fig.sca(ax)\\n\\n    return ax\\n\\n\\n@overload\\ndef subplots(\\n    nrows: Literal[1] = ...,\\n    ncols: Literal[1] = ...,\\n    *,\\n    sharex: bool | Literal[\"none\", \"all\", \"row\", \"col\"] = ...,\\n    sharey: bool | Literal[\"none\", \"all\", \"row\", \"col\"] = ...,\\n    squeeze: Literal[True] = ...,\\n    width_ratios: Sequence[float] | None = ...,\\n    height_ratios: Sequence[float] | None = ...,\\n    subplot_kw: dict[str, Any] | None = ...,\\n    gridspec_kw: dict[str, Any] | None = ...,\\n    **fig_kw\\n) -> tuple[Figure, Axes]:\\n    ...\\n\\n\\n@overload\\ndef subplots(\\n    nrows: int = ...,\\n    ncols: int = ...,\\n    *,\\n    sharex: bool | Literal[\"none\", \"all\", \"row\", \"col\"] = ...,\\n    sharey: bool | Literal[\"none\", \"all\", \"row\", \"col\"] = ...,\\n    squeeze: Literal[False],\\n    width_ratios: Sequence[float] | None = ...,\\n    height_ratios: Sequence[float] | None = ...,\\n    subplot_kw: dict[str, Any] | None = ...,\\n    gridspec_kw: dict[str, Any] | None = ...,\\n    **fig_kw\\n) -> tuple[Figure, np.ndarray]:  # TODO numpy/numpy#24738\\n    ...\\n\\n\\n@overload\\ndef subplots(\\n    nrows: int = ...,\\n    ncols: int = ...,\\n    *,\\n    sharex: bool | Literal[\"none\", \"all\", \"row\", \"col\"] = ...,\\n    sharey: bool | Literal[\"none\", \"all\", \"row\", \"col\"] = ...,\\n    squeeze: bool = ...,\\n    width_ratios: Sequence[float] | None = ...,\\n    height_ratios: Sequence[float] | None = ...,\\n    subplot_kw: dict[str, Any] | None = ...,\\n    gridspec_kw: dict[str, Any] | None = ...,\\n    **fig_kw\\n) -> tuple[Figure, Any]:\\n    ...\\n\\n\\ndef subplots(\\n    nrows: int = 1, ncols: int = 1, *,\\n    sharex: bool | Literal[\"none\", \"all\", \"row\", \"col\"] = False,\\n    sharey: bool | Literal[\"none\", \"all\", \"row\", \"col\"] = False,\\n    squeeze: bool = True,\\n    width_ratios: Sequence[float] | None = None,\\n    height_ratios: Sequence[float] | None = None,\\n    subplot_kw: dict[str, Any] | None = None,\\n    gridspec_kw: dict[str, Any] | None = None,\\n    **fig_kw\\n) -> tuple[Figure, Any]:\\n    \"\"\"\\n    Create a figure and a set of subplots.\\n\\n    This utility wrapper makes it convenient to create common layouts of\\n    subplots, including the enclosing figure object, in a single call.\\n\\n    Parameters\\n    ----------\\n    nrows, ncols : int, default: 1\\n        Number of rows/columns of the subplot grid.\\n\\n    sharex, sharey : bool or {\\'none\\', \\'all\\', \\'row\\', \\'col\\'}, default: False\\n        Controls sharing of properties among x (*sharex*) or y (*sharey*)\\n        axes:\\n\\n        - True or \\'all\\': x- or y-axis will be shared among all subplots.\\n        - False or \\'none\\': each subplot x- or y-axis will be independent.\\n        - \\'row\\': each subplot row will share an x- or y-axis.\\n        - \\'col\\': each subplot column will share an x- or y-axis.\\n\\n        When subplots have a shared x-axis along a column, only the x tick\\n        labels of the bottom subplot are created. Similarly, when subplots\\n        have a shared y-axis along a row, only the y tick labels of the first\\n        column subplot are created. To later turn other subplots\\' ticklabels\\n        on, use `~matplotlib.axes.Axes.tick_params`.\\n\\n        When subplots have a shared axis that has units, calling\\n        `.Axis.set_units` will update each axis with the new units.\\n\\n        Note that it is not possible to unshare axes.\\n\\n    squeeze : bool, default: True\\n        - If True, extra dimensions are squeezed out from the returned\\n          array of `~matplotlib.axes.Axes`:\\n\\n          - if only one subplot is constructed (nrows=ncols=1), the\\n            resulting single Axes object is returned as a scalar.\\n          - for Nx1 or 1xM subplots, the returned object is a 1D numpy\\n            object array of Axes objects.\\n          - for NxM, subplots with N>1 and M>1 are returned as a 2D array.\\n\\n        - If False, no squeezing at all is done: the returned Axes object is\\n          always a 2D array containing Axes instances, even if it ends up\\n          being 1x1.\\n\\n    width_ratios : array-like of length *ncols*, optional\\n        Defines the relative widths of the columns. Each column gets a\\n        relative width of ``width_ratios[i] / sum(width_ratios)``.\\n        If not given, all columns will have the same width.  Equivalent\\n        to ``gridspec_kw={\\'width_ratios\\': [...]}``.\\n\\n    height_ratios : array-like of length *nrows*, optional\\n        Defines the relative heights of the rows. Each row gets a\\n        relative height of ``height_ratios[i] / sum(height_ratios)``.\\n        If not given, all rows will have the same height. Convenience\\n        for ``gridspec_kw={\\'height_ratios\\': [...]}``.\\n\\n    subplot_kw : dict, optional\\n        Dict with keywords passed to the\\n        `~matplotlib.figure.Figure.add_subplot` call used to create each\\n        subplot.\\n\\n    gridspec_kw : dict, optional\\n        Dict with keywords passed to the `~matplotlib.gridspec.GridSpec`\\n        constructor used to create the grid the subplots are placed on.\\n\\n    **fig_kw\\n        All additional keyword arguments are passed to the\\n        `.pyplot.figure` call.\\n\\n    Returns\\n    -------\\n    fig : `.Figure`\\n\\n    ax : `~matplotlib.axes.Axes` or array of Axes\\n        *ax* can be either a single `~.axes.Axes` object, or an array of Axes\\n        objects if more than one subplot was created.  The dimensions of the\\n        resulting array can be controlled with the squeeze keyword, see above.\\n\\n        Typical idioms for handling the return value are::\\n\\n            # using the variable ax for single a Axes\\n            fig, ax = plt.subplots()\\n\\n            # using the variable axs for multiple Axes\\n            fig, axs = plt.subplots(2, 2)\\n\\n            # using tuple unpacking for multiple Axes\\n            fig, (ax1, ax2) = plt.subplots(1, 2)\\n            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\\n\\n        The names ``ax`` and pluralized ``axs`` are preferred over ``axes``\\n        because for the latter it\\'s not clear if it refers to a single\\n        `~.axes.Axes` instance or a collection of these.\\n\\n    See Also\\n    --------\\n    .pyplot.figure\\n    .pyplot.subplot\\n    .pyplot.axes\\n    .Figure.subplots\\n    .Figure.add_subplot\\n\\n    Examples\\n    --------\\n    ::\\n\\n        # First create some toy data:\\n        x = np.linspace(0, 2*np.pi, 400)\\n        y = np.sin(x**2)\\n\\n        # Create just a figure and only one subplot\\n        fig, ax = plt.subplots()\\n        ax.plot(x, y)\\n        ax.set_title(\\'Simple plot\\')\\n\\n        # Create two subplots and unpack the output array immediately\\n        f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\\n        ax1.plot(x, y)\\n        ax1.set_title(\\'Sharing Y axis\\')\\n        ax2.scatter(x, y)\\n\\n        # Create four polar Axes and access them through the returned array\\n        fig, axs = plt.subplots(2, 2, subplot_kw=dict(projection=\"polar\"))\\n        axs[0, 0].plot(x, y)\\n        axs[1, 1].scatter(x, y)\\n\\n        # Share a X axis with each column of subplots\\n        plt.subplots(2, 2, sharex=\\'col\\')\\n\\n        # Share a Y axis with each row of subplots\\n        plt.subplots(2, 2, sharey=\\'row\\')\\n\\n        # Share both X and Y axes with all subplots\\n        plt.subplots(2, 2, sharex=\\'all\\', sharey=\\'all\\')\\n\\n        # Note that this is the same as\\n        plt.subplots(2, 2, sharex=True, sharey=True)\\n\\n        # Create figure number 10 with a single subplot\\n        # and clears it if it already exists.\\n        fig, ax = plt.subplots(num=10, clear=True)\\n\\n    \"\"\"\\n    fig = figure(**fig_kw)\\n    axs = fig.subplots(nrows=nrows, ncols=ncols, sharex=sharex, sharey=sharey,\\n                       squeeze=squeeze, subplot_kw=subplot_kw,\\n                       gridspec_kw=gridspec_kw, height_ratios=height_ratios,\\n                       width_ratios=width_ratios)\\n    return fig, axs\\n\\n\\n@overload\\ndef subplot_mosaic(\\n    mosaic: str,\\n    *,\\n    sharex: bool = ...,\\n    sharey: bool = ...,\\n    width_ratios: ArrayLike | None = ...,\\n    height_ratios: ArrayLike | None = ...,\\n    empty_sentinel: str = ...,\\n    subplot_kw: dict[str, Any] | None = ...,\\n    gridspec_kw: dict[str, Any] | None = ...,\\n    per_subplot_kw: dict[str | tuple[str, ...], dict[str, Any]] | None = ...,\\n    **fig_kw: Any\\n) -> tuple[Figure, dict[str, matplotlib.axes.Axes]]: ...\\n\\n\\n@overload\\ndef subplot_mosaic(\\n    mosaic: list[HashableList[_T]],\\n    *,\\n    sharex: bool = ...,\\n    sharey: bool = ...,\\n    width_ratios: ArrayLike | None = ...,\\n    height_ratios: ArrayLike | None = ...,\\n    empty_sentinel: _T = ...,\\n    subplot_kw: dict[str, Any] | None = ...,\\n    gridspec_kw: dict[str, Any] | None = ...,\\n    per_subplot_kw: dict[_T | tuple[_T, ...], dict[str, Any]] | None = ...,\\n    **fig_kw: Any\\n) -> tuple[Figure, dict[_T, matplotlib.axes.Axes]]: ...\\n\\n\\n@overload\\ndef subplot_mosaic(\\n    mosaic: list[HashableList[Hashable]],\\n    *,\\n    sharex: bool = ...,\\n    sharey: bool = ...,\\n    width_ratios: ArrayLike | None = ...,\\n    height_ratios: ArrayLike | None = ...,\\n    empty_sentinel: Any = ...,\\n    subplot_kw: dict[str, Any] | None = ...,\\n    gridspec_kw: dict[str, Any] | None = ...,\\n    per_subplot_kw: dict[Hashable | tuple[Hashable, ...], dict[str, Any]] | None = ...,\\n    **fig_kw: Any\\n) -> tuple[Figure, dict[Hashable, matplotlib.axes.Axes]]: ...\\n\\n\\ndef subplot_mosaic(\\n    mosaic: str | list[HashableList[_T]] | list[HashableList[Hashable]],\\n    *,\\n    sharex: bool = False,\\n    sharey: bool = False,\\n    width_ratios: ArrayLike | None = None,\\n    height_ratios: ArrayLike | None = None,\\n    empty_sentinel: Any = \\'.\\',\\n    subplot_kw: dict[str, Any] | None = None,\\n    gridspec_kw: dict[str, Any] | None = None,\\n    per_subplot_kw: dict[str | tuple[str, ...], dict[str, Any]] |\\n                    dict[_T | tuple[_T, ...], dict[str, Any]] |\\n                    dict[Hashable | tuple[Hashable, ...], dict[str, Any]] | None = None,\\n    **fig_kw: Any\\n) -> tuple[Figure, dict[str, matplotlib.axes.Axes]] | \\\\\\n     tuple[Figure, dict[_T, matplotlib.axes.Axes]] | \\\\\\n     tuple[Figure, dict[Hashable, matplotlib.axes.Axes]]:\\n    \"\"\"\\n    Build a layout of Axes based on ASCII art or nested lists.\\n\\n    This is a helper function to build complex GridSpec layouts visually.\\n\\n    See :ref:`mosaic`\\n    for an example and full API documentation\\n\\n    Parameters\\n    ----------\\n    mosaic : list of list of {hashable or nested} or str\\n\\n        A visual layout of how you want your Axes to be arranged\\n        labeled as strings.  For example ::\\n\\n           x = [[\\'A panel\\', \\'A panel\\', \\'edge\\'],\\n                [\\'C panel\\', \\'.\\',       \\'edge\\']]\\n\\n        produces 4 Axes:\\n\\n        - \\'A panel\\' which is 1 row high and spans the first two columns\\n        - \\'edge\\' which is 2 rows high and is on the right edge\\n        - \\'C panel\\' which in 1 row and 1 column wide in the bottom left\\n        - a blank space 1 row and 1 column wide in the bottom center\\n\\n        Any of the entries in the layout can be a list of lists\\n        of the same form to create nested layouts.\\n\\n        If input is a str, then it must be of the form ::\\n\\n          \\'\\'\\'\\n          AAE\\n          C.E\\n          \\'\\'\\'\\n\\n        where each character is a column and each line is a row.\\n        This only allows only single character Axes labels and does\\n        not allow nesting but is very terse.\\n\\n    sharex, sharey : bool, default: False\\n        If True, the x-axis (*sharex*) or y-axis (*sharey*) will be shared\\n        among all subplots.  In that case, tick label visibility and axis units\\n        behave as for `subplots`.  If False, each subplot\\'s x- or y-axis will\\n        be independent.\\n\\n    width_ratios : array-like of length *ncols*, optional\\n        Defines the relative widths of the columns. Each column gets a\\n        relative width of ``width_ratios[i] / sum(width_ratios)``.\\n        If not given, all columns will have the same width.  Convenience\\n        for ``gridspec_kw={\\'width_ratios\\': [...]}``.\\n\\n    height_ratios : array-like of length *nrows*, optional\\n        Defines the relative heights of the rows. Each row gets a\\n        relative height of ``height_ratios[i] / sum(height_ratios)``.\\n        If not given, all rows will have the same height. Convenience\\n        for ``gridspec_kw={\\'height_ratios\\': [...]}``.\\n\\n    empty_sentinel : object, optional\\n        Entry in the layout to mean \"leave this space empty\".  Defaults\\n        to ``\\'.\\'``. Note, if *layout* is a string, it is processed via\\n        `inspect.cleandoc` to remove leading white space, which may\\n        interfere with using white-space as the empty sentinel.\\n\\n    subplot_kw : dict, optional\\n        Dictionary with keywords passed to the `.Figure.add_subplot` call\\n        used to create each subplot.  These values may be overridden by\\n        values in *per_subplot_kw*.\\n\\n    per_subplot_kw : dict, optional\\n        A dictionary mapping the Axes identifiers or tuples of identifiers\\n        to a dictionary of keyword arguments to be passed to the\\n        `.Figure.add_subplot` call used to create each subplot.  The values\\n        in these dictionaries have precedence over the values in\\n        *subplot_kw*.\\n\\n        If *mosaic* is a string, and thus all keys are single characters,\\n        it is possible to use a single string instead of a tuple as keys;\\n        i.e. ``\"AB\"`` is equivalent to ``(\"A\", \"B\")``.\\n\\n        .. versionadded:: 3.7\\n\\n    gridspec_kw : dict, optional\\n        Dictionary with keywords passed to the `.GridSpec` constructor used\\n        to create the grid the subplots are placed on.\\n\\n    **fig_kw\\n        All additional keyword arguments are passed to the\\n        `.pyplot.figure` call.\\n\\n    Returns\\n    -------\\n    fig : `.Figure`\\n       The new figure\\n\\n    dict[label, Axes]\\n       A dictionary mapping the labels to the Axes objects.  The order of\\n       the Axes is left-to-right and top-to-bottom of their position in the\\n       total layout.\\n\\n    \"\"\"\\n    fig = figure(**fig_kw)\\n    ax_dict = fig.subplot_mosaic(  # type: ignore[misc]\\n        mosaic,  # type: ignore[arg-type]\\n        sharex=sharex, sharey=sharey,\\n        height_ratios=height_ratios, width_ratios=width_ratios,\\n        subplot_kw=subplot_kw, gridspec_kw=gridspec_kw,\\n        empty_sentinel=empty_sentinel,\\n        per_subplot_kw=per_subplot_kw,  # type: ignore[arg-type]\\n    )\\n    return fig, ax_dict\\n\\n\\ndef subplot2grid(\\n    shape: tuple[int, int], loc: tuple[int, int],\\n    rowspan: int = 1, colspan: int = 1,\\n    fig: Figure | None = None,\\n    **kwargs\\n) -> matplotlib.axes.Axes:\\n    \"\"\"\\n    Create a subplot at a specific location inside a regular grid.\\n\\n    Parameters\\n    ----------\\n    shape : (int, int)\\n        Number of rows and of columns of the grid in which to place axis.\\n    loc : (int, int)\\n        Row number and column number of the axis location within the grid.\\n    rowspan : int, default: 1\\n        Number of rows for the axis to span downwards.\\n    colspan : int, default: 1\\n        Number of columns for the axis to span to the right.\\n    fig : `.Figure`, optional\\n        Figure to place the subplot in. Defaults to the current figure.\\n    **kwargs\\n        Additional keyword arguments are handed to `~.Figure.add_subplot`.\\n\\n    Returns\\n    -------\\n    `~.axes.Axes`\\n\\n        The Axes of the subplot. The returned Axes can actually be an instance\\n        of a subclass, such as `.projections.polar.PolarAxes` for polar\\n        projections.\\n\\n    Notes\\n    -----\\n    The following call ::\\n\\n        ax = subplot2grid((nrows, ncols), (row, col), rowspan, colspan)\\n\\n    is identical to ::\\n\\n        fig = gcf()\\n        gs = fig.add_gridspec(nrows, ncols)\\n        ax = fig.add_subplot(gs[row:row+rowspan, col:col+colspan])\\n    \"\"\"\\n    if fig is None:\\n        fig = gcf()\\n    rows, cols = shape\\n    gs = GridSpec._check_gridspec_exists(fig, rows, cols)\\n    subplotspec = gs.new_subplotspec(loc, rowspan=rowspan, colspan=colspan)\\n    return fig.add_subplot(subplotspec, **kwargs)\\n\\n\\ndef twinx(ax: matplotlib.axes.Axes | None = None) -> _AxesBase:\\n    \"\"\"\\n    Make and return a second Axes that shares the *x*-axis.  The new Axes will\\n    overlay *ax* (or the current Axes if *ax* is *None*), and its ticks will be\\n    on the right.\\n\\n    Examples\\n    --------\\n    :doc:`/gallery/subplots_axes_and_figures/two_scales`\\n    \"\"\"\\n    if ax is None:\\n        ax = gca()\\n    ax1 = ax.twinx()\\n    return ax1\\n\\n\\ndef twiny(ax: matplotlib.axes.Axes | None = None) -> _AxesBase:\\n    \"\"\"\\n    Make and return a second Axes that shares the *y*-axis.  The new Axes will\\n    overlay *ax* (or the current Axes if *ax* is *None*), and its ticks will be\\n    on the top.\\n\\n    Examples\\n    --------\\n    :doc:`/gallery/subplots_axes_and_figures/two_scales`\\n    \"\"\"\\n    if ax is None:\\n        ax = gca()\\n    ax1 = ax.twiny()\\n    return ax1\\n\\n\\ndef subplot_tool(targetfig: Figure | None = None) -> SubplotTool | None:\\n    \"\"\"\\n    Launch a subplot tool window for a figure.\\n\\n    Returns\\n    -------\\n    `matplotlib.widgets.SubplotTool`\\n    \"\"\"\\n    if targetfig is None:\\n        targetfig = gcf()\\n    tb = targetfig.canvas.manager.toolbar  # type: ignore[union-attr]\\n    if hasattr(tb, \"configure_subplots\"):  # toolbar2\\n        from matplotlib.backend_bases import NavigationToolbar2\\n        return cast(NavigationToolbar2, tb).configure_subplots()\\n    elif hasattr(tb, \"trigger_tool\"):  # toolmanager\\n        from matplotlib.backend_bases import ToolContainerBase\\n        cast(ToolContainerBase, tb).trigger_tool(\"subplots\")\\n        return None\\n    else:\\n        raise ValueError(\"subplot_tool can only be launched for figures with \"\\n                         \"an associated toolbar\")\\n\\n\\ndef box(on: bool | None = None) -> None:\\n    \"\"\"\\n    Turn the Axes box on or off on the current Axes.\\n\\n    Parameters\\n    ----------\\n    on : bool or None\\n        The new `~matplotlib.axes.Axes` box state. If ``None``, toggle\\n        the state.\\n\\n    See Also\\n    --------\\n    :meth:`matplotlib.axes.Axes.set_frame_on`\\n    :meth:`matplotlib.axes.Axes.get_frame_on`\\n    \"\"\"\\n    ax = gca()\\n    if on is None:\\n        on = not ax.get_frame_on()\\n    ax.set_frame_on(on)\\n\\n## Axis ##\\n\\n\\ndef xlim(*args, **kwargs) -> tuple[float, float]:\\n    \"\"\"\\n    Get or set the x limits of the current Axes.\\n\\n    Call signatures::\\n\\n        left, right = xlim()  # return the current xlim\\n        xlim((left, right))   # set the xlim to left, right\\n        xlim(left, right)     # set the xlim to left, right\\n\\n    If you do not specify args, you can pass *left* or *right* as kwargs,\\n    i.e.::\\n\\n        xlim(right=3)  # adjust the right leaving left unchanged\\n        xlim(left=1)  # adjust the left leaving right unchanged\\n\\n    Setting limits turns autoscaling off for the x-axis.\\n\\n    Returns\\n    -------\\n    left, right\\n        A tuple of the new x-axis limits.\\n\\n    Notes\\n    -----\\n    Calling this function with no arguments (e.g. ``xlim()``) is the pyplot\\n    equivalent of calling `~.Axes.get_xlim` on the current Axes.\\n    Calling this function with arguments is the pyplot equivalent of calling\\n    `~.Axes.set_xlim` on the current Axes. All arguments are passed though.\\n    \"\"\"\\n    ax = gca()\\n    if not args and not kwargs:\\n        return ax.get_xlim()\\n    ret = ax.set_xlim(*args, **kwargs)\\n    return ret\\n\\n\\ndef ylim(*args, **kwargs) -> tuple[float, float]:\\n    \"\"\"\\n    Get or set the y-limits of the current Axes.\\n\\n    Call signatures::\\n\\n        bottom, top = ylim()  # return the current ylim\\n        ylim((bottom, top))   # set the ylim to bottom, top\\n        ylim(bottom, top)     # set the ylim to bottom, top\\n\\n    If you do not specify args, you can alternatively pass *bottom* or\\n    *top* as kwargs, i.e.::\\n\\n        ylim(top=3)  # adjust the top leaving bottom unchanged\\n        ylim(bottom=1)  # adjust the bottom leaving top unchanged\\n\\n    Setting limits turns autoscaling off for the y-axis.\\n\\n    Returns\\n    -------\\n    bottom, top\\n        A tuple of the new y-axis limits.\\n\\n    Notes\\n    -----\\n    Calling this function with no arguments (e.g. ``ylim()``) is the pyplot\\n    equivalent of calling `~.Axes.get_ylim` on the current Axes.\\n    Calling this function with arguments is the pyplot equivalent of calling\\n    `~.Axes.set_ylim` on the current Axes. All arguments are passed though.\\n    \"\"\"\\n    ax = gca()\\n    if not args and not kwargs:\\n        return ax.get_ylim()\\n    ret = ax.set_ylim(*args, **kwargs)\\n    return ret\\n\\n\\ndef xticks(\\n    ticks: ArrayLike | None = None,\\n    labels: Sequence[str] | None = None,\\n    *,\\n    minor: bool = False,\\n    **kwargs\\n) -> tuple[list[Tick] | np.ndarray, list[Text]]:\\n    \"\"\"\\n    Get or set the current tick locations and labels of the x-axis.\\n\\n    Pass no arguments to return the current values without modifying them.\\n\\n    Parameters\\n    ----------\\n    ticks : array-like, optional\\n        The list of xtick locations.  Passing an empty list removes all xticks.\\n    labels : array-like, optional\\n        The labels to place at the given *ticks* locations.  This argument can\\n        only be passed if *ticks* is passed as well.\\n    minor : bool, default: False\\n        If ``False``, get/set the major ticks/labels; if ``True``, the minor\\n        ticks/labels.\\n    **kwargs\\n        `.Text` properties can be used to control the appearance of the labels.\\n\\n        .. warning::\\n\\n            This only sets the properties of the current ticks, which is\\n            only sufficient if you either pass *ticks*, resulting in a\\n            fixed list of ticks, or if the plot is static.\\n\\n            Ticks are not guaranteed to be persistent. Various operations\\n            can create, delete and modify the Tick instances. There is an\\n            imminent risk that these settings can get lost if you work on\\n            the figure further (including also panning/zooming on a\\n            displayed figure).\\n\\n            Use `~.pyplot.tick_params` instead if possible.\\n\\n\\n    Returns\\n    -------\\n    locs\\n        The list of xtick locations.\\n    labels\\n        The list of xlabel `.Text` objects.\\n\\n    Notes\\n    -----\\n    Calling this function with no arguments (e.g. ``xticks()``) is the pyplot\\n    equivalent of calling `~.Axes.get_xticks` and `~.Axes.get_xticklabels` on\\n    the current Axes.\\n    Calling this function with arguments is the pyplot equivalent of calling\\n    `~.Axes.set_xticks` and `~.Axes.set_xticklabels` on the current Axes.\\n\\n    Examples\\n    --------\\n    >>> locs, labels = xticks()  # Get the current locations and labels.\\n    >>> xticks(np.arange(0, 1, step=0.2))  # Set label locations.\\n    >>> xticks(np.arange(3), [\\'Tom\\', \\'Dick\\', \\'Sue\\'])  # Set text labels.\\n    >>> xticks([0, 1, 2], [\\'January\\', \\'February\\', \\'March\\'],\\n    ...        rotation=20)  # Set text labels and properties.\\n    >>> xticks([])  # Disable xticks.\\n    \"\"\"\\n    ax = gca()\\n\\n    locs: list[Tick] | np.ndarray\\n    if ticks is None:\\n        locs = ax.get_xticks(minor=minor)\\n        if labels is not None:\\n            raise TypeError(\"xticks(): Parameter \\'labels\\' can\\'t be set \"\\n                            \"without setting \\'ticks\\'\")\\n    else:\\n        locs = ax.set_xticks(ticks, minor=minor)\\n\\n    labels_out: list[Text] = []\\n    if labels is None:\\n        labels_out = ax.get_xticklabels(minor=minor)\\n        for l in labels_out:\\n            l._internal_update(kwargs)\\n    else:\\n        labels_out = ax.set_xticklabels(labels, minor=minor, **kwargs)\\n\\n    return locs, labels_out\\n\\n\\ndef yticks(\\n    ticks: ArrayLike | None = None,\\n    labels: Sequence[str] | None = None,\\n    *,\\n    minor: bool = False,\\n    **kwargs\\n) -> tuple[list[Tick] | np.ndarray, list[Text]]:\\n    \"\"\"\\n    Get or set the current tick locations and labels of the y-axis.\\n\\n    Pass no arguments to return the current values without modifying them.\\n\\n    Parameters\\n    ----------\\n    ticks : array-like, optional\\n        The list of ytick locations.  Passing an empty list removes all yticks.\\n    labels : array-like, optional\\n        The labels to place at the given *ticks* locations.  This argument can\\n        only be passed if *ticks* is passed as well.\\n    minor : bool, default: False\\n        If ``False``, get/set the major ticks/labels; if ``True``, the minor\\n        ticks/labels.\\n    **kwargs\\n        `.Text` properties can be used to control the appearance of the labels.\\n\\n        .. warning::\\n\\n            This only sets the properties of the current ticks, which is\\n            only sufficient if you either pass *ticks*, resulting in a\\n            fixed list of ticks, or if the plot is static.\\n\\n            Ticks are not guaranteed to be persistent. Various operations\\n            can create, delete and modify the Tick instances. There is an\\n            imminent risk that these settings can get lost if you work on\\n            the figure further (including also panning/zooming on a\\n            displayed figure).\\n\\n            Use `~.pyplot.tick_params` instead if possible.\\n\\n    Returns\\n    -------\\n    locs\\n        The list of ytick locations.\\n    labels\\n        The list of ylabel `.Text` objects.\\n\\n    Notes\\n    -----\\n    Calling this function with no arguments (e.g. ``yticks()``) is the pyplot\\n    equivalent of calling `~.Axes.get_yticks` and `~.Axes.get_yticklabels` on\\n    the current Axes.\\n    Calling this function with arguments is the pyplot equivalent of calling\\n    `~.Axes.set_yticks` and `~.Axes.set_yticklabels` on the current Axes.\\n\\n    Examples\\n    --------\\n    >>> locs, labels = yticks()  # Get the current locations and labels.\\n    >>> yticks(np.arange(0, 1, step=0.2))  # Set label locations.\\n    >>> yticks(np.arange(3), [\\'Tom\\', \\'Dick\\', \\'Sue\\'])  # Set text labels.\\n    >>> yticks([0, 1, 2], [\\'January\\', \\'February\\', \\'March\\'],\\n    ...        rotation=45)  # Set text labels and properties.\\n    >>> yticks([])  # Disable yticks.\\n    \"\"\"\\n    ax = gca()\\n\\n    locs: list[Tick] | np.ndarray\\n    if ticks is None:\\n        locs = ax.get_yticks(minor=minor)\\n        if labels is not None:\\n            raise TypeError(\"yticks(): Parameter \\'labels\\' can\\'t be set \"\\n                            \"without setting \\'ticks\\'\")\\n    else:\\n        locs = ax.set_yticks(ticks, minor=minor)\\n\\n    labels_out: list[Text] = []\\n    if labels is None:\\n        labels_out = ax.get_yticklabels(minor=minor)\\n        for l in labels_out:\\n            l._internal_update(kwargs)\\n    else:\\n        labels_out = ax.set_yticklabels(labels, minor=minor, **kwargs)\\n\\n    return locs, labels_out\\n\\n\\ndef rgrids(\\n    radii: ArrayLike | None = None,\\n    labels: Sequence[str | Text] | None = None,\\n    angle: float | None = None,\\n    fmt: str | None = None,\\n    **kwargs\\n) -> tuple[list[Line2D], list[Text]]:\\n    \"\"\"\\n    Get or set the radial gridlines on the current polar plot.\\n\\n    Call signatures::\\n\\n     lines, labels = rgrids()\\n     lines, labels = rgrids(radii, labels=None, angle=22.5, fmt=None, **kwargs)\\n\\n    When called with no arguments, `.rgrids` simply returns the tuple\\n    (*lines*, *labels*). When called with arguments, the labels will\\n    appear at the specified radial distances and angle.\\n\\n    Parameters\\n    ----------\\n    radii : tuple with floats\\n        The radii for the radial gridlines\\n\\n    labels : tuple with strings or None\\n        The labels to use at each radial gridline. The\\n        `matplotlib.ticker.ScalarFormatter` will be used if None.\\n\\n    angle : float\\n        The angular position of the radius labels in degrees.\\n\\n    fmt : str or None\\n        Format string used in `matplotlib.ticker.FormatStrFormatter`.\\n        For example \\'%f\\'.\\n\\n    Returns\\n    -------\\n    lines : list of `.lines.Line2D`\\n        The radial gridlines.\\n\\n    labels : list of `.text.Text`\\n        The tick labels.\\n\\n    Other Parameters\\n    ----------------\\n    **kwargs\\n        *kwargs* are optional `.Text` properties for the labels.\\n\\n    See Also\\n    --------\\n    .pyplot.thetagrids\\n    .projections.polar.PolarAxes.set_rgrids\\n    .Axis.get_gridlines\\n    .Axis.get_ticklabels\\n\\n    Examples\\n    --------\\n    ::\\n\\n      # set the locations of the radial gridlines\\n      lines, labels = rgrids( (0.25, 0.5, 1.0) )\\n\\n      # set the locations and labels of the radial gridlines\\n      lines, labels = rgrids( (0.25, 0.5, 1.0), (\\'Tom\\', \\'Dick\\', \\'Harry\\' ))\\n    \"\"\"\\n    ax = gca()\\n    if not isinstance(ax, PolarAxes):\\n        raise RuntimeError(\\'rgrids only defined for polar Axes\\')\\n    if all(p is None for p in [radii, labels, angle, fmt]) and not kwargs:\\n        lines_out: list[Line2D] = ax.yaxis.get_gridlines()\\n        labels_out: list[Text] = ax.yaxis.get_ticklabels()\\n    elif radii is None:\\n        raise TypeError(\"\\'radii\\' cannot be None when other parameters are passed\")\\n    else:\\n        lines_out, labels_out = ax.set_rgrids(\\n            radii, labels=labels, angle=angle, fmt=fmt, **kwargs)\\n    return lines_out, labels_out\\n\\n\\ndef thetagrids(\\n    angles: ArrayLike | None = None,\\n    labels: Sequence[str | Text] | None = None,\\n    fmt: str | None = None,\\n    **kwargs\\n) -> tuple[list[Line2D], list[Text]]:\\n    \"\"\"\\n    Get or set the theta gridlines on the current polar plot.\\n\\n    Call signatures::\\n\\n     lines, labels = thetagrids()\\n     lines, labels = thetagrids(angles, labels=None, fmt=None, **kwargs)\\n\\n    When called with no arguments, `.thetagrids` simply returns the tuple\\n    (*lines*, *labels*). When called with arguments, the labels will\\n    appear at the specified angles.\\n\\n    Parameters\\n    ----------\\n    angles : tuple with floats, degrees\\n        The angles of the theta gridlines.\\n\\n    labels : tuple with strings or None\\n        The labels to use at each radial gridline. The\\n        `.projections.polar.ThetaFormatter` will be used if None.\\n\\n    fmt : str or None\\n        Format string used in `matplotlib.ticker.FormatStrFormatter`.\\n        For example \\'%f\\'. Note that the angle in radians will be used.\\n\\n    Returns\\n    -------\\n    lines : list of `.lines.Line2D`\\n        The theta gridlines.\\n\\n    labels : list of `.text.Text`\\n        The tick labels.\\n\\n    Other Parameters\\n    ----------------\\n    **kwargs\\n        *kwargs* are optional `.Text` properties for the labels.\\n\\n    See Also\\n    --------\\n    .pyplot.rgrids\\n    .projections.polar.PolarAxes.set_thetagrids\\n    .Axis.get_gridlines\\n    .Axis.get_ticklabels\\n\\n    Examples\\n    --------\\n    ::\\n\\n      # set the locations of the angular gridlines\\n      lines, labels = thetagrids(range(45, 360, 90))\\n\\n      # set the locations and labels of the angular gridlines\\n      lines, labels = thetagrids(range(45, 360, 90), (\\'NE\\', \\'NW\\', \\'SW\\', \\'SE\\'))\\n    \"\"\"\\n    ax = gca()\\n    if not isinstance(ax, PolarAxes):\\n        raise RuntimeError(\\'thetagrids only defined for polar Axes\\')\\n    if all(param is None for param in [angles, labels, fmt]) and not kwargs:\\n        lines_out: list[Line2D] = ax.xaxis.get_ticklines()\\n        labels_out: list[Text] = ax.xaxis.get_ticklabels()\\n    elif angles is None:\\n        raise TypeError(\"\\'angles\\' cannot be None when other parameters are passed\")\\n    else:\\n        lines_out, labels_out = ax.set_thetagrids(angles,\\n                                                  labels=labels, fmt=fmt,\\n                                                  **kwargs)\\n    return lines_out, labels_out\\n\\n\\n@_api.deprecated(\"3.7\", pending=True)\\ndef get_plot_commands() -> list[str]:\\n    \"\"\"\\n    Get a sorted list of all of the plotting commands.\\n    \"\"\"\\n    NON_PLOT_COMMANDS = {\\n        \\'connect\\', \\'disconnect\\', \\'get_current_fig_manager\\', \\'ginput\\',\\n        \\'new_figure_manager\\', \\'waitforbuttonpress\\'}\\n    return [name for name in _get_pyplot_commands()\\n            if name not in NON_PLOT_COMMANDS]\\n\\n\\ndef _get_pyplot_commands() -> list[str]:\\n    # This works by searching for all functions in this module and removing\\n    # a few hard-coded exclusions, as well as all of the colormap-setting\\n    # functions, and anything marked as private with a preceding underscore.\\n    exclude = {\\'colormaps\\', \\'colors\\', \\'get_plot_commands\\', *colormaps}\\n    this_module = inspect.getmodule(get_plot_commands)\\n    return sorted(\\n        name for name, obj in globals().items()\\n        if not name.startswith(\\'_\\') and name not in exclude\\n           and inspect.isfunction(obj)\\n           and inspect.getmodule(obj) is this_module)\\n\\n\\n## Plotting part 1: manually generated functions and wrappers ##\\n\\n\\n@_copy_docstring_and_deprecators(Figure.colorbar)\\ndef colorbar(\\n    mappable: ScalarMappable | ColorizingArtist | None = None,\\n    cax: matplotlib.axes.Axes | None = None,\\n    ax: matplotlib.axes.Axes | Iterable[matplotlib.axes.Axes] | None = None,\\n    **kwargs\\n) -> Colorbar:\\n    if mappable is None:\\n        mappable = gci()\\n        if mappable is None:\\n            raise RuntimeError(\\'No mappable was found to use for colorbar \\'\\n                               \\'creation. First define a mappable such as \\'\\n                               \\'an image (with imshow) or a contour set (\\'\\n                               \\'with contourf).\\')\\n    ret = gcf().colorbar(mappable, cax=cax, ax=ax, **kwargs)\\n    return ret\\n\\n\\ndef clim(vmin: float | None = None, vmax: float | None = None) -> None:\\n    \"\"\"\\n    Set the color limits of the current image.\\n\\n    If either *vmin* or *vmax* is None, the image min/max respectively\\n    will be used for color scaling.\\n\\n    If you want to set the clim of multiple images, use\\n    `~.ScalarMappable.set_clim` on every image, for example::\\n\\n      for im in gca().get_images():\\n          im.set_clim(0, 0.5)\\n\\n    \"\"\"\\n    im = gci()\\n    if im is None:\\n        raise RuntimeError(\\'You must first define an image, e.g., with imshow\\')\\n\\n    im.set_clim(vmin, vmax)\\n\\n\\ndef get_cmap(name: Colormap | str | None = None, lut: int | None = None) -> Colormap:\\n    \"\"\"\\n    Get a colormap instance, defaulting to rc values if *name* is None.\\n\\n    Parameters\\n    ----------\\n    name : `~matplotlib.colors.Colormap` or str or None, default: None\\n        If a `.Colormap` instance, it will be returned. Otherwise, the name of\\n        a colormap known to Matplotlib, which will be resampled by *lut*. The\\n        default, None, means :rc:`image.cmap`.\\n    lut : int or None, default: None\\n        If *name* is not already a Colormap instance and *lut* is not None, the\\n        colormap will be resampled to have *lut* entries in the lookup table.\\n\\n    Returns\\n    -------\\n    Colormap\\n    \"\"\"\\n    if name is None:\\n        name = rcParams[\\'image.cmap\\']\\n    if isinstance(name, Colormap):\\n        return name\\n    _api.check_in_list(sorted(_colormaps), name=name)\\n    if lut is None:\\n        return _colormaps[name]\\n    else:\\n        return _colormaps[name].resampled(lut)\\n\\n\\ndef set_cmap(cmap: Colormap | str) -> None:\\n    \"\"\"\\n    Set the default colormap, and applies it to the current image if any.\\n\\n    Parameters\\n    ----------\\n    cmap : `~matplotlib.colors.Colormap` or str\\n        A colormap instance or the name of a registered colormap.\\n\\n    See Also\\n    --------\\n    colormaps\\n    get_cmap\\n    \"\"\"\\n    cmap = get_cmap(cmap)\\n\\n    rc(\\'image\\', cmap=cmap.name)\\n    im = gci()\\n\\n    if im is not None:\\n        im.set_cmap(cmap)\\n\\n\\n@_copy_docstring_and_deprecators(matplotlib.image.imread)\\ndef imread(\\n        fname: str | pathlib.Path | BinaryIO, format: str | None = None\\n) -> np.ndarray:\\n    return matplotlib.image.imread(fname, format)\\n\\n\\n@_copy_docstring_and_deprecators(matplotlib.image.imsave)\\ndef imsave(\\n    fname: str | os.PathLike | BinaryIO, arr: ArrayLike, **kwargs\\n) -> None:\\n    matplotlib.image.imsave(fname, arr, **kwargs)\\n\\n\\ndef matshow(A: ArrayLike, fignum: None | int = None, **kwargs) -> AxesImage:\\n    \"\"\"\\n    Display a 2D array as a matrix in a new figure window.\\n\\n    The origin is set at the upper left hand corner.\\n    The indexing is ``(row, column)`` so that the first index runs vertically\\n    and the second index runs horizontally in the figure:\\n\\n    .. code-block:: none\\n\\n        A[0, 0]   ⋯ A[0, M-1]\\n           ⋮             ⋮\\n        A[N-1, 0] ⋯ A[N-1, M-1]\\n\\n    The aspect ratio of the figure window is that of the array,\\n    unless this would make an excessively short or narrow figure.\\n\\n    Tick labels for the xaxis are placed on top.\\n\\n    Parameters\\n    ----------\\n    A : 2D array-like\\n        The matrix to be displayed.\\n\\n    fignum : None or int\\n        If *None*, create a new, appropriately sized figure window.\\n\\n        If 0, use the current Axes (creating one if there is none, without ever\\n        adjusting the figure size).\\n\\n        Otherwise, create a new Axes on the figure with the given number\\n        (creating it at the appropriate size if it does not exist, but not\\n        adjusting the figure size otherwise).  Note that this will be drawn on\\n        top of any preexisting Axes on the figure.\\n\\n    Returns\\n    -------\\n    `~matplotlib.image.AxesImage`\\n\\n    Other Parameters\\n    ----------------\\n    **kwargs : `~matplotlib.axes.Axes.imshow` arguments\\n\\n    \"\"\"\\n    A = np.asanyarray(A)\\n    if fignum == 0:\\n        ax = gca()\\n    else:\\n        # Extract actual aspect ratio of array and make appropriately sized\\n        # figure.\\n        fig = figure(fignum, figsize=figaspect(A))\\n        ax = fig.add_axes((0.15, 0.09, 0.775, 0.775))\\n    im = ax.matshow(A, **kwargs)\\n    sci(im)\\n    return im\\n\\n\\ndef polar(*args, **kwargs) -> list[Line2D]:\\n    \"\"\"\\n    Make a polar plot.\\n\\n    call signature::\\n\\n      polar(theta, r, [fmt], **kwargs)\\n\\n    This is a convenience wrapper around `.pyplot.plot`. It ensures that the\\n    current Axes is polar (or creates one if needed) and then passes all parameters\\n    to ``.pyplot.plot``.\\n\\n    .. note::\\n        When making polar plots using the :ref:`pyplot API <pyplot_interface>`,\\n        ``polar()`` should typically be the first command because that makes sure\\n        a polar Axes is created. Using other commands such as ``plt.title()``\\n        before this can lead to the implicit creation of a rectangular Axes, in which\\n        case a subsequent ``polar()`` call will fail.\\n    \"\"\"\\n    # If an axis already exists, check if it has a polar projection\\n    if gcf().get_axes():\\n        ax = gca()\\n        if not isinstance(ax, PolarAxes):\\n            _api.warn_deprecated(\\n                \"3.10\",\\n                message=\"There exists a non-polar current Axes. Therefore, the \"\\n                        \"resulting plot from \\'polar()\\' is non-polar. You likely \"\\n                        \"should call \\'polar()\\' before any other pyplot plotting \"\\n                        \"commands. \"\\n                        \"Support for this scenario is deprecated in %(since)s and \"\\n                        \"will raise an error in %(removal)s\"\\n            )\\n    else:\\n        ax = axes(projection=\"polar\")\\n    return ax.plot(*args, **kwargs)\\n\\n\\n# If rcParams[\\'backend_fallback\\'] is true, and an interactive backend is\\n# requested, ignore rcParams[\\'backend\\'] and force selection of a backend that\\n# is compatible with the current running interactive framework.\\nif (rcParams[\"backend_fallback\"]\\n        and rcParams._get_backend_or_none() in (  # type: ignore[attr-defined]\\n            set(backend_registry.list_builtin(BackendFilter.INTERACTIVE)) -\\n            {\\'webagg\\', \\'nbagg\\'})\\n        and cbook._get_running_interactive_framework()):\\n    rcParams._set(\"backend\", rcsetup._auto_backend_sentinel)\\n\\n# fmt: on\\n\\n################# REMAINING CONTENT GENERATED BY boilerplate.py ##############\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Figure.figimage)\\ndef figimage(\\n    X: ArrayLike,\\n    xo: int = 0,\\n    yo: int = 0,\\n    alpha: float | None = None,\\n    norm: str | Normalize | None = None,\\n    cmap: str | Colormap | None = None,\\n    vmin: float | None = None,\\n    vmax: float | None = None,\\n    origin: Literal[\"upper\", \"lower\"] | None = None,\\n    resize: bool = False,\\n    *,\\n    colorizer: Colorizer | None = None,\\n    **kwargs,\\n) -> FigureImage:\\n    return gcf().figimage(\\n        X,\\n        xo=xo,\\n        yo=yo,\\n        alpha=alpha,\\n        norm=norm,\\n        cmap=cmap,\\n        vmin=vmin,\\n        vmax=vmax,\\n        origin=origin,\\n        resize=resize,\\n        colorizer=colorizer,\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Figure.text)\\ndef figtext(\\n    x: float, y: float, s: str, fontdict: dict[str, Any] | None = None, **kwargs\\n) -> Text:\\n    return gcf().text(x, y, s, fontdict=fontdict, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Figure.gca)\\ndef gca() -> Axes:\\n    return gcf().gca()\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Figure._gci)\\ndef gci() -> ColorizingArtist | None:\\n    return gcf()._gci()\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Figure.ginput)\\ndef ginput(\\n    n: int = 1,\\n    timeout: float = 30,\\n    show_clicks: bool = True,\\n    mouse_add: MouseButton = MouseButton.LEFT,\\n    mouse_pop: MouseButton = MouseButton.RIGHT,\\n    mouse_stop: MouseButton = MouseButton.MIDDLE,\\n) -> list[tuple[int, int]]:\\n    return gcf().ginput(\\n        n=n,\\n        timeout=timeout,\\n        show_clicks=show_clicks,\\n        mouse_add=mouse_add,\\n        mouse_pop=mouse_pop,\\n        mouse_stop=mouse_stop,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Figure.subplots_adjust)\\ndef subplots_adjust(\\n    left: float | None = None,\\n    bottom: float | None = None,\\n    right: float | None = None,\\n    top: float | None = None,\\n    wspace: float | None = None,\\n    hspace: float | None = None,\\n) -> None:\\n    gcf().subplots_adjust(\\n        left=left, bottom=bottom, right=right, top=top, wspace=wspace, hspace=hspace\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Figure.suptitle)\\ndef suptitle(t: str, **kwargs) -> Text:\\n    return gcf().suptitle(t, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Figure.tight_layout)\\ndef tight_layout(\\n    *,\\n    pad: float = 1.08,\\n    h_pad: float | None = None,\\n    w_pad: float | None = None,\\n    rect: tuple[float, float, float, float] | None = None,\\n) -> None:\\n    gcf().tight_layout(pad=pad, h_pad=h_pad, w_pad=w_pad, rect=rect)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Figure.waitforbuttonpress)\\ndef waitforbuttonpress(timeout: float = -1) -> None | bool:\\n    return gcf().waitforbuttonpress(timeout=timeout)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.acorr)\\ndef acorr(\\n    x: ArrayLike, *, data=None, **kwargs\\n) -> tuple[np.ndarray, np.ndarray, LineCollection | Line2D, Line2D | None]:\\n    return gca().acorr(x, **({\"data\": data} if data is not None else {}), **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.angle_spectrum)\\ndef angle_spectrum(\\n    x: ArrayLike,\\n    Fs: float | None = None,\\n    Fc: int | None = None,\\n    window: Callable[[ArrayLike], ArrayLike] | ArrayLike | None = None,\\n    pad_to: int | None = None,\\n    sides: Literal[\"default\", \"onesided\", \"twosided\"] | None = None,\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> tuple[np.ndarray, np.ndarray, Line2D]:\\n    return gca().angle_spectrum(\\n        x,\\n        Fs=Fs,\\n        Fc=Fc,\\n        window=window,\\n        pad_to=pad_to,\\n        sides=sides,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.annotate)\\ndef annotate(\\n    text: str,\\n    xy: tuple[float, float],\\n    xytext: tuple[float, float] | None = None,\\n    xycoords: CoordsType = \"data\",\\n    textcoords: CoordsType | None = None,\\n    arrowprops: dict[str, Any] | None = None,\\n    annotation_clip: bool | None = None,\\n    **kwargs,\\n) -> Annotation:\\n    return gca().annotate(\\n        text,\\n        xy,\\n        xytext=xytext,\\n        xycoords=xycoords,\\n        textcoords=textcoords,\\n        arrowprops=arrowprops,\\n        annotation_clip=annotation_clip,\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.arrow)\\ndef arrow(x: float, y: float, dx: float, dy: float, **kwargs) -> FancyArrow:\\n    return gca().arrow(x, y, dx, dy, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.autoscale)\\ndef autoscale(\\n    enable: bool = True,\\n    axis: Literal[\"both\", \"x\", \"y\"] = \"both\",\\n    tight: bool | None = None,\\n) -> None:\\n    gca().autoscale(enable=enable, axis=axis, tight=tight)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.axhline)\\ndef axhline(y: float = 0, xmin: float = 0, xmax: float = 1, **kwargs) -> Line2D:\\n    return gca().axhline(y=y, xmin=xmin, xmax=xmax, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.axhspan)\\ndef axhspan(\\n    ymin: float, ymax: float, xmin: float = 0, xmax: float = 1, **kwargs\\n) -> Rectangle:\\n    return gca().axhspan(ymin, ymax, xmin=xmin, xmax=xmax, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.axis)\\ndef axis(\\n    arg: tuple[float, float, float, float] | bool | str | None = None,\\n    /,\\n    *,\\n    emit: bool = True,\\n    **kwargs,\\n) -> tuple[float, float, float, float]:\\n    return gca().axis(arg, emit=emit, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.axline)\\ndef axline(\\n    xy1: tuple[float, float],\\n    xy2: tuple[float, float] | None = None,\\n    *,\\n    slope: float | None = None,\\n    **kwargs,\\n) -> AxLine:\\n    return gca().axline(xy1, xy2=xy2, slope=slope, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.axvline)\\ndef axvline(x: float = 0, ymin: float = 0, ymax: float = 1, **kwargs) -> Line2D:\\n    return gca().axvline(x=x, ymin=ymin, ymax=ymax, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.axvspan)\\ndef axvspan(\\n    xmin: float, xmax: float, ymin: float = 0, ymax: float = 1, **kwargs\\n) -> Rectangle:\\n    return gca().axvspan(xmin, xmax, ymin=ymin, ymax=ymax, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.bar)\\ndef bar(\\n    x: float | ArrayLike,\\n    height: float | ArrayLike,\\n    width: float | ArrayLike = 0.8,\\n    bottom: float | ArrayLike | None = None,\\n    *,\\n    align: Literal[\"center\", \"edge\"] = \"center\",\\n    data=None,\\n    **kwargs,\\n) -> BarContainer:\\n    return gca().bar(\\n        x,\\n        height,\\n        width=width,\\n        bottom=bottom,\\n        align=align,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.barbs)\\ndef barbs(*args, data=None, **kwargs) -> Barbs:\\n    return gca().barbs(*args, **({\"data\": data} if data is not None else {}), **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.barh)\\ndef barh(\\n    y: float | ArrayLike,\\n    width: float | ArrayLike,\\n    height: float | ArrayLike = 0.8,\\n    left: float | ArrayLike | None = None,\\n    *,\\n    align: Literal[\"center\", \"edge\"] = \"center\",\\n    data=None,\\n    **kwargs,\\n) -> BarContainer:\\n    return gca().barh(\\n        y,\\n        width,\\n        height=height,\\n        left=left,\\n        align=align,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.bar_label)\\ndef bar_label(\\n    container: BarContainer,\\n    labels: ArrayLike | None = None,\\n    *,\\n    fmt: str | Callable[[float], str] = \"%g\",\\n    label_type: Literal[\"center\", \"edge\"] = \"edge\",\\n    padding: float = 0,\\n    **kwargs,\\n) -> list[Annotation]:\\n    return gca().bar_label(\\n        container,\\n        labels=labels,\\n        fmt=fmt,\\n        label_type=label_type,\\n        padding=padding,\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.boxplot)\\ndef boxplot(\\n    x: ArrayLike | Sequence[ArrayLike],\\n    notch: bool | None = None,\\n    sym: str | None = None,\\n    vert: bool | None = None,\\n    orientation: Literal[\"vertical\", \"horizontal\"] = \"vertical\",\\n    whis: float | tuple[float, float] | None = None,\\n    positions: ArrayLike | None = None,\\n    widths: float | ArrayLike | None = None,\\n    patch_artist: bool | None = None,\\n    bootstrap: int | None = None,\\n    usermedians: ArrayLike | None = None,\\n    conf_intervals: ArrayLike | None = None,\\n    meanline: bool | None = None,\\n    showmeans: bool | None = None,\\n    showcaps: bool | None = None,\\n    showbox: bool | None = None,\\n    showfliers: bool | None = None,\\n    boxprops: dict[str, Any] | None = None,\\n    tick_labels: Sequence[str] | None = None,\\n    flierprops: dict[str, Any] | None = None,\\n    medianprops: dict[str, Any] | None = None,\\n    meanprops: dict[str, Any] | None = None,\\n    capprops: dict[str, Any] | None = None,\\n    whiskerprops: dict[str, Any] | None = None,\\n    manage_ticks: bool = True,\\n    autorange: bool = False,\\n    zorder: float | None = None,\\n    capwidths: float | ArrayLike | None = None,\\n    label: Sequence[str] | None = None,\\n    *,\\n    data=None,\\n) -> dict[str, Any]:\\n    return gca().boxplot(\\n        x,\\n        notch=notch,\\n        sym=sym,\\n        vert=vert,\\n        orientation=orientation,\\n        whis=whis,\\n        positions=positions,\\n        widths=widths,\\n        patch_artist=patch_artist,\\n        bootstrap=bootstrap,\\n        usermedians=usermedians,\\n        conf_intervals=conf_intervals,\\n        meanline=meanline,\\n        showmeans=showmeans,\\n        showcaps=showcaps,\\n        showbox=showbox,\\n        showfliers=showfliers,\\n        boxprops=boxprops,\\n        tick_labels=tick_labels,\\n        flierprops=flierprops,\\n        medianprops=medianprops,\\n        meanprops=meanprops,\\n        capprops=capprops,\\n        whiskerprops=whiskerprops,\\n        manage_ticks=manage_ticks,\\n        autorange=autorange,\\n        zorder=zorder,\\n        capwidths=capwidths,\\n        label=label,\\n        **({\"data\": data} if data is not None else {}),\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.broken_barh)\\ndef broken_barh(\\n    xranges: Sequence[tuple[float, float]],\\n    yrange: tuple[float, float],\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> PolyCollection:\\n    return gca().broken_barh(\\n        xranges, yrange, **({\"data\": data} if data is not None else {}), **kwargs\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.clabel)\\ndef clabel(CS: ContourSet, levels: ArrayLike | None = None, **kwargs) -> list[Text]:\\n    return gca().clabel(CS, levels=levels, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.cohere)\\ndef cohere(\\n    x: ArrayLike,\\n    y: ArrayLike,\\n    NFFT: int = 256,\\n    Fs: float = 2,\\n    Fc: int = 0,\\n    detrend: Literal[\"none\", \"mean\", \"linear\"]\\n    | Callable[[ArrayLike], ArrayLike] = mlab.detrend_none,\\n    window: Callable[[ArrayLike], ArrayLike] | ArrayLike = mlab.window_hanning,\\n    noverlap: int = 0,\\n    pad_to: int | None = None,\\n    sides: Literal[\"default\", \"onesided\", \"twosided\"] = \"default\",\\n    scale_by_freq: bool | None = None,\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> tuple[np.ndarray, np.ndarray]:\\n    return gca().cohere(\\n        x,\\n        y,\\n        NFFT=NFFT,\\n        Fs=Fs,\\n        Fc=Fc,\\n        detrend=detrend,\\n        window=window,\\n        noverlap=noverlap,\\n        pad_to=pad_to,\\n        sides=sides,\\n        scale_by_freq=scale_by_freq,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.contour)\\ndef contour(*args, data=None, **kwargs) -> QuadContourSet:\\n    __ret = gca().contour(\\n        *args, **({\"data\": data} if data is not None else {}), **kwargs\\n    )\\n    if __ret._A is not None:  # type: ignore[attr-defined]\\n        sci(__ret)\\n    return __ret\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.contourf)\\ndef contourf(*args, data=None, **kwargs) -> QuadContourSet:\\n    __ret = gca().contourf(\\n        *args, **({\"data\": data} if data is not None else {}), **kwargs\\n    )\\n    if __ret._A is not None:  # type: ignore[attr-defined]\\n        sci(__ret)\\n    return __ret\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.csd)\\ndef csd(\\n    x: ArrayLike,\\n    y: ArrayLike,\\n    NFFT: int | None = None,\\n    Fs: float | None = None,\\n    Fc: int | None = None,\\n    detrend: Literal[\"none\", \"mean\", \"linear\"]\\n    | Callable[[ArrayLike], ArrayLike]\\n    | None = None,\\n    window: Callable[[ArrayLike], ArrayLike] | ArrayLike | None = None,\\n    noverlap: int | None = None,\\n    pad_to: int | None = None,\\n    sides: Literal[\"default\", \"onesided\", \"twosided\"] | None = None,\\n    scale_by_freq: bool | None = None,\\n    return_line: bool | None = None,\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> tuple[np.ndarray, np.ndarray] | tuple[np.ndarray, np.ndarray, Line2D]:\\n    return gca().csd(\\n        x,\\n        y,\\n        NFFT=NFFT,\\n        Fs=Fs,\\n        Fc=Fc,\\n        detrend=detrend,\\n        window=window,\\n        noverlap=noverlap,\\n        pad_to=pad_to,\\n        sides=sides,\\n        scale_by_freq=scale_by_freq,\\n        return_line=return_line,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.ecdf)\\ndef ecdf(\\n    x: ArrayLike,\\n    weights: ArrayLike | None = None,\\n    *,\\n    complementary: bool = False,\\n    orientation: Literal[\"vertical\", \"horizonatal\"] = \"vertical\",\\n    compress: bool = False,\\n    data=None,\\n    **kwargs,\\n) -> Line2D:\\n    return gca().ecdf(\\n        x,\\n        weights=weights,\\n        complementary=complementary,\\n        orientation=orientation,\\n        compress=compress,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.errorbar)\\ndef errorbar(\\n    x: float | ArrayLike,\\n    y: float | ArrayLike,\\n    yerr: float | ArrayLike | None = None,\\n    xerr: float | ArrayLike | None = None,\\n    fmt: str = \"\",\\n    ecolor: ColorType | None = None,\\n    elinewidth: float | None = None,\\n    capsize: float | None = None,\\n    barsabove: bool = False,\\n    lolims: bool | ArrayLike = False,\\n    uplims: bool | ArrayLike = False,\\n    xlolims: bool | ArrayLike = False,\\n    xuplims: bool | ArrayLike = False,\\n    errorevery: int | tuple[int, int] = 1,\\n    capthick: float | None = None,\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> ErrorbarContainer:\\n    return gca().errorbar(\\n        x,\\n        y,\\n        yerr=yerr,\\n        xerr=xerr,\\n        fmt=fmt,\\n        ecolor=ecolor,\\n        elinewidth=elinewidth,\\n        capsize=capsize,\\n        barsabove=barsabove,\\n        lolims=lolims,\\n        uplims=uplims,\\n        xlolims=xlolims,\\n        xuplims=xuplims,\\n        errorevery=errorevery,\\n        capthick=capthick,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.eventplot)\\ndef eventplot(\\n    positions: ArrayLike | Sequence[ArrayLike],\\n    orientation: Literal[\"horizontal\", \"vertical\"] = \"horizontal\",\\n    lineoffsets: float | Sequence[float] = 1,\\n    linelengths: float | Sequence[float] = 1,\\n    linewidths: float | Sequence[float] | None = None,\\n    colors: ColorType | Sequence[ColorType] | None = None,\\n    alpha: float | Sequence[float] | None = None,\\n    linestyles: LineStyleType | Sequence[LineStyleType] = \"solid\",\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> EventCollection:\\n    return gca().eventplot(\\n        positions,\\n        orientation=orientation,\\n        lineoffsets=lineoffsets,\\n        linelengths=linelengths,\\n        linewidths=linewidths,\\n        colors=colors,\\n        alpha=alpha,\\n        linestyles=linestyles,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.fill)\\ndef fill(*args, data=None, **kwargs) -> list[Polygon]:\\n    return gca().fill(*args, **({\"data\": data} if data is not None else {}), **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.fill_between)\\ndef fill_between(\\n    x: ArrayLike,\\n    y1: ArrayLike | float,\\n    y2: ArrayLike | float = 0,\\n    where: Sequence[bool] | None = None,\\n    interpolate: bool = False,\\n    step: Literal[\"pre\", \"post\", \"mid\"] | None = None,\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> FillBetweenPolyCollection:\\n    return gca().fill_between(\\n        x,\\n        y1,\\n        y2=y2,\\n        where=where,\\n        interpolate=interpolate,\\n        step=step,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.fill_betweenx)\\ndef fill_betweenx(\\n    y: ArrayLike,\\n    x1: ArrayLike | float,\\n    x2: ArrayLike | float = 0,\\n    where: Sequence[bool] | None = None,\\n    step: Literal[\"pre\", \"post\", \"mid\"] | None = None,\\n    interpolate: bool = False,\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> FillBetweenPolyCollection:\\n    return gca().fill_betweenx(\\n        y,\\n        x1,\\n        x2=x2,\\n        where=where,\\n        step=step,\\n        interpolate=interpolate,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.grid)\\ndef grid(\\n    visible: bool | None = None,\\n    which: Literal[\"major\", \"minor\", \"both\"] = \"major\",\\n    axis: Literal[\"both\", \"x\", \"y\"] = \"both\",\\n    **kwargs,\\n) -> None:\\n    gca().grid(visible=visible, which=which, axis=axis, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.hexbin)\\ndef hexbin(\\n    x: ArrayLike,\\n    y: ArrayLike,\\n    C: ArrayLike | None = None,\\n    gridsize: int | tuple[int, int] = 100,\\n    bins: Literal[\"log\"] | int | Sequence[float] | None = None,\\n    xscale: Literal[\"linear\", \"log\"] = \"linear\",\\n    yscale: Literal[\"linear\", \"log\"] = \"linear\",\\n    extent: tuple[float, float, float, float] | None = None,\\n    cmap: str | Colormap | None = None,\\n    norm: str | Normalize | None = None,\\n    vmin: float | None = None,\\n    vmax: float | None = None,\\n    alpha: float | None = None,\\n    linewidths: float | None = None,\\n    edgecolors: Literal[\"face\", \"none\"] | ColorType = \"face\",\\n    reduce_C_function: Callable[[np.ndarray | list[float]], float] = np.mean,\\n    mincnt: int | None = None,\\n    marginals: bool = False,\\n    colorizer: Colorizer | None = None,\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> PolyCollection:\\n    __ret = gca().hexbin(\\n        x,\\n        y,\\n        C=C,\\n        gridsize=gridsize,\\n        bins=bins,\\n        xscale=xscale,\\n        yscale=yscale,\\n        extent=extent,\\n        cmap=cmap,\\n        norm=norm,\\n        vmin=vmin,\\n        vmax=vmax,\\n        alpha=alpha,\\n        linewidths=linewidths,\\n        edgecolors=edgecolors,\\n        reduce_C_function=reduce_C_function,\\n        mincnt=mincnt,\\n        marginals=marginals,\\n        colorizer=colorizer,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n    sci(__ret)\\n    return __ret\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.hist)\\ndef hist(\\n    x: ArrayLike | Sequence[ArrayLike],\\n    bins: int | Sequence[float] | str | None = None,\\n    range: tuple[float, float] | None = None,\\n    density: bool = False,\\n    weights: ArrayLike | None = None,\\n    cumulative: bool | float = False,\\n    bottom: ArrayLike | float | None = None,\\n    histtype: Literal[\"bar\", \"barstacked\", \"step\", \"stepfilled\"] = \"bar\",\\n    align: Literal[\"left\", \"mid\", \"right\"] = \"mid\",\\n    orientation: Literal[\"vertical\", \"horizontal\"] = \"vertical\",\\n    rwidth: float | None = None,\\n    log: bool = False,\\n    color: ColorType | Sequence[ColorType] | None = None,\\n    label: str | Sequence[str] | None = None,\\n    stacked: bool = False,\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> tuple[\\n    np.ndarray | list[np.ndarray],\\n    np.ndarray,\\n    BarContainer | Polygon | list[BarContainer | Polygon],\\n]:\\n    return gca().hist(\\n        x,\\n        bins=bins,\\n        range=range,\\n        density=density,\\n        weights=weights,\\n        cumulative=cumulative,\\n        bottom=bottom,\\n        histtype=histtype,\\n        align=align,\\n        orientation=orientation,\\n        rwidth=rwidth,\\n        log=log,\\n        color=color,\\n        label=label,\\n        stacked=stacked,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.stairs)\\ndef stairs(\\n    values: ArrayLike,\\n    edges: ArrayLike | None = None,\\n    *,\\n    orientation: Literal[\"vertical\", \"horizontal\"] = \"vertical\",\\n    baseline: float | ArrayLike | None = 0,\\n    fill: bool = False,\\n    data=None,\\n    **kwargs,\\n) -> StepPatch:\\n    return gca().stairs(\\n        values,\\n        edges=edges,\\n        orientation=orientation,\\n        baseline=baseline,\\n        fill=fill,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.hist2d)\\ndef hist2d(\\n    x: ArrayLike,\\n    y: ArrayLike,\\n    bins: None | int | tuple[int, int] | ArrayLike | tuple[ArrayLike, ArrayLike] = 10,\\n    range: ArrayLike | None = None,\\n    density: bool = False,\\n    weights: ArrayLike | None = None,\\n    cmin: float | None = None,\\n    cmax: float | None = None,\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> tuple[np.ndarray, np.ndarray, np.ndarray, QuadMesh]:\\n    __ret = gca().hist2d(\\n        x,\\n        y,\\n        bins=bins,\\n        range=range,\\n        density=density,\\n        weights=weights,\\n        cmin=cmin,\\n        cmax=cmax,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n    sci(__ret[-1])\\n    return __ret\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.hlines)\\ndef hlines(\\n    y: float | ArrayLike,\\n    xmin: float | ArrayLike,\\n    xmax: float | ArrayLike,\\n    colors: ColorType | Sequence[ColorType] | None = None,\\n    linestyles: LineStyleType = \"solid\",\\n    label: str = \"\",\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> LineCollection:\\n    return gca().hlines(\\n        y,\\n        xmin,\\n        xmax,\\n        colors=colors,\\n        linestyles=linestyles,\\n        label=label,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.imshow)\\ndef imshow(\\n    X: ArrayLike | PIL.Image.Image,\\n    cmap: str | Colormap | None = None,\\n    norm: str | Normalize | None = None,\\n    *,\\n    aspect: Literal[\"equal\", \"auto\"] | float | None = None,\\n    interpolation: str | None = None,\\n    alpha: float | ArrayLike | None = None,\\n    vmin: float | None = None,\\n    vmax: float | None = None,\\n    colorizer: Colorizer | None = None,\\n    origin: Literal[\"upper\", \"lower\"] | None = None,\\n    extent: tuple[float, float, float, float] | None = None,\\n    interpolation_stage: Literal[\"data\", \"rgba\", \"auto\"] | None = None,\\n    filternorm: bool = True,\\n    filterrad: float = 4.0,\\n    resample: bool | None = None,\\n    url: str | None = None,\\n    data=None,\\n    **kwargs,\\n) -> AxesImage:\\n    __ret = gca().imshow(\\n        X,\\n        cmap=cmap,\\n        norm=norm,\\n        aspect=aspect,\\n        interpolation=interpolation,\\n        alpha=alpha,\\n        vmin=vmin,\\n        vmax=vmax,\\n        colorizer=colorizer,\\n        origin=origin,\\n        extent=extent,\\n        interpolation_stage=interpolation_stage,\\n        filternorm=filternorm,\\n        filterrad=filterrad,\\n        resample=resample,\\n        url=url,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n    sci(__ret)\\n    return __ret\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.legend)\\ndef legend(*args, **kwargs) -> Legend:\\n    return gca().legend(*args, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.locator_params)\\ndef locator_params(\\n    axis: Literal[\"both\", \"x\", \"y\"] = \"both\", tight: bool | None = None, **kwargs\\n) -> None:\\n    gca().locator_params(axis=axis, tight=tight, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.loglog)\\ndef loglog(*args, **kwargs) -> list[Line2D]:\\n    return gca().loglog(*args, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.magnitude_spectrum)\\ndef magnitude_spectrum(\\n    x: ArrayLike,\\n    Fs: float | None = None,\\n    Fc: int | None = None,\\n    window: Callable[[ArrayLike], ArrayLike] | ArrayLike | None = None,\\n    pad_to: int | None = None,\\n    sides: Literal[\"default\", \"onesided\", \"twosided\"] | None = None,\\n    scale: Literal[\"default\", \"linear\", \"dB\"] | None = None,\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> tuple[np.ndarray, np.ndarray, Line2D]:\\n    return gca().magnitude_spectrum(\\n        x,\\n        Fs=Fs,\\n        Fc=Fc,\\n        window=window,\\n        pad_to=pad_to,\\n        sides=sides,\\n        scale=scale,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.margins)\\ndef margins(\\n    *margins: float,\\n    x: float | None = None,\\n    y: float | None = None,\\n    tight: bool | None = True,\\n) -> tuple[float, float] | None:\\n    return gca().margins(*margins, x=x, y=y, tight=tight)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.minorticks_off)\\ndef minorticks_off() -> None:\\n    gca().minorticks_off()\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.minorticks_on)\\ndef minorticks_on() -> None:\\n    gca().minorticks_on()\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.pcolor)\\ndef pcolor(\\n    *args: ArrayLike,\\n    shading: Literal[\"flat\", \"nearest\", \"auto\"] | None = None,\\n    alpha: float | None = None,\\n    norm: str | Normalize | None = None,\\n    cmap: str | Colormap | None = None,\\n    vmin: float | None = None,\\n    vmax: float | None = None,\\n    colorizer: Colorizer | None = None,\\n    data=None,\\n    **kwargs,\\n) -> Collection:\\n    __ret = gca().pcolor(\\n        *args,\\n        shading=shading,\\n        alpha=alpha,\\n        norm=norm,\\n        cmap=cmap,\\n        vmin=vmin,\\n        vmax=vmax,\\n        colorizer=colorizer,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n    sci(__ret)\\n    return __ret\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.pcolormesh)\\ndef pcolormesh(\\n    *args: ArrayLike,\\n    alpha: float | None = None,\\n    norm: str | Normalize | None = None,\\n    cmap: str | Colormap | None = None,\\n    vmin: float | None = None,\\n    vmax: float | None = None,\\n    colorizer: Colorizer | None = None,\\n    shading: Literal[\"flat\", \"nearest\", \"gouraud\", \"auto\"] | None = None,\\n    antialiased: bool = False,\\n    data=None,\\n    **kwargs,\\n) -> QuadMesh:\\n    __ret = gca().pcolormesh(\\n        *args,\\n        alpha=alpha,\\n        norm=norm,\\n        cmap=cmap,\\n        vmin=vmin,\\n        vmax=vmax,\\n        colorizer=colorizer,\\n        shading=shading,\\n        antialiased=antialiased,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n    sci(__ret)\\n    return __ret\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.phase_spectrum)\\ndef phase_spectrum(\\n    x: ArrayLike,\\n    Fs: float | None = None,\\n    Fc: int | None = None,\\n    window: Callable[[ArrayLike], ArrayLike] | ArrayLike | None = None,\\n    pad_to: int | None = None,\\n    sides: Literal[\"default\", \"onesided\", \"twosided\"] | None = None,\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> tuple[np.ndarray, np.ndarray, Line2D]:\\n    return gca().phase_spectrum(\\n        x,\\n        Fs=Fs,\\n        Fc=Fc,\\n        window=window,\\n        pad_to=pad_to,\\n        sides=sides,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.pie)\\ndef pie(\\n    x: ArrayLike,\\n    explode: ArrayLike | None = None,\\n    labels: Sequence[str] | None = None,\\n    colors: ColorType | Sequence[ColorType] | None = None,\\n    autopct: str | Callable[[float], str] | None = None,\\n    pctdistance: float = 0.6,\\n    shadow: bool = False,\\n    labeldistance: float | None = 1.1,\\n    startangle: float = 0,\\n    radius: float = 1,\\n    counterclock: bool = True,\\n    wedgeprops: dict[str, Any] | None = None,\\n    textprops: dict[str, Any] | None = None,\\n    center: tuple[float, float] = (0, 0),\\n    frame: bool = False,\\n    rotatelabels: bool = False,\\n    *,\\n    normalize: bool = True,\\n    hatch: str | Sequence[str] | None = None,\\n    data=None,\\n) -> tuple[list[Wedge], list[Text]] | tuple[list[Wedge], list[Text], list[Text]]:\\n    return gca().pie(\\n        x,\\n        explode=explode,\\n        labels=labels,\\n        colors=colors,\\n        autopct=autopct,\\n        pctdistance=pctdistance,\\n        shadow=shadow,\\n        labeldistance=labeldistance,\\n        startangle=startangle,\\n        radius=radius,\\n        counterclock=counterclock,\\n        wedgeprops=wedgeprops,\\n        textprops=textprops,\\n        center=center,\\n        frame=frame,\\n        rotatelabels=rotatelabels,\\n        normalize=normalize,\\n        hatch=hatch,\\n        **({\"data\": data} if data is not None else {}),\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.plot)\\ndef plot(\\n    *args: float | ArrayLike | str,\\n    scalex: bool = True,\\n    scaley: bool = True,\\n    data=None,\\n    **kwargs,\\n) -> list[Line2D]:\\n    return gca().plot(\\n        *args,\\n        scalex=scalex,\\n        scaley=scaley,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.plot_date)\\ndef plot_date(\\n    x: ArrayLike,\\n    y: ArrayLike,\\n    fmt: str = \"o\",\\n    tz: str | datetime.tzinfo | None = None,\\n    xdate: bool = True,\\n    ydate: bool = False,\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> list[Line2D]:\\n    return gca().plot_date(\\n        x,\\n        y,\\n        fmt=fmt,\\n        tz=tz,\\n        xdate=xdate,\\n        ydate=ydate,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.psd)\\ndef psd(\\n    x: ArrayLike,\\n    NFFT: int | None = None,\\n    Fs: float | None = None,\\n    Fc: int | None = None,\\n    detrend: Literal[\"none\", \"mean\", \"linear\"]\\n    | Callable[[ArrayLike], ArrayLike]\\n    | None = None,\\n    window: Callable[[ArrayLike], ArrayLike] | ArrayLike | None = None,\\n    noverlap: int | None = None,\\n    pad_to: int | None = None,\\n    sides: Literal[\"default\", \"onesided\", \"twosided\"] | None = None,\\n    scale_by_freq: bool | None = None,\\n    return_line: bool | None = None,\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> tuple[np.ndarray, np.ndarray] | tuple[np.ndarray, np.ndarray, Line2D]:\\n    return gca().psd(\\n        x,\\n        NFFT=NFFT,\\n        Fs=Fs,\\n        Fc=Fc,\\n        detrend=detrend,\\n        window=window,\\n        noverlap=noverlap,\\n        pad_to=pad_to,\\n        sides=sides,\\n        scale_by_freq=scale_by_freq,\\n        return_line=return_line,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.quiver)\\ndef quiver(*args, data=None, **kwargs) -> Quiver:\\n    __ret = gca().quiver(\\n        *args, **({\"data\": data} if data is not None else {}), **kwargs\\n    )\\n    sci(__ret)\\n    return __ret\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.quiverkey)\\ndef quiverkey(\\n    Q: Quiver, X: float, Y: float, U: float, label: str, **kwargs\\n) -> QuiverKey:\\n    return gca().quiverkey(Q, X, Y, U, label, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.scatter)\\ndef scatter(\\n    x: float | ArrayLike,\\n    y: float | ArrayLike,\\n    s: float | ArrayLike | None = None,\\n    c: ArrayLike | Sequence[ColorType] | ColorType | None = None,\\n    marker: MarkerType | None = None,\\n    cmap: str | Colormap | None = None,\\n    norm: str | Normalize | None = None,\\n    vmin: float | None = None,\\n    vmax: float | None = None,\\n    alpha: float | None = None,\\n    linewidths: float | Sequence[float] | None = None,\\n    *,\\n    edgecolors: Literal[\"face\", \"none\"] | ColorType | Sequence[ColorType] | None = None,\\n    colorizer: Colorizer | None = None,\\n    plotnonfinite: bool = False,\\n    data=None,\\n    **kwargs,\\n) -> PathCollection:\\n    __ret = gca().scatter(\\n        x,\\n        y,\\n        s=s,\\n        c=c,\\n        marker=marker,\\n        cmap=cmap,\\n        norm=norm,\\n        vmin=vmin,\\n        vmax=vmax,\\n        alpha=alpha,\\n        linewidths=linewidths,\\n        edgecolors=edgecolors,\\n        colorizer=colorizer,\\n        plotnonfinite=plotnonfinite,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n    sci(__ret)\\n    return __ret\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.semilogx)\\ndef semilogx(*args, **kwargs) -> list[Line2D]:\\n    return gca().semilogx(*args, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.semilogy)\\ndef semilogy(*args, **kwargs) -> list[Line2D]:\\n    return gca().semilogy(*args, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.specgram)\\ndef specgram(\\n    x: ArrayLike,\\n    NFFT: int | None = None,\\n    Fs: float | None = None,\\n    Fc: int | None = None,\\n    detrend: Literal[\"none\", \"mean\", \"linear\"]\\n    | Callable[[ArrayLike], ArrayLike]\\n    | None = None,\\n    window: Callable[[ArrayLike], ArrayLike] | ArrayLike | None = None,\\n    noverlap: int | None = None,\\n    cmap: str | Colormap | None = None,\\n    xextent: tuple[float, float] | None = None,\\n    pad_to: int | None = None,\\n    sides: Literal[\"default\", \"onesided\", \"twosided\"] | None = None,\\n    scale_by_freq: bool | None = None,\\n    mode: Literal[\"default\", \"psd\", \"magnitude\", \"angle\", \"phase\"] | None = None,\\n    scale: Literal[\"default\", \"linear\", \"dB\"] | None = None,\\n    vmin: float | None = None,\\n    vmax: float | None = None,\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> tuple[np.ndarray, np.ndarray, np.ndarray, AxesImage]:\\n    __ret = gca().specgram(\\n        x,\\n        NFFT=NFFT,\\n        Fs=Fs,\\n        Fc=Fc,\\n        detrend=detrend,\\n        window=window,\\n        noverlap=noverlap,\\n        cmap=cmap,\\n        xextent=xextent,\\n        pad_to=pad_to,\\n        sides=sides,\\n        scale_by_freq=scale_by_freq,\\n        mode=mode,\\n        scale=scale,\\n        vmin=vmin,\\n        vmax=vmax,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n    sci(__ret[-1])\\n    return __ret\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.spy)\\ndef spy(\\n    Z: ArrayLike,\\n    precision: float | Literal[\"present\"] = 0,\\n    marker: str | None = None,\\n    markersize: float | None = None,\\n    aspect: Literal[\"equal\", \"auto\"] | float | None = \"equal\",\\n    origin: Literal[\"upper\", \"lower\"] = \"upper\",\\n    **kwargs,\\n) -> AxesImage:\\n    __ret = gca().spy(\\n        Z,\\n        precision=precision,\\n        marker=marker,\\n        markersize=markersize,\\n        aspect=aspect,\\n        origin=origin,\\n        **kwargs,\\n    )\\n    if isinstance(__ret, _ColorizerInterface):\\n        sci(__ret)\\n    return __ret\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.stackplot)\\ndef stackplot(\\n    x, *args, labels=(), colors=None, hatch=None, baseline=\"zero\", data=None, **kwargs\\n):\\n    return gca().stackplot(\\n        x,\\n        *args,\\n        labels=labels,\\n        colors=colors,\\n        hatch=hatch,\\n        baseline=baseline,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.stem)\\ndef stem(\\n    *args: ArrayLike | str,\\n    linefmt: str | None = None,\\n    markerfmt: str | None = None,\\n    basefmt: str | None = None,\\n    bottom: float = 0,\\n    label: str | None = None,\\n    orientation: Literal[\"vertical\", \"horizontal\"] = \"vertical\",\\n    data=None,\\n) -> StemContainer:\\n    return gca().stem(\\n        *args,\\n        linefmt=linefmt,\\n        markerfmt=markerfmt,\\n        basefmt=basefmt,\\n        bottom=bottom,\\n        label=label,\\n        orientation=orientation,\\n        **({\"data\": data} if data is not None else {}),\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.step)\\ndef step(\\n    x: ArrayLike,\\n    y: ArrayLike,\\n    *args,\\n    where: Literal[\"pre\", \"post\", \"mid\"] = \"pre\",\\n    data=None,\\n    **kwargs,\\n) -> list[Line2D]:\\n    return gca().step(\\n        x,\\n        y,\\n        *args,\\n        where=where,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.streamplot)\\ndef streamplot(\\n    x,\\n    y,\\n    u,\\n    v,\\n    density=1,\\n    linewidth=None,\\n    color=None,\\n    cmap=None,\\n    norm=None,\\n    arrowsize=1,\\n    arrowstyle=\"-|>\",\\n    minlength=0.1,\\n    transform=None,\\n    zorder=None,\\n    start_points=None,\\n    maxlength=4.0,\\n    integration_direction=\"both\",\\n    broken_streamlines=True,\\n    *,\\n    data=None,\\n):\\n    __ret = gca().streamplot(\\n        x,\\n        y,\\n        u,\\n        v,\\n        density=density,\\n        linewidth=linewidth,\\n        color=color,\\n        cmap=cmap,\\n        norm=norm,\\n        arrowsize=arrowsize,\\n        arrowstyle=arrowstyle,\\n        minlength=minlength,\\n        transform=transform,\\n        zorder=zorder,\\n        start_points=start_points,\\n        maxlength=maxlength,\\n        integration_direction=integration_direction,\\n        broken_streamlines=broken_streamlines,\\n        **({\"data\": data} if data is not None else {}),\\n    )\\n    sci(__ret.lines)\\n    return __ret\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.table)\\ndef table(\\n    cellText=None,\\n    cellColours=None,\\n    cellLoc=\"right\",\\n    colWidths=None,\\n    rowLabels=None,\\n    rowColours=None,\\n    rowLoc=\"left\",\\n    colLabels=None,\\n    colColours=None,\\n    colLoc=\"center\",\\n    loc=\"bottom\",\\n    bbox=None,\\n    edges=\"closed\",\\n    **kwargs,\\n):\\n    return gca().table(\\n        cellText=cellText,\\n        cellColours=cellColours,\\n        cellLoc=cellLoc,\\n        colWidths=colWidths,\\n        rowLabels=rowLabels,\\n        rowColours=rowColours,\\n        rowLoc=rowLoc,\\n        colLabels=colLabels,\\n        colColours=colColours,\\n        colLoc=colLoc,\\n        loc=loc,\\n        bbox=bbox,\\n        edges=edges,\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.text)\\ndef text(\\n    x: float, y: float, s: str, fontdict: dict[str, Any] | None = None, **kwargs\\n) -> Text:\\n    return gca().text(x, y, s, fontdict=fontdict, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.tick_params)\\ndef tick_params(axis: Literal[\"both\", \"x\", \"y\"] = \"both\", **kwargs) -> None:\\n    gca().tick_params(axis=axis, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.ticklabel_format)\\ndef ticklabel_format(\\n    *,\\n    axis: Literal[\"both\", \"x\", \"y\"] = \"both\",\\n    style: Literal[\"\", \"sci\", \"scientific\", \"plain\"] | None = None,\\n    scilimits: tuple[int, int] | None = None,\\n    useOffset: bool | float | None = None,\\n    useLocale: bool | None = None,\\n    useMathText: bool | None = None,\\n) -> None:\\n    gca().ticklabel_format(\\n        axis=axis,\\n        style=style,\\n        scilimits=scilimits,\\n        useOffset=useOffset,\\n        useLocale=useLocale,\\n        useMathText=useMathText,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.tricontour)\\ndef tricontour(*args, **kwargs):\\n    __ret = gca().tricontour(*args, **kwargs)\\n    if __ret._A is not None:  # type: ignore[attr-defined]\\n        sci(__ret)\\n    return __ret\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.tricontourf)\\ndef tricontourf(*args, **kwargs):\\n    __ret = gca().tricontourf(*args, **kwargs)\\n    if __ret._A is not None:  # type: ignore[attr-defined]\\n        sci(__ret)\\n    return __ret\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.tripcolor)\\ndef tripcolor(\\n    *args,\\n    alpha=1.0,\\n    norm=None,\\n    cmap=None,\\n    vmin=None,\\n    vmax=None,\\n    shading=\"flat\",\\n    facecolors=None,\\n    **kwargs,\\n):\\n    __ret = gca().tripcolor(\\n        *args,\\n        alpha=alpha,\\n        norm=norm,\\n        cmap=cmap,\\n        vmin=vmin,\\n        vmax=vmax,\\n        shading=shading,\\n        facecolors=facecolors,\\n        **kwargs,\\n    )\\n    sci(__ret)\\n    return __ret\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.triplot)\\ndef triplot(*args, **kwargs):\\n    return gca().triplot(*args, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.violinplot)\\ndef violinplot(\\n    dataset: ArrayLike | Sequence[ArrayLike],\\n    positions: ArrayLike | None = None,\\n    vert: bool | None = None,\\n    orientation: Literal[\"vertical\", \"horizontal\"] = \"vertical\",\\n    widths: float | ArrayLike = 0.5,\\n    showmeans: bool = False,\\n    showextrema: bool = True,\\n    showmedians: bool = False,\\n    quantiles: Sequence[float | Sequence[float]] | None = None,\\n    points: int = 100,\\n    bw_method: Literal[\"scott\", \"silverman\"]\\n    | float\\n    | Callable[[GaussianKDE], float]\\n    | None = None,\\n    side: Literal[\"both\", \"low\", \"high\"] = \"both\",\\n    *,\\n    data=None,\\n) -> dict[str, Collection]:\\n    return gca().violinplot(\\n        dataset,\\n        positions=positions,\\n        vert=vert,\\n        orientation=orientation,\\n        widths=widths,\\n        showmeans=showmeans,\\n        showextrema=showextrema,\\n        showmedians=showmedians,\\n        quantiles=quantiles,\\n        points=points,\\n        bw_method=bw_method,\\n        side=side,\\n        **({\"data\": data} if data is not None else {}),\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.vlines)\\ndef vlines(\\n    x: float | ArrayLike,\\n    ymin: float | ArrayLike,\\n    ymax: float | ArrayLike,\\n    colors: ColorType | Sequence[ColorType] | None = None,\\n    linestyles: LineStyleType = \"solid\",\\n    label: str = \"\",\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> LineCollection:\\n    return gca().vlines(\\n        x,\\n        ymin,\\n        ymax,\\n        colors=colors,\\n        linestyles=linestyles,\\n        label=label,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.xcorr)\\ndef xcorr(\\n    x: ArrayLike,\\n    y: ArrayLike,\\n    normed: bool = True,\\n    detrend: Callable[[ArrayLike], ArrayLike] = mlab.detrend_none,\\n    usevlines: bool = True,\\n    maxlags: int = 10,\\n    *,\\n    data=None,\\n    **kwargs,\\n) -> tuple[np.ndarray, np.ndarray, LineCollection | Line2D, Line2D | None]:\\n    return gca().xcorr(\\n        x,\\n        y,\\n        normed=normed,\\n        detrend=detrend,\\n        usevlines=usevlines,\\n        maxlags=maxlags,\\n        **({\"data\": data} if data is not None else {}),\\n        **kwargs,\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes._sci)\\ndef sci(im: ColorizingArtist) -> None:\\n    gca()._sci(im)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.set_title)\\ndef title(\\n    label: str,\\n    fontdict: dict[str, Any] | None = None,\\n    loc: Literal[\"left\", \"center\", \"right\"] | None = None,\\n    pad: float | None = None,\\n    *,\\n    y: float | None = None,\\n    **kwargs,\\n) -> Text:\\n    return gca().set_title(label, fontdict=fontdict, loc=loc, pad=pad, y=y, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.set_xlabel)\\ndef xlabel(\\n    xlabel: str,\\n    fontdict: dict[str, Any] | None = None,\\n    labelpad: float | None = None,\\n    *,\\n    loc: Literal[\"left\", \"center\", \"right\"] | None = None,\\n    **kwargs,\\n) -> Text:\\n    return gca().set_xlabel(\\n        xlabel, fontdict=fontdict, labelpad=labelpad, loc=loc, **kwargs\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.set_ylabel)\\ndef ylabel(\\n    ylabel: str,\\n    fontdict: dict[str, Any] | None = None,\\n    labelpad: float | None = None,\\n    *,\\n    loc: Literal[\"bottom\", \"center\", \"top\"] | None = None,\\n    **kwargs,\\n) -> Text:\\n    return gca().set_ylabel(\\n        ylabel, fontdict=fontdict, labelpad=labelpad, loc=loc, **kwargs\\n    )\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.set_xscale)\\ndef xscale(value: str | ScaleBase, **kwargs) -> None:\\n    gca().set_xscale(value, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\n@_copy_docstring_and_deprecators(Axes.set_yscale)\\ndef yscale(value: str | ScaleBase, **kwargs) -> None:\\n    gca().set_yscale(value, **kwargs)\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef autumn() -> None:\\n    \"\"\"\\n    Set the colormap to \\'autumn\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"autumn\")\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef bone() -> None:\\n    \"\"\"\\n    Set the colormap to \\'bone\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"bone\")\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef cool() -> None:\\n    \"\"\"\\n    Set the colormap to \\'cool\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"cool\")\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef copper() -> None:\\n    \"\"\"\\n    Set the colormap to \\'copper\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"copper\")\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef flag() -> None:\\n    \"\"\"\\n    Set the colormap to \\'flag\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"flag\")\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef gray() -> None:\\n    \"\"\"\\n    Set the colormap to \\'gray\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"gray\")\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef hot() -> None:\\n    \"\"\"\\n    Set the colormap to \\'hot\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"hot\")\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef hsv() -> None:\\n    \"\"\"\\n    Set the colormap to \\'hsv\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"hsv\")\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef jet() -> None:\\n    \"\"\"\\n    Set the colormap to \\'jet\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"jet\")\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef pink() -> None:\\n    \"\"\"\\n    Set the colormap to \\'pink\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"pink\")\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef prism() -> None:\\n    \"\"\"\\n    Set the colormap to \\'prism\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"prism\")\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef spring() -> None:\\n    \"\"\"\\n    Set the colormap to \\'spring\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"spring\")\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef summer() -> None:\\n    \"\"\"\\n    Set the colormap to \\'summer\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"summer\")\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef winter() -> None:\\n    \"\"\"\\n    Set the colormap to \\'winter\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"winter\")\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef magma() -> None:\\n    \"\"\"\\n    Set the colormap to \\'magma\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"magma\")\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef inferno() -> None:\\n    \"\"\"\\n    Set the colormap to \\'inferno\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"inferno\")\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef plasma() -> None:\\n    \"\"\"\\n    Set the colormap to \\'plasma\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"plasma\")\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef viridis() -> None:\\n    \"\"\"\\n    Set the colormap to \\'viridis\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"viridis\")\\n\\n\\n# Autogenerated by boilerplate.py.  Do not edit as changes will be lost.\\ndef nipy_spectral() -> None:\\n    \"\"\"\\n    Set the colormap to \\'nipy_spectral\\'.\\n\\n    This changes the default colormap as well as the colormap of the current\\n    image if there is one. See ``help(colormaps)`` for more information.\\n    \"\"\"\\n    set_cmap(\"nipy_spectral\")\\n', 'caller': 'default_function'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from ContextGenerators.LanguageContextGeneratorManager import LanguageContextGenerator\n",
    "import getProjectCommitState\n",
    "from getProjectCommitState import CLBPP\n",
    "import model\n",
    "\n",
    "config = {\n",
    "    # \"dataset_path\": \"/mnt/ssd2/wangke/dataset/AgentRefiner/datasets/new_repo_datasets_estimated.json\",\n",
    "    \"dataset_path\": \"/mnt/ssd2/wangke/dataset/AgentRefiner/datasets/new_repo_datasets.json\",\n",
    "    #  \"dataset_path\": \"/mnt/ssd2/wangke/dataset/AgentRefiner/datasets/new_datasets.json\",\n",
    "    \"output_path\": \"/mnt/ssd2/wangke/dataset/AgentRefiner/tmp_result.json\"\n",
    "}\n",
    "with open(config[\"dataset_path\"], \"r\") as f:\n",
    "    records = [json.loads(line) for line in f]\n",
    "    print(len(records))\n",
    "    # print(records[5][\"_id\"])\n",
    "    record = records[7]\n",
    "    # record[\"old\"] = record[\"old\"].split(\"\\n\")\n",
    "    # record[\"new\"] = record[\"new\"].split(\"\\n\")\n",
    "    record = CLBPP(record)\n",
    "    languageContextGenerator = LanguageContextGenerator(record)\n",
    "    contextGenerator = languageContextGenerator.context_generator\n",
    "    defs_bef = contextGenerator.getContext()\n",
    "    print(defs_bef)\n",
    "    \n",
    "\n",
    "\n",
    "# with open(config[\"output_path\"], \"w\") as f1:\n",
    "#     json.dump(record, f1, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '-', ' import numpy as np', ' from matplotlib import pyplot as plt', ' from sklearn import datasets', ' ', '+', ' # Ridge Regression function', ' # reference : https://en.wikipedia.org/wiki/Ridge_regression', '-def ridge_cost_function(x: np.ndarray, y: np.ndarray, theta: np.ndarray, alpha: float) -> float:', '+def ridge_cost_function(', '+    x: np.ndarray, y: np.ndarray, theta: np.ndarray, alpha: float', '+) -> float:', '     \"\"\"', '     Compute the Ridge regression cost function with L2 regularization.', ' ', '']\n"
     ]
    }
   ],
   "source": [
    "old = [\n",
    "    \"\",\n",
    "    \"-\",\n",
    "    \" import numpy as np\",\n",
    "    \" from matplotlib import pyplot as plt\",\n",
    "    \" from sklearn import datasets\",\n",
    "    \" \",\n",
    "    \" # Ridge Regression function\",\n",
    "    \" # reference : https://en.wikipedia.org/wiki/Ridge_regression\",\n",
    "    \"-def ridge_cost_function(x: np.ndarray, y: np.ndarray, theta: np.ndarray, alpha: float) -> float:\",\n",
    "    \"     \\\"\\\"\\\"\",\n",
    "    \"     Compute the Ridge regression cost function with L2 regularization.\",\n",
    "    \" \",\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "new = [\n",
    "    \"\",\n",
    "    \" import numpy as np\",\n",
    "    \" from matplotlib import pyplot as plt\",\n",
    "    \" from sklearn import datasets\",\n",
    "    \" \",\n",
    "    \"+\",\n",
    "    \" # Ridge Regression function\",\n",
    "    \" # reference : https://en.wikipedia.org/wiki/Ridge_regression\",\n",
    "    \"+def ridge_cost_function(\",\n",
    "    \"+    x: np.ndarray, y: np.ndarray, theta: np.ndarray, alpha: float\",\n",
    "    \"+) -> float:\",\n",
    "    \"     \\\"\\\"\\\"\",\n",
    "    \"     Compute the Ridge regression cost function with L2 regularization.\",\n",
    "    \" \",\n",
    "    \"\"\n",
    "]\n",
    "\n",
    "def merge_diff(old, new):\n",
    "    diff = []\n",
    "    i, j = 0, 0\n",
    "    while i < len(old) or j < len(new):\n",
    "        line_old = old[i] if i < len(old) else \"\"\n",
    "        line_new = new[j] if j < len(new) else \"\"\n",
    "\n",
    "        if line_old.startswith(\"-\"):\n",
    "            diff.append(line_old)\n",
    "            i += 1\n",
    "        elif line_new.startswith(\"+\"):\n",
    "            diff.append(line_new)\n",
    "            j += 1\n",
    "        else:\n",
    "            # Prefer new line if available and not a + line\n",
    "            if j < len(new) and not line_new.startswith(\"+\"):\n",
    "                diff.append(line_new)\n",
    "            elif i < len(old):\n",
    "                diff.append(line_old)\n",
    "            i += 1\n",
    "            j += 1\n",
    "\n",
    "    return diff\n",
    "\n",
    "print(merge_diff(old, new))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpaca-lora",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
