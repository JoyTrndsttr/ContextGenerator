import gradio as gr
import json
import os
import re
import copy

# æ–‡ä»¶è·¯å¾„
data_file = "/mnt/ssd2/wangke/dataset/AgentRefiner/datasets/new_datasets_all_filtered_5.json"
output_file = "/mnt/ssd2/wangke/dataset/AgentRefiner/final_datasets/datasets_human_filtered.json"

# è¯»å–æ•°æ®
with open(data_file, "r", encoding="utf-8") as f:
    all_records = [json.loads(line) for line in f]

# è·å–æœ€åä¸€ä¸ªå·²é€šè¿‡è®°å½•çš„ _id
passed_records = []
last_passed_id = 0
if os.path.exists(output_file):
    with open(output_file, "r", encoding="utf-8") as f1:
        passed_records = [json.loads(line) for line in f1]
        if passed_records:
            last_passed_id = passed_records[-1].get("_id", 0)

# æ ¹æ® last_passed_id ç­›é€‰å‡ºå¾…å®¡æŸ¥è®°å½•
records_to_review = [r for r in all_records if r.get("_id", 0) > last_passed_id]
# records_to_review = [record for record in records_to_review if record["dataset_valid_or_discard_estimation"]["Classification"] == "Valid"]

# ä½¿ç”¨ index æ¥è·Ÿè¸ªå½“å‰å±•ç¤ºä½ç½®
index = 0

def split_diff(diff):
    diff_lines = diff.split("\n")[1:]
    old_lines = []
    new_lines = []
    for line in diff_lines:
        if line.startswith("-"):
            old_lines.append(line)
        elif line.startswith("+"):
            new_lines.append(line)
        else:
            old_lines.append(line)
            new_lines.append(line)
    return old_lines, new_lines

def review_line_exist_in_old(old_lines, review_line):
    def normalize_text(text):
        text = re.sub(r'\W+','', text)
        return text

    old_lines = [normalize_text(line) for line in old_lines]
    review_line = normalize_text(review_line)
    return review_line in old_lines

def show_record():
    global index
    if index >= len(records_to_review):
        return "âœ… æ‰€æœ‰è®°å½•å·²è¯„ä¼°å®Œæ¯•ã€‚", f"{len(passed_records)} / {len(records_to_review)}"
    record = copy.deepcopy(records_to_review[index])
    record["old"] = record["old"].split("\n")
    record["new"] = record["new"].split("\n")
    record["diff_hunk"] = record["diff_hunk"].split("\n")
    if not review_line_exist_in_old(record["old"], record["comment"]["review_position_line"]) : reject_record()
    record["path"] = "omit"
    record["code_diff"] = "omit"
    return json.dumps(record, ensure_ascii=False, indent=2), f"{index + 1} / {len(records_to_review)}"

def pass_record():
    global index
    if index >= len(records_to_review):
        return "âœ… æ‰€æœ‰è®°å½•å·²è¯„ä¼°å®Œæ¯•ã€‚", f"{len(passed_records)} / {len(records_to_review)}"
    record = records_to_review[index]
    old, new = split_diff(record["diff_hunk"])
    record["old"] = '\n'.join(old)
    record["new"] = '\n'.join(new)
    with open(output_file, "a", encoding="utf-8") as f:
        f.write(json.dumps(record, ensure_ascii=False) + "\n")
    index += 1
    passed_records.append(record)
    return show_record()

def reject_record():
    global index
    if index >= len(records_to_review):
        return "âœ… æ‰€æœ‰è®°å½•å·²è¯„ä¼°å®Œæ¯•ã€‚", f"{len(passed_records)} / {len(records_to_review)}"
    index += 1
    return show_record()

with gr.Blocks() as demo:
    gr.Markdown("# ğŸ‘ï¸ äººå·¥æ•°æ®ç­›é€‰ç•Œé¢")
    # ä½¿ç”¨ gr.Code ç»„ä»¶æ¥æ˜¾ç¤º JSON æ ¼å¼çš„å†…å®¹å¹¶é«˜äº®
    record_display = gr.Code(label="å½“å‰è®°å½•å†…å®¹", language="json", lines=20)
    progress_display = gr.Textbox(label="è¿›åº¦")
    with gr.Row():
        btn_pass = gr.Button("âœ… é€šè¿‡")
        btn_reject = gr.Button("âŒ ä¸é€šè¿‡")
    btn_pass.click(pass_record, outputs=[record_display, progress_display])
    btn_reject.click(reject_record, outputs=[record_display, progress_display])

    # åˆå§‹åŒ–å†…å®¹
    demo.load(show_record, outputs=[record_display, progress_display])

demo.launch(server_name="0.0.0.0", server_port=7860)
